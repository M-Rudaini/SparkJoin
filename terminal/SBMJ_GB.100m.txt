Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
18/03/19 07:43:16 WARN Utils: Your hostname, rudaini.com resolves to a loopback address: 127.0.0.1; using 192.168.8.100 instead (on interface wlp3s0)
18/03/19 07:43:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
18/03/19 07:43:16 INFO SparkContext: Running Spark version 2.3.0
18/03/19 07:43:16 DEBUG MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
18/03/19 07:43:16 DEBUG MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
18/03/19 07:43:16 DEBUG MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
18/03/19 07:43:16 DEBUG MetricsSystemImpl: UgiMetrics, User and group related metrics
18/03/19 07:43:17 DEBUG KerberosName: Kerberos krb5 configuration not found, setting default realm to empty
18/03/19 07:43:17 DEBUG Groups:  Creating new Groups object
18/03/19 07:43:17 DEBUG NativeCodeLoader: Trying to load the custom-built native-hadoop library...
18/03/19 07:43:17 DEBUG NativeCodeLoader: Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
18/03/19 07:43:17 DEBUG NativeCodeLoader: java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
18/03/19 07:43:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/03/19 07:43:17 DEBUG PerformanceAdvisory: Falling back to shell based
18/03/19 07:43:17 DEBUG JniBasedUnixGroupsMappingWithFallback: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
18/03/19 07:43:17 DEBUG Shell: setsid exited with exit code 0
18/03/19 07:43:17 DEBUG Groups: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
18/03/19 07:43:17 DEBUG UserGroupInformation: hadoop login
18/03/19 07:43:17 DEBUG UserGroupInformation: hadoop login commit
18/03/19 07:43:17 DEBUG UserGroupInformation: using local user:UnixPrincipal: rudaini
18/03/19 07:43:17 DEBUG UserGroupInformation: Using user: "UnixPrincipal: rudaini" with name rudaini
18/03/19 07:43:17 DEBUG UserGroupInformation: User entry: "rudaini"
18/03/19 07:43:17 DEBUG UserGroupInformation: UGI loginUser:rudaini (auth:SIMPLE)
18/03/19 07:43:17 INFO SparkContext: Submitted application: Spark_Basic_RDD_Join_Using_ReduceByKey
18/03/19 07:43:17 INFO SecurityManager: Changing view acls to: rudaini
18/03/19 07:43:17 INFO SecurityManager: Changing modify acls to: rudaini
18/03/19 07:43:17 INFO SecurityManager: Changing view acls groups to: 
18/03/19 07:43:17 INFO SecurityManager: Changing modify acls groups to: 
18/03/19 07:43:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rudaini); groups with view permissions: Set(); users  with modify permissions: Set(rudaini); groups with modify permissions: Set()
18/03/19 07:43:17 DEBUG SecurityManager: Created SSL options for fs: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
18/03/19 07:43:17 DEBUG TransportServer: Shuffle server started on port: 45639
18/03/19 07:43:17 INFO Utils: Successfully started service 'sparkDriver' on port 45639.
18/03/19 07:43:17 DEBUG SparkEnv: Using serializer: class org.apache.spark.serializer.JavaSerializer
18/03/19 07:43:17 INFO SparkEnv: Registering MapOutputTracker
18/03/19 07:43:17 DEBUG MapOutputTrackerMasterEndpoint: init
18/03/19 07:43:18 INFO SparkEnv: Registering BlockManagerMaster
18/03/19 07:43:18 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/03/19 07:43:18 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/03/19 07:43:18 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d
18/03/19 07:43:18 DEBUG DiskBlockManager: Adding shutdown hook
18/03/19 07:43:18 DEBUG ShutdownHookManager: Adding shutdown hook
18/03/19 07:43:18 INFO MemoryStore: MemoryStore started with capacity 852.6 MB
18/03/19 07:43:18 INFO SparkEnv: Registering OutputCommitCoordinator
18/03/19 07:43:18 DEBUG OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: init
18/03/19 07:43:18 DEBUG SecurityManager: Created SSL options for ui: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
18/03/19 07:43:18 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/03/19 07:43:18 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.8.100:4040
18/03/19 07:43:18 TRACE HeartbeatReceiver: Checking for hosts with no recent heartbeats in HeartbeatReceiver.
18/03/19 07:43:18 INFO Executor: Starting executor ID driver on host localhost
18/03/19 07:43:18 DEBUG TransportServer: Shuffle server started on port: 40919
18/03/19 07:43:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40919.
18/03/19 07:43:18 INFO NettyBlockTransferService: Server created on 192.168.8.100:40919
18/03/19 07:43:18 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/03/19 07:43:18 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.8.100, 40919, None)
18/03/19 07:43:18 DEBUG DefaultTopologyMapper: Got a request for 192.168.8.100
18/03/19 07:43:18 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.8.100:40919 with 852.6 MB RAM, BlockManagerId(driver, 192.168.8.100, 40919, None)
18/03/19 07:43:18 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.8.100, 40919, None)
18/03/19 07:43:18 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.8.100, 40919, None)
18/03/19 07:43:18 DEBUG SparkContext: Adding shutdown hook
18/03/19 07:43:19 TRACE BlockInfoManager: Task -1024 trying to put broadcast_0
18/03/19 07:43:19 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_0
18/03/19 07:43:19 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_0
18/03/19 07:43:19 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_0
18/03/19 07:43:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 214.5 KB, free 852.4 MB)
18/03/19 07:43:19 DEBUG BlockManager: Put block broadcast_0 locally took  202 ms
18/03/19 07:43:19 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_0
18/03/19 07:43:19 DEBUG BlockManager: Putting block broadcast_0 without replication took  214 ms
18/03/19 07:43:19 TRACE BlockInfoManager: Task -1024 trying to put broadcast_0_piece0
18/03/19 07:43:19 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_0_piece0
18/03/19 07:43:19 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_0_piece0
18/03/19 07:43:19 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_0_piece0
18/03/19 07:43:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 852.4 MB)
18/03/19 07:43:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.8.100:40919 (size: 20.4 KB, free: 852.6 MB)
18/03/19 07:43:19 DEBUG BlockManagerMaster: Updated info of block broadcast_0_piece0
18/03/19 07:43:19 DEBUG BlockManager: Told master about block broadcast_0_piece0
18/03/19 07:43:19 DEBUG BlockManager: Put block broadcast_0_piece0 locally took  13 ms
18/03/19 07:43:19 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_0_piece0
18/03/19 07:43:19 DEBUG BlockManager: Putting block broadcast_0_piece0 without replication took  15 ms
18/03/19 07:43:19 INFO SparkContext: Created broadcast 0 from textFile at SBMJ_GB.scala:26
18/03/19 07:43:19 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$30) +++
18/03/19 07:43:19 DEBUG ClosureCleaner:  + declared fields: 2
18/03/19 07:43:19 DEBUG ClosureCleaner:      public static final long org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$30.serialVersionUID
18/03/19 07:43:19 DEBUG ClosureCleaner:      private final org.apache.spark.SparkContext$$anonfun$hadoopFile$1 org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$30.$outer
18/03/19 07:43:19 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:19 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$30.apply(java.lang.Object)
18/03/19 07:43:19 DEBUG ClosureCleaner:      public final void org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$30.apply(org.apache.hadoop.mapred.JobConf)
18/03/19 07:43:19 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:43:19 DEBUG ClosureCleaner:  + outer classes: 2
18/03/19 07:43:19 DEBUG ClosureCleaner:      org.apache.spark.SparkContext$$anonfun$hadoopFile$1
18/03/19 07:43:19 DEBUG ClosureCleaner:      org.apache.spark.SparkContext
18/03/19 07:43:19 DEBUG ClosureCleaner:  + outer objects: 2
18/03/19 07:43:19 DEBUG ClosureCleaner:      <function0>
18/03/19 07:43:19 DEBUG ClosureCleaner:      org.apache.spark.SparkContext@165e389b
18/03/19 07:43:19 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:43:19 DEBUG ClosureCleaner:  + fields accessed by starting closure: 4
18/03/19 07:43:19 DEBUG ClosureCleaner:      (class java.lang.Object,Set())
18/03/19 07:43:19 DEBUG ClosureCleaner:      (class org.apache.spark.SparkContext$$anonfun$hadoopFile$1,Set(path$6))
18/03/19 07:43:19 DEBUG ClosureCleaner:      (class scala.runtime.AbstractFunction0,Set())
18/03/19 07:43:19 DEBUG ClosureCleaner:      (class org.apache.spark.SparkContext,Set())
18/03/19 07:43:19 DEBUG ClosureCleaner:  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.SparkContext,org.apache.spark.SparkContext@165e389b)
18/03/19 07:43:19 DEBUG ClosureCleaner:  + cloning the object <function0> of class org.apache.spark.SparkContext$$anonfun$hadoopFile$1
18/03/19 07:43:19 DEBUG ClosureCleaner:  + cleaning cloned closure <function0> recursively (org.apache.spark.SparkContext$$anonfun$hadoopFile$1)
18/03/19 07:43:19 DEBUG ClosureCleaner: +++ Cleaning closure <function0> (org.apache.spark.SparkContext$$anonfun$hadoopFile$1) +++
18/03/19 07:43:19 DEBUG ClosureCleaner:  + declared fields: 7
18/03/19 07:43:19 DEBUG ClosureCleaner:      public static final long org.apache.spark.SparkContext$$anonfun$hadoopFile$1.serialVersionUID
18/03/19 07:43:19 DEBUG ClosureCleaner:      private final org.apache.spark.SparkContext org.apache.spark.SparkContext$$anonfun$hadoopFile$1.$outer
18/03/19 07:43:19 DEBUG ClosureCleaner:      public final java.lang.String org.apache.spark.SparkContext$$anonfun$hadoopFile$1.path$6
18/03/19 07:43:19 DEBUG ClosureCleaner:      private final java.lang.Class org.apache.spark.SparkContext$$anonfun$hadoopFile$1.inputFormatClass$1
18/03/19 07:43:19 DEBUG ClosureCleaner:      private final java.lang.Class org.apache.spark.SparkContext$$anonfun$hadoopFile$1.keyClass$1
18/03/19 07:43:19 DEBUG ClosureCleaner:      private final java.lang.Class org.apache.spark.SparkContext$$anonfun$hadoopFile$1.valueClass$1
18/03/19 07:43:19 DEBUG ClosureCleaner:      private final int org.apache.spark.SparkContext$$anonfun$hadoopFile$1.minPartitions$3
18/03/19 07:43:19 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:19 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$hadoopFile$1.apply()
18/03/19 07:43:19 DEBUG ClosureCleaner:      public final org.apache.spark.rdd.HadoopRDD org.apache.spark.SparkContext$$anonfun$hadoopFile$1.apply()
18/03/19 07:43:19 DEBUG ClosureCleaner:  + inner classes: 1
18/03/19 07:43:19 DEBUG ClosureCleaner:      org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$30
18/03/19 07:43:19 DEBUG ClosureCleaner:  + outer classes: 1
18/03/19 07:43:19 DEBUG ClosureCleaner:      org.apache.spark.SparkContext
18/03/19 07:43:19 DEBUG ClosureCleaner:  + outer objects: 1
18/03/19 07:43:19 DEBUG ClosureCleaner:      org.apache.spark.SparkContext@165e389b
18/03/19 07:43:19 DEBUG ClosureCleaner:  + fields accessed by starting closure: 4
18/03/19 07:43:19 DEBUG ClosureCleaner:      (class java.lang.Object,Set())
18/03/19 07:43:19 DEBUG ClosureCleaner:      (class org.apache.spark.SparkContext$$anonfun$hadoopFile$1,Set(path$6))
18/03/19 07:43:19 DEBUG ClosureCleaner:      (class scala.runtime.AbstractFunction0,Set())
18/03/19 07:43:19 DEBUG ClosureCleaner:      (class org.apache.spark.SparkContext,Set())
18/03/19 07:43:19 DEBUG ClosureCleaner:  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.SparkContext,org.apache.spark.SparkContext@165e389b)
18/03/19 07:43:19 DEBUG ClosureCleaner:  + the starting closure doesn't actually need org.apache.spark.SparkContext@165e389b, so we null it out
18/03/19 07:43:19 DEBUG ClosureCleaner:  +++ closure <function0> (org.apache.spark.SparkContext$$anonfun$hadoopFile$1) is now cleaned +++
18/03/19 07:43:19 DEBUG ClosureCleaner:  +++ closure <function1> (org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$30) is now cleaned +++
18/03/19 07:43:19 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (org.apache.spark.SparkContext$$anonfun$textFile$1$$anonfun$apply$8) +++
18/03/19 07:43:19 DEBUG ClosureCleaner:  + declared fields: 1
18/03/19 07:43:19 DEBUG ClosureCleaner:      public static final long org.apache.spark.SparkContext$$anonfun$textFile$1$$anonfun$apply$8.serialVersionUID
18/03/19 07:43:19 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:19 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$textFile$1$$anonfun$apply$8.apply(java.lang.Object)
18/03/19 07:43:19 DEBUG ClosureCleaner:      public final java.lang.String org.apache.spark.SparkContext$$anonfun$textFile$1$$anonfun$apply$8.apply(scala.Tuple2)
18/03/19 07:43:19 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:43:19 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:43:19 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:43:19 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:43:19 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:43:19 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:43:19 DEBUG ClosureCleaner:  +++ closure <function1> (org.apache.spark.SparkContext$$anonfun$textFile$1$$anonfun$apply$8) is now cleaned +++
18/03/19 07:43:19 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (Joins.SBMJ_GB$$anonfun$1) +++
18/03/19 07:43:19 DEBUG ClosureCleaner:  + declared fields: 1
18/03/19 07:43:19 DEBUG ClosureCleaner:      public static final long Joins.SBMJ_GB$$anonfun$1.serialVersionUID
18/03/19 07:43:19 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:19 DEBUG ClosureCleaner:      public final java.lang.Object Joins.SBMJ_GB$$anonfun$1.apply(java.lang.Object)
18/03/19 07:43:19 DEBUG ClosureCleaner:      public final boolean Joins.SBMJ_GB$$anonfun$1.apply(java.lang.String)
18/03/19 07:43:19 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:43:19 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:43:19 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:43:19 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:43:19 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:43:19 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:43:19 DEBUG ClosureCleaner:  +++ closure <function1> (Joins.SBMJ_GB$$anonfun$1) is now cleaned +++
18/03/19 07:43:19 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (Joins.SBMJ_GB$$anonfun$2) +++
18/03/19 07:43:19 DEBUG ClosureCleaner:  + declared fields: 1
18/03/19 07:43:19 DEBUG ClosureCleaner:      public static final long Joins.SBMJ_GB$$anonfun$2.serialVersionUID
18/03/19 07:43:19 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:19 DEBUG ClosureCleaner:      public final java.lang.Object Joins.SBMJ_GB$$anonfun$2.apply(java.lang.Object)
18/03/19 07:43:19 DEBUG ClosureCleaner:      public final java.lang.String Joins.SBMJ_GB$$anonfun$2.apply(java.lang.String)
18/03/19 07:43:19 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:43:19 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:43:19 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:43:19 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:43:19 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:43:19 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:43:19 DEBUG ClosureCleaner:  +++ closure <function1> (Joins.SBMJ_GB$$anonfun$2) is now cleaned +++
18/03/19 07:43:19 DEBUG BlockManager: Getting local block broadcast_0
18/03/19 07:43:19 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_0
18/03/19 07:43:19 TRACE BlockInfoManager: Task -1024 acquired read lock for broadcast_0
18/03/19 07:43:19 DEBUG BlockManager: Level for block broadcast_0 is StorageLevel(disk, memory, deserialized, 1 replicas)
18/03/19 07:43:19 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_0
18/03/19 07:43:19 DEBUG HadoopRDD: Creating new JobConf and caching it for later re-use
18/03/19 07:43:20 DEBUG FileInputFormat: Time taken to get FileStatuses: 18
18/03/19 07:43:20 INFO FileInputFormat: Total input paths to process : 1
18/03/19 07:43:20 DEBUG FileInputFormat: Total # of splits generated by getSplits: 8, TimeTaken: 30
18/03/19 07:43:20 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28) +++
18/03/19 07:43:20 DEBUG ClosureCleaner:  + declared fields: 3
18/03/19 07:43:20 DEBUG ClosureCleaner:      public static final long org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28.serialVersionUID
18/03/19 07:43:20 DEBUG ClosureCleaner:      private final org.apache.spark.rdd.RDD$$anonfun$take$1 org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28.$outer
18/03/19 07:43:20 DEBUG ClosureCleaner:      private final int org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28.left$1
18/03/19 07:43:20 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:20 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28.apply(java.lang.Object)
18/03/19 07:43:20 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28.apply(scala.collection.Iterator)
18/03/19 07:43:20 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:43:20 DEBUG ClosureCleaner:  + outer classes: 2
18/03/19 07:43:20 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD$$anonfun$take$1
18/03/19 07:43:20 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD
18/03/19 07:43:20 DEBUG ClosureCleaner:  + outer objects: 2
18/03/19 07:43:20 DEBUG ClosureCleaner:      <function0>
18/03/19 07:43:20 DEBUG ClosureCleaner:      MapPartitionsRDD[3] at map at SBMJ_GB.scala:26
18/03/19 07:43:20 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:43:20 DEBUG ClosureCleaner:  + fields accessed by starting closure: 4
18/03/19 07:43:20 DEBUG ClosureCleaner:      (class java.lang.Object,Set())
18/03/19 07:43:20 DEBUG ClosureCleaner:      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
18/03/19 07:43:20 DEBUG ClosureCleaner:      (class scala.runtime.AbstractFunction0,Set())
18/03/19 07:43:20 DEBUG ClosureCleaner:      (class org.apache.spark.rdd.RDD$$anonfun$take$1,Set($outer))
18/03/19 07:43:20 DEBUG ClosureCleaner:  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[3] at map at SBMJ_GB.scala:26)
18/03/19 07:43:20 DEBUG ClosureCleaner:  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$take$1
18/03/19 07:43:20 DEBUG ClosureCleaner:  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$take$1)
18/03/19 07:43:20 DEBUG ClosureCleaner: +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$take$1) +++
18/03/19 07:43:20 DEBUG ClosureCleaner:  + declared fields: 3
18/03/19 07:43:20 DEBUG ClosureCleaner:      public static final long org.apache.spark.rdd.RDD$$anonfun$take$1.serialVersionUID
18/03/19 07:43:20 DEBUG ClosureCleaner:      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$take$1.$outer
18/03/19 07:43:20 DEBUG ClosureCleaner:      public final int org.apache.spark.rdd.RDD$$anonfun$take$1.num$2
18/03/19 07:43:20 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:20 DEBUG ClosureCleaner:      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$take$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
18/03/19 07:43:20 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$take$1.apply()
18/03/19 07:43:20 DEBUG ClosureCleaner:  + inner classes: 2
18/03/19 07:43:20 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$apply$49
18/03/19 07:43:20 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28
18/03/19 07:43:20 DEBUG ClosureCleaner:  + outer classes: 1
18/03/19 07:43:20 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD
18/03/19 07:43:20 DEBUG ClosureCleaner:  + outer objects: 1
18/03/19 07:43:20 DEBUG ClosureCleaner:      MapPartitionsRDD[3] at map at SBMJ_GB.scala:26
18/03/19 07:43:20 DEBUG ClosureCleaner:  + fields accessed by starting closure: 4
18/03/19 07:43:20 DEBUG ClosureCleaner:      (class java.lang.Object,Set())
18/03/19 07:43:20 DEBUG ClosureCleaner:      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
18/03/19 07:43:20 DEBUG ClosureCleaner:      (class scala.runtime.AbstractFunction0,Set())
18/03/19 07:43:20 DEBUG ClosureCleaner:      (class org.apache.spark.rdd.RDD$$anonfun$take$1,Set($outer))
18/03/19 07:43:20 DEBUG ClosureCleaner:  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[3] at map at SBMJ_GB.scala:26)
18/03/19 07:43:20 DEBUG ClosureCleaner:  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$take$1) is now cleaned +++
18/03/19 07:43:20 DEBUG ClosureCleaner:  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28) is now cleaned +++
18/03/19 07:43:20 DEBUG ClosureCleaner: +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
18/03/19 07:43:20 DEBUG ClosureCleaner:  + declared fields: 2
18/03/19 07:43:20 DEBUG ClosureCleaner:      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
18/03/19 07:43:20 DEBUG ClosureCleaner:      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
18/03/19 07:43:20 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:20 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
18/03/19 07:43:20 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
18/03/19 07:43:20 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:43:20 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:43:20 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:43:20 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:43:20 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:43:20 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:43:20 DEBUG ClosureCleaner:  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
18/03/19 07:43:20 INFO SparkContext: Starting job: take at SBMJ_GB.scala:30
18/03/19 07:43:20 INFO DAGScheduler: Got job 0 (take at SBMJ_GB.scala:30) with 1 output partitions
18/03/19 07:43:20 INFO DAGScheduler: Final stage: ResultStage 0 (take at SBMJ_GB.scala:30)
18/03/19 07:43:20 INFO DAGScheduler: Parents of final stage: List()
18/03/19 07:43:20 INFO DAGScheduler: Missing parents: List()
18/03/19 07:43:20 DEBUG DAGScheduler: submitStage(ResultStage 0)
18/03/19 07:43:20 DEBUG DAGScheduler: missing: List()
18/03/19 07:43:20 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at map at SBMJ_GB.scala:26), which has no missing parents
18/03/19 07:43:20 DEBUG DAGScheduler: submitMissingTasks(ResultStage 0)
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 trying to put broadcast_1
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_1
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_1
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_1
18/03/19 07:43:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 852.4 MB)
18/03/19 07:43:20 DEBUG BlockManager: Put block broadcast_1 locally took  16 ms
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_1
18/03/19 07:43:20 DEBUG BlockManager: Putting block broadcast_1 without replication took  16 ms
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 trying to put broadcast_1_piece0
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_1_piece0
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_1_piece0
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_1_piece0
18/03/19 07:43:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 852.4 MB)
18/03/19 07:43:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.8.100:40919 (size: 2.1 KB, free: 852.6 MB)
18/03/19 07:43:20 DEBUG BlockManagerMaster: Updated info of block broadcast_1_piece0
18/03/19 07:43:20 DEBUG BlockManager: Told master about block broadcast_1_piece0
18/03/19 07:43:20 DEBUG BlockManager: Put block broadcast_1_piece0 locally took  5 ms
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_1_piece0
18/03/19 07:43:20 DEBUG BlockManager: Putting block broadcast_1_piece0 without replication took  6 ms
18/03/19 07:43:20 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1039
18/03/19 07:43:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at map at SBMJ_GB.scala:26) (first 15 tasks are for partitions Vector(0))
18/03/19 07:43:20 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/03/19 07:43:20 DEBUG TaskSetManager: Epoch for TaskSet 0.0: 0
18/03/19 07:43:20 DEBUG TaskSetManager: Valid locality levels for TaskSet 0.0: NO_PREF, ANY
18/03/19 07:43:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0.0, runningTasks: 0
18/03/19 07:43:20 DEBUG TaskSetManager: Valid locality levels for TaskSet 0.0: NO_PREF, ANY
18/03/19 07:43:20 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7866 bytes)
18/03/19 07:43:20 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
18/03/19 07:43:20 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/03/19 07:43:20 DEBUG BlockManager: Getting local block broadcast_1
18/03/19 07:43:20 TRACE BlockInfoManager: Task 0 trying to acquire read lock for broadcast_1
18/03/19 07:43:20 TRACE BlockInfoManager: Task 0 acquired read lock for broadcast_1
18/03/19 07:43:20 DEBUG BlockManager: Level for block broadcast_1 is StorageLevel(disk, memory, deserialized, 1 replicas)
18/03/19 07:43:20 INFO HadoopRDD: Input split: file:/Data/user.csv:0+33554432
18/03/19 07:43:20 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:20 TRACE BlockInfoManager: Task 0 releasing lock for broadcast_1
18/03/19 07:43:20 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 991 bytes result sent to driver
18/03/19 07:43:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0.0, runningTasks: 0
18/03/19 07:43:20 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 222 ms on localhost (executor driver) (1/1)
18/03/19 07:43:20 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/03/19 07:43:20 INFO DAGScheduler: ResultStage 0 (take at SBMJ_GB.scala:30) finished in 0.356 s
18/03/19 07:43:20 DEBUG DAGScheduler: After removal of stage 0, remaining stages = 0
18/03/19 07:43:20 INFO DAGScheduler: Job 0 finished: take at SBMJ_GB.scala:30, took 0.491263 s
18/03/19 07:43:20 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
18/03/19 07:43:20 DEBUG ClosureCleaner:  + declared fields: 1
18/03/19 07:43:20 DEBUG ClosureCleaner:      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
18/03/19 07:43:20 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:20 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
18/03/19 07:43:20 DEBUG ClosureCleaner:      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
18/03/19 07:43:20 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:43:20 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:43:20 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:43:20 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
1,Willie Pacocha
18/03/19 07:43:20 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
2,Dangelo Predovic
3,Kattie Johnson
4,Bobby Beer
18/03/19 07:43:20 DEBUG ClosureCleaner:  + there are no enclosing objects!
5,Esmeralda Jacobi
6,Raven Goyette
7,Timmy Stoltenberg
8,Kenna Jones
9,Shaylee Ankunding
10,Quincy Breitenberg
18/03/19 07:43:20 DEBUG ClosureCleaner:  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
18/03/19 07:43:20 DEBUG ClosureCleaner: +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
18/03/19 07:43:20 DEBUG ClosureCleaner:  + declared fields: 2
18/03/19 07:43:20 DEBUG ClosureCleaner:      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
18/03/19 07:43:20 DEBUG ClosureCleaner:      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
18/03/19 07:43:20 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:20 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
18/03/19 07:43:20 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
18/03/19 07:43:20 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:43:20 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:43:20 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:43:20 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:43:20 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:43:20 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:43:20 DEBUG ClosureCleaner:  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
18/03/19 07:43:20 INFO SparkContext: Starting job: count at SBMJ_GB.scala:31
18/03/19 07:43:20 INFO DAGScheduler: Got job 1 (count at SBMJ_GB.scala:31) with 8 output partitions
18/03/19 07:43:20 INFO DAGScheduler: Final stage: ResultStage 1 (count at SBMJ_GB.scala:31)
18/03/19 07:43:20 INFO DAGScheduler: Parents of final stage: List()
18/03/19 07:43:20 INFO DAGScheduler: Missing parents: List()
18/03/19 07:43:20 DEBUG DAGScheduler: submitStage(ResultStage 1)
18/03/19 07:43:20 DEBUG DAGScheduler: missing: List()
18/03/19 07:43:20 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[3] at map at SBMJ_GB.scala:26), which has no missing parents
18/03/19 07:43:20 DEBUG DAGScheduler: submitMissingTasks(ResultStage 1)
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 trying to put broadcast_2
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_2
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_2
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_2
18/03/19 07:43:20 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 3.4 KB, free 852.4 MB)
18/03/19 07:43:20 DEBUG BlockManager: Put block broadcast_2 locally took  2 ms
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_2
18/03/19 07:43:20 DEBUG BlockManager: Putting block broadcast_2 without replication took  2 ms
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 trying to put broadcast_2_piece0
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_2_piece0
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_2_piece0
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_2_piece0
18/03/19 07:43:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2042.0 B, free 852.4 MB)
18/03/19 07:43:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.8.100:40919 (size: 2042.0 B, free: 852.6 MB)
18/03/19 07:43:20 DEBUG BlockManagerMaster: Updated info of block broadcast_2_piece0
18/03/19 07:43:20 DEBUG BlockManager: Told master about block broadcast_2_piece0
18/03/19 07:43:20 DEBUG BlockManager: Put block broadcast_2_piece0 locally took  2 ms
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_2_piece0
18/03/19 07:43:20 DEBUG BlockManager: Putting block broadcast_2_piece0 without replication took  3 ms
18/03/19 07:43:20 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1039
18/03/19 07:43:20 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at map at SBMJ_GB.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
18/03/19 07:43:20 INFO TaskSchedulerImpl: Adding task set 1.0 with 8 tasks
18/03/19 07:43:20 DEBUG TaskSetManager: Epoch for TaskSet 1.0: 0
18/03/19 07:43:20 DEBUG TaskSetManager: Valid locality levels for TaskSet 1.0: NO_PREF, ANY
18/03/19 07:43:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_1.0, runningTasks: 0
18/03/19 07:43:20 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7866 bytes)
18/03/19 07:43:20 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 7866 bytes)
18/03/19 07:43:20 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/03/19 07:43:20 DEBUG BlockManager: Getting local block broadcast_2
18/03/19 07:43:20 TRACE BlockInfoManager: Task 1 trying to acquire read lock for broadcast_2
18/03/19 07:43:20 TRACE BlockInfoManager: Task 1 acquired read lock for broadcast_2
18/03/19 07:43:20 DEBUG BlockManager: Level for block broadcast_2 is StorageLevel(disk, memory, deserialized, 1 replicas)
18/03/19 07:43:20 INFO HadoopRDD: Input split: file:/Data/user.csv:0+33554432
18/03/19 07:43:20 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:20 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
18/03/19 07:43:20 INFO HadoopRDD: Input split: file:/Data/user.csv:33554432+33554432
18/03/19 07:43:20 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:20 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(1)
18/03/19 07:43:20 DEBUG ContextCleaner: Cleaning broadcast 1
18/03/19 07:43:20 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 1
18/03/19 07:43:20 DEBUG BlockManagerSlaveEndpoint: removing broadcast 1
18/03/19 07:43:20 DEBUG BlockManager: Removing broadcast 1
18/03/19 07:43:20 DEBUG BlockManager: Removing block broadcast_1
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_1
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_1
18/03/19 07:43:20 DEBUG MemoryStore: Block broadcast_1 of size 3664 dropped from memory (free 893767747)
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 trying to remove block broadcast_1
18/03/19 07:43:20 DEBUG BlockManager: Removing block broadcast_1_piece0
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_1_piece0
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_1_piece0
18/03/19 07:43:20 DEBUG MemoryStore: Block broadcast_1_piece0 of size 2116 dropped from memory (free 893769863)
18/03/19 07:43:20 TRACE BlockInfoManager: Task -1024 trying to remove block broadcast_1_piece0
18/03/19 07:43:20 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.8.100:40919 in memory (size: 2.1 KB, free: 852.6 MB)
18/03/19 07:43:20 DEBUG BlockManagerMaster: Updated info of block broadcast_1_piece0
18/03/19 07:43:20 DEBUG BlockManager: Told master about block broadcast_1_piece0
18/03/19 07:43:21 DEBUG BlockManagerSlaveEndpoint: Done removing broadcast 1, response is 0
18/03/19 07:43:21 DEBUG BlockManagerSlaveEndpoint: Sent response: 0 to 192.168.8.100:45639
18/03/19 07:43:21 DEBUG ContextCleaner: Cleaned broadcast 1
18/03/19 07:43:21 TRACE BlockInfoManager: Task 1 releasing lock for broadcast_2
18/03/19 07:43:21 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 875 bytes result sent to driver
18/03/19 07:43:21 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_1.0, runningTasks: 1
18/03/19 07:43:21 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 7866 bytes)
18/03/19 07:43:21 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 918 bytes result sent to driver
18/03/19 07:43:21 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
18/03/19 07:43:21 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_1.0, runningTasks: 1
18/03/19 07:43:21 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 7866 bytes)
18/03/19 07:43:21 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
18/03/19 07:43:21 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1290 ms on localhost (executor driver) (1/8)
18/03/19 07:43:21 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1294 ms on localhost (executor driver) (2/8)
18/03/19 07:43:21 INFO HadoopRDD: Input split: file:/Data/user.csv:100663296+33554432
18/03/19 07:43:21 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:21 INFO HadoopRDD: Input split: file:/Data/user.csv:67108864+33554432
18/03/19 07:43:21 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:22 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 875 bytes result sent to driver
18/03/19 07:43:22 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_1.0, runningTasks: 1
18/03/19 07:43:22 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5, localhost, executor driver, partition 4, PROCESS_LOCAL, 7866 bytes)
18/03/19 07:43:22 INFO Executor: Running task 4.0 in stage 1.0 (TID 5)
18/03/19 07:43:22 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 568 ms on localhost (executor driver) (3/8)
18/03/19 07:43:22 INFO HadoopRDD: Input split: file:/Data/user.csv:134217728+33554432
18/03/19 07:43:22 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:22 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 875 bytes result sent to driver
18/03/19 07:43:22 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_1.0, runningTasks: 1
18/03/19 07:43:22 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6, localhost, executor driver, partition 5, PROCESS_LOCAL, 7866 bytes)
18/03/19 07:43:22 INFO Executor: Running task 5.0 in stage 1.0 (TID 6)
18/03/19 07:43:22 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 615 ms on localhost (executor driver) (4/8)
18/03/19 07:43:22 INFO HadoopRDD: Input split: file:/Data/user.csv:167772160+33554432
18/03/19 07:43:22 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:22 INFO Executor: Finished task 4.0 in stage 1.0 (TID 5). 875 bytes result sent to driver
18/03/19 07:43:22 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_1.0, runningTasks: 1
18/03/19 07:43:22 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7, localhost, executor driver, partition 6, PROCESS_LOCAL, 7866 bytes)
18/03/19 07:43:22 INFO Executor: Running task 6.0 in stage 1.0 (TID 7)
18/03/19 07:43:22 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 454 ms on localhost (executor driver) (5/8)
18/03/19 07:43:23 INFO HadoopRDD: Input split: file:/Data/user.csv:201326592+33554432
18/03/19 07:43:23 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:23 INFO Executor: Finished task 5.0 in stage 1.0 (TID 6). 875 bytes result sent to driver
18/03/19 07:43:23 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_1.0, runningTasks: 1
18/03/19 07:43:23 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8, localhost, executor driver, partition 7, PROCESS_LOCAL, 7866 bytes)
18/03/19 07:43:23 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 464 ms on localhost (executor driver) (6/8)
18/03/19 07:43:23 INFO Executor: Running task 7.0 in stage 1.0 (TID 8)
18/03/19 07:43:23 INFO HadoopRDD: Input split: file:/Data/user.csv:234881024+21712488
18/03/19 07:43:23 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:23 INFO Executor: Finished task 7.0 in stage 1.0 (TID 8). 875 bytes result sent to driver
18/03/19 07:43:23 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_1.0, runningTasks: 1
18/03/19 07:43:23 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
18/03/19 07:43:23 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 311 ms on localhost (executor driver) (7/8)
18/03/19 07:43:23 INFO Executor: Finished task 6.0 in stage 1.0 (TID 7). 875 bytes result sent to driver
18/03/19 07:43:23 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_1.0, runningTasks: 0
18/03/19 07:43:23 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 543 ms on localhost (executor driver) (8/8)
18/03/19 07:43:23 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/03/19 07:43:23 INFO DAGScheduler: ResultStage 1 (count at SBMJ_GB.scala:31) finished in 2.866 s
1500000
18/03/19 07:43:23 DEBUG DAGScheduler: After removal of stage 1, remaining stages = 0
18/03/19 07:43:23 INFO DAGScheduler: Job 1 finished: count at SBMJ_GB.scala:31, took 2.877226 s
18/03/19 07:43:23 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (Joins.SBMJ_GB$$anonfun$3) +++
18/03/19 07:43:23 DEBUG ClosureCleaner:  + declared fields: 1
18/03/19 07:43:23 DEBUG ClosureCleaner:      public static final long Joins.SBMJ_GB$$anonfun$3.serialVersionUID
18/03/19 07:43:23 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:23 DEBUG ClosureCleaner:      public final java.lang.Object Joins.SBMJ_GB$$anonfun$3.apply(java.lang.Object)
18/03/19 07:43:23 DEBUG ClosureCleaner:      public final scala.collection.mutable.ArrayOps Joins.SBMJ_GB$$anonfun$3.apply(java.lang.String)
18/03/19 07:43:23 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:43:23 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:43:23 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:43:23 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:43:23 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:43:23 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:43:23 DEBUG ClosureCleaner:  +++ closure <function1> (Joins.SBMJ_GB$$anonfun$3) is now cleaned +++
18/03/19 07:43:23 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (Joins.SBMJ_GB$$anonfun$4) +++
18/03/19 07:43:23 DEBUG ClosureCleaner:  + declared fields: 1
18/03/19 07:43:23 DEBUG ClosureCleaner:      public static final long Joins.SBMJ_GB$$anonfun$4.serialVersionUID
18/03/19 07:43:23 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:23 DEBUG ClosureCleaner:      public final java.lang.Object Joins.SBMJ_GB$$anonfun$4.apply(java.lang.Object)
18/03/19 07:43:23 DEBUG ClosureCleaner:      public final scala.Tuple2 Joins.SBMJ_GB$$anonfun$4.apply(java.lang.String)
18/03/19 07:43:23 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:43:23 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:43:23 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:43:23 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:43:23 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:43:23 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:43:23 DEBUG ClosureCleaner:  +++ closure <function1> (Joins.SBMJ_GB$$anonfun$4) is now cleaned +++
18/03/19 07:43:23 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28) +++
18/03/19 07:43:23 DEBUG ClosureCleaner:  + declared fields: 3
18/03/19 07:43:23 DEBUG ClosureCleaner:      public static final long org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28.serialVersionUID
18/03/19 07:43:23 DEBUG ClosureCleaner:      private final org.apache.spark.rdd.RDD$$anonfun$take$1 org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28.$outer
18/03/19 07:43:23 DEBUG ClosureCleaner:      private final int org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28.left$1
18/03/19 07:43:23 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:23 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28.apply(java.lang.Object)
18/03/19 07:43:23 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28.apply(scala.collection.Iterator)
18/03/19 07:43:23 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:43:23 DEBUG ClosureCleaner:  + outer classes: 2
18/03/19 07:43:23 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD$$anonfun$take$1
18/03/19 07:43:23 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD
18/03/19 07:43:23 DEBUG ClosureCleaner:  + outer objects: 2
18/03/19 07:43:23 DEBUG ClosureCleaner:      <function0>
18/03/19 07:43:23 DEBUG ClosureCleaner:      MapPartitionsRDD[5] at map at SBMJ_GB.scala:33
18/03/19 07:43:23 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:43:23 DEBUG ClosureCleaner:  + fields accessed by starting closure: 4
18/03/19 07:43:23 DEBUG ClosureCleaner:      (class java.lang.Object,Set())
18/03/19 07:43:23 DEBUG ClosureCleaner:      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
18/03/19 07:43:23 DEBUG ClosureCleaner:      (class scala.runtime.AbstractFunction0,Set())
18/03/19 07:43:23 DEBUG ClosureCleaner:      (class org.apache.spark.rdd.RDD$$anonfun$take$1,Set($outer))
18/03/19 07:43:23 DEBUG ClosureCleaner:  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[5] at map at SBMJ_GB.scala:33)
18/03/19 07:43:23 DEBUG ClosureCleaner:  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$take$1
18/03/19 07:43:23 DEBUG ClosureCleaner:  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$take$1)
18/03/19 07:43:23 DEBUG ClosureCleaner: +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$take$1) +++
18/03/19 07:43:23 DEBUG ClosureCleaner:  + declared fields: 3
18/03/19 07:43:23 DEBUG ClosureCleaner:      public static final long org.apache.spark.rdd.RDD$$anonfun$take$1.serialVersionUID
18/03/19 07:43:23 DEBUG ClosureCleaner:      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$take$1.$outer
18/03/19 07:43:23 DEBUG ClosureCleaner:      public final int org.apache.spark.rdd.RDD$$anonfun$take$1.num$2
18/03/19 07:43:23 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:23 DEBUG ClosureCleaner:      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$take$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
18/03/19 07:43:23 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$take$1.apply()
18/03/19 07:43:23 DEBUG ClosureCleaner:  + inner classes: 2
18/03/19 07:43:23 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$apply$49
18/03/19 07:43:23 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28
18/03/19 07:43:23 DEBUG ClosureCleaner:  + outer classes: 1
18/03/19 07:43:23 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD
18/03/19 07:43:23 DEBUG ClosureCleaner:  + outer objects: 1
18/03/19 07:43:23 DEBUG ClosureCleaner:      MapPartitionsRDD[5] at map at SBMJ_GB.scala:33
18/03/19 07:43:23 DEBUG ClosureCleaner:  + fields accessed by starting closure: 4
18/03/19 07:43:23 DEBUG ClosureCleaner:      (class java.lang.Object,Set())
18/03/19 07:43:23 DEBUG ClosureCleaner:      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
18/03/19 07:43:23 DEBUG ClosureCleaner:      (class scala.runtime.AbstractFunction0,Set())
18/03/19 07:43:23 DEBUG ClosureCleaner:      (class org.apache.spark.rdd.RDD$$anonfun$take$1,Set($outer))
18/03/19 07:43:23 DEBUG ClosureCleaner:  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[5] at map at SBMJ_GB.scala:33)
18/03/19 07:43:23 DEBUG ClosureCleaner:  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$take$1) is now cleaned +++
18/03/19 07:43:23 DEBUG ClosureCleaner:  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28) is now cleaned +++
18/03/19 07:43:23 DEBUG ClosureCleaner: +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
18/03/19 07:43:23 DEBUG ClosureCleaner:  + declared fields: 2
18/03/19 07:43:23 DEBUG ClosureCleaner:      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
18/03/19 07:43:23 DEBUG ClosureCleaner:      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
18/03/19 07:43:23 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:23 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
18/03/19 07:43:23 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
18/03/19 07:43:23 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:43:23 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:43:23 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:43:23 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:43:23 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:43:23 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:43:23 DEBUG ClosureCleaner:  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
18/03/19 07:43:23 INFO SparkContext: Starting job: take at SBMJ_GB.scala:34
18/03/19 07:43:23 INFO DAGScheduler: Got job 2 (take at SBMJ_GB.scala:34) with 1 output partitions
18/03/19 07:43:23 INFO DAGScheduler: Final stage: ResultStage 2 (take at SBMJ_GB.scala:34)
18/03/19 07:43:23 INFO DAGScheduler: Parents of final stage: List()
18/03/19 07:43:23 INFO DAGScheduler: Missing parents: List()
18/03/19 07:43:23 DEBUG DAGScheduler: submitStage(ResultStage 2)
18/03/19 07:43:23 DEBUG DAGScheduler: missing: List()
18/03/19 07:43:23 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[5] at map at SBMJ_GB.scala:33), which has no missing parents
18/03/19 07:43:23 DEBUG DAGScheduler: submitMissingTasks(ResultStage 2)
18/03/19 07:43:23 TRACE BlockInfoManager: Task -1024 trying to put broadcast_3
18/03/19 07:43:23 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_3
18/03/19 07:43:23 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_3
18/03/19 07:43:23 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_3
18/03/19 07:43:23 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 3.9 KB, free 852.4 MB)
18/03/19 07:43:23 DEBUG BlockManager: Put block broadcast_3 locally took  2 ms
18/03/19 07:43:23 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_3
18/03/19 07:43:23 DEBUG BlockManager: Putting block broadcast_3 without replication took  3 ms
18/03/19 07:43:23 TRACE BlockInfoManager: Task -1024 trying to put broadcast_3_piece0
18/03/19 07:43:23 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_3_piece0
18/03/19 07:43:23 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_3_piece0
18/03/19 07:43:23 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_3_piece0
18/03/19 07:43:23 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.2 KB, free 852.4 MB)
18/03/19 07:43:23 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.8.100:40919 (size: 2.2 KB, free: 852.6 MB)
18/03/19 07:43:23 DEBUG BlockManagerMaster: Updated info of block broadcast_3_piece0
18/03/19 07:43:23 DEBUG BlockManager: Told master about block broadcast_3_piece0
18/03/19 07:43:23 DEBUG BlockManager: Put block broadcast_3_piece0 locally took  4 ms
18/03/19 07:43:23 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_3_piece0
18/03/19 07:43:23 DEBUG BlockManager: Putting block broadcast_3_piece0 without replication took  4 ms
18/03/19 07:43:23 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1039
18/03/19 07:43:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at map at SBMJ_GB.scala:33) (first 15 tasks are for partitions Vector(0))
18/03/19 07:43:23 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
18/03/19 07:43:23 DEBUG TaskSetManager: Epoch for TaskSet 2.0: 0
18/03/19 07:43:23 DEBUG TaskSetManager: Valid locality levels for TaskSet 2.0: NO_PREF, ANY
18/03/19 07:43:23 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_2.0, runningTasks: 0
18/03/19 07:43:23 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 7866 bytes)
18/03/19 07:43:23 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
18/03/19 07:43:23 INFO Executor: Running task 0.0 in stage 2.0 (TID 9)
18/03/19 07:43:23 DEBUG BlockManager: Getting local block broadcast_3
18/03/19 07:43:23 TRACE BlockInfoManager: Task 9 trying to acquire read lock for broadcast_3
18/03/19 07:43:23 TRACE BlockInfoManager: Task 9 acquired read lock for broadcast_3
18/03/19 07:43:23 DEBUG BlockManager: Level for block broadcast_3 is StorageLevel(disk, memory, deserialized, 1 replicas)
18/03/19 07:43:23 INFO HadoopRDD: Input split: file:/Data/user.csv:0+33554432
18/03/19 07:43:23 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:23 TRACE BlockInfoManager: Task 9 releasing lock for broadcast_3
18/03/19 07:43:23 INFO Executor: Finished task 0.0 in stage 2.0 (TID 9). 1172 bytes result sent to driver
18/03/19 07:43:23 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_2.0, runningTasks: 0
18/03/19 07:43:23 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 9) in 11 ms on localhost (executor driver) (1/1)
18/03/19 07:43:23 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/03/19 07:43:23 INFO DAGScheduler: ResultStage 2 (take at SBMJ_GB.scala:34) finished in 0.029 s
18/03/19 07:43:23 DEBUG DAGScheduler: After removal of stage 2, remaining stages = 0
18/03/19 07:43:23 INFO DAGScheduler: Job 2 finished: take at SBMJ_GB.scala:34, took 0.034974 s
(1,Willie Pacocha)
(2,Dangelo Predovic)
(3,Kattie Johnson)
(4,Bobby Beer)
(5,Esmeralda Jacobi)
(6,Raven Goyette)
(7,Timmy Stoltenberg)
(8,Kenna Jones)
(9,Shaylee Ankunding)
(10,Quincy Breitenberg)
18/03/19 07:43:23 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
18/03/19 07:43:23 DEBUG ClosureCleaner:  + declared fields: 1
18/03/19 07:43:23 DEBUG ClosureCleaner:      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
18/03/19 07:43:23 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:23 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
18/03/19 07:43:23 DEBUG ClosureCleaner:      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
18/03/19 07:43:23 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:43:23 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:43:23 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:43:23 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:43:23 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:43:23 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:43:23 DEBUG ClosureCleaner:  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
18/03/19 07:43:23 DEBUG ClosureCleaner: +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
18/03/19 07:43:23 DEBUG ClosureCleaner:  + declared fields: 2
18/03/19 07:43:23 DEBUG ClosureCleaner:      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
18/03/19 07:43:23 DEBUG ClosureCleaner:      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
18/03/19 07:43:23 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:23 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
18/03/19 07:43:23 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
18/03/19 07:43:23 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:43:23 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:43:23 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:43:23 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:43:23 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:43:23 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:43:23 DEBUG ClosureCleaner:  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
18/03/19 07:43:23 INFO SparkContext: Starting job: count at SBMJ_GB.scala:35
18/03/19 07:43:23 INFO DAGScheduler: Got job 3 (count at SBMJ_GB.scala:35) with 8 output partitions
18/03/19 07:43:23 INFO DAGScheduler: Final stage: ResultStage 3 (count at SBMJ_GB.scala:35)
18/03/19 07:43:23 INFO DAGScheduler: Parents of final stage: List()
18/03/19 07:43:23 INFO DAGScheduler: Missing parents: List()
18/03/19 07:43:23 DEBUG DAGScheduler: submitStage(ResultStage 3)
18/03/19 07:43:23 DEBUG DAGScheduler: missing: List()
18/03/19 07:43:23 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[5] at map at SBMJ_GB.scala:33), which has no missing parents
18/03/19 07:43:23 DEBUG DAGScheduler: submitMissingTasks(ResultStage 3)
18/03/19 07:43:23 TRACE BlockInfoManager: Task -1024 trying to put broadcast_4
18/03/19 07:43:23 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_4
18/03/19 07:43:23 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_4
18/03/19 07:43:23 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_4
18/03/19 07:43:23 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 3.7 KB, free 852.4 MB)
18/03/19 07:43:23 DEBUG BlockManager: Put block broadcast_4 locally took  2 ms
18/03/19 07:43:23 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_4
18/03/19 07:43:23 DEBUG BlockManager: Putting block broadcast_4 without replication took  2 ms
18/03/19 07:43:23 TRACE BlockInfoManager: Task -1024 trying to put broadcast_4_piece0
18/03/19 07:43:23 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_4_piece0
18/03/19 07:43:23 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_4_piece0
18/03/19 07:43:23 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_4_piece0
18/03/19 07:43:23 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.1 KB, free 852.4 MB)
18/03/19 07:43:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.8.100:40919 (size: 2.1 KB, free: 852.6 MB)
18/03/19 07:43:23 DEBUG BlockManagerMaster: Updated info of block broadcast_4_piece0
18/03/19 07:43:23 DEBUG BlockManager: Told master about block broadcast_4_piece0
18/03/19 07:43:23 DEBUG BlockManager: Put block broadcast_4_piece0 locally took  3 ms
18/03/19 07:43:23 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_4_piece0
18/03/19 07:43:23 DEBUG BlockManager: Putting block broadcast_4_piece0 without replication took  3 ms
18/03/19 07:43:23 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1039
18/03/19 07:43:23 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 3 (MapPartitionsRDD[5] at map at SBMJ_GB.scala:33) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
18/03/19 07:43:23 INFO TaskSchedulerImpl: Adding task set 3.0 with 8 tasks
18/03/19 07:43:23 DEBUG TaskSetManager: Epoch for TaskSet 3.0: 0
18/03/19 07:43:23 DEBUG TaskSetManager: Valid locality levels for TaskSet 3.0: NO_PREF, ANY
18/03/19 07:43:23 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_3.0, runningTasks: 0
18/03/19 07:43:23 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 7866 bytes)
18/03/19 07:43:23 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 11, localhost, executor driver, partition 1, PROCESS_LOCAL, 7866 bytes)
18/03/19 07:43:23 INFO Executor: Running task 0.0 in stage 3.0 (TID 10)
18/03/19 07:43:23 INFO Executor: Running task 1.0 in stage 3.0 (TID 11)
18/03/19 07:43:23 DEBUG BlockManager: Getting local block broadcast_4
18/03/19 07:43:23 TRACE BlockInfoManager: Task 10 trying to acquire read lock for broadcast_4
18/03/19 07:43:23 TRACE BlockInfoManager: Task 10 acquired read lock for broadcast_4
18/03/19 07:43:23 DEBUG BlockManager: Level for block broadcast_4 is StorageLevel(disk, memory, deserialized, 1 replicas)
18/03/19 07:43:23 INFO HadoopRDD: Input split: file:/Data/user.csv:33554432+33554432
18/03/19 07:43:23 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:23 INFO HadoopRDD: Input split: file:/Data/user.csv:0+33554432
18/03/19 07:43:23 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(3)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning broadcast 3
18/03/19 07:43:24 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 3
18/03/19 07:43:24 DEBUG BlockManagerSlaveEndpoint: removing broadcast 3
18/03/19 07:43:24 DEBUG BlockManager: Removing broadcast 3
18/03/19 07:43:24 DEBUG BlockManager: Removing block broadcast_3_piece0
18/03/19 07:43:24 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_3_piece0
18/03/19 07:43:24 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_3_piece0
18/03/19 07:43:24 DEBUG MemoryStore: Block broadcast_3_piece0 of size 2209 dropped from memory (free 893759944)
18/03/19 07:43:24 TRACE BlockInfoManager: Task -1024 trying to remove block broadcast_3_piece0
18/03/19 07:43:24 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.8.100:40919 in memory (size: 2.2 KB, free: 852.6 MB)
18/03/19 07:43:24 DEBUG BlockManagerMaster: Updated info of block broadcast_3_piece0
18/03/19 07:43:24 DEBUG BlockManager: Told master about block broadcast_3_piece0
18/03/19 07:43:24 DEBUG BlockManager: Removing block broadcast_3
18/03/19 07:43:24 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_3
18/03/19 07:43:24 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_3
18/03/19 07:43:24 DEBUG MemoryStore: Block broadcast_3 of size 3976 dropped from memory (free 893763920)
18/03/19 07:43:24 TRACE BlockInfoManager: Task -1024 trying to remove block broadcast_3
18/03/19 07:43:24 DEBUG BlockManagerSlaveEndpoint: Done removing broadcast 3, response is 0
18/03/19 07:43:24 DEBUG BlockManagerSlaveEndpoint: Sent response: 0 to 192.168.8.100:45639
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaned broadcast 3
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanAccum(70)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning accumulator 70
18/03/19 07:43:24 INFO ContextCleaner: Cleaned accumulator 70
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanAccum(54)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning accumulator 54
18/03/19 07:43:24 INFO ContextCleaner: Cleaned accumulator 54
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanAccum(73)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning accumulator 73
18/03/19 07:43:24 INFO ContextCleaner: Cleaned accumulator 73
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanAccum(63)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning accumulator 63
18/03/19 07:43:24 INFO ContextCleaner: Cleaned accumulator 63
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanAccum(67)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning accumulator 67
18/03/19 07:43:24 INFO ContextCleaner: Cleaned accumulator 67
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanAccum(53)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning accumulator 53
18/03/19 07:43:24 INFO ContextCleaner: Cleaned accumulator 53
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanAccum(57)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning accumulator 57
18/03/19 07:43:24 INFO ContextCleaner: Cleaned accumulator 57
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanAccum(59)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning accumulator 59
18/03/19 07:43:24 INFO ContextCleaner: Cleaned accumulator 59
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanAccum(69)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning accumulator 69
18/03/19 07:43:24 INFO ContextCleaner: Cleaned accumulator 69
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanAccum(74)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning accumulator 74
18/03/19 07:43:24 INFO ContextCleaner: Cleaned accumulator 74
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanAccum(58)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning accumulator 58
18/03/19 07:43:24 INFO ContextCleaner: Cleaned accumulator 58
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanAccum(56)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning accumulator 56
18/03/19 07:43:24 INFO ContextCleaner: Cleaned accumulator 56
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanAccum(60)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning accumulator 60
18/03/19 07:43:24 INFO ContextCleaner: Cleaned accumulator 60
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanAccum(66)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning accumulator 66
18/03/19 07:43:24 INFO ContextCleaner: Cleaned accumulator 66
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanAccum(64)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning accumulator 64
18/03/19 07:43:24 INFO ContextCleaner: Cleaned accumulator 64
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanAccum(61)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning accumulator 61
18/03/19 07:43:24 INFO ContextCleaner: Cleaned accumulator 61
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanAccum(71)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning accumulator 71
18/03/19 07:43:24 INFO ContextCleaner: Cleaned accumulator 71
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanAccum(62)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning accumulator 62
18/03/19 07:43:24 INFO ContextCleaner: Cleaned accumulator 62
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanAccum(51)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning accumulator 51
18/03/19 07:43:24 INFO ContextCleaner: Cleaned accumulator 51
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanAccum(72)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning accumulator 72
18/03/19 07:43:24 INFO ContextCleaner: Cleaned accumulator 72
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanAccum(50)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning accumulator 50
18/03/19 07:43:24 INFO ContextCleaner: Cleaned accumulator 50
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanAccum(52)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning accumulator 52
18/03/19 07:43:24 INFO ContextCleaner: Cleaned accumulator 52
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanAccum(55)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning accumulator 55
18/03/19 07:43:24 INFO ContextCleaner: Cleaned accumulator 55
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanAccum(68)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning accumulator 68
18/03/19 07:43:24 INFO ContextCleaner: Cleaned accumulator 68
18/03/19 07:43:24 DEBUG ContextCleaner: Got cleaning task CleanAccum(65)
18/03/19 07:43:24 DEBUG ContextCleaner: Cleaning accumulator 65
18/03/19 07:43:24 INFO ContextCleaner: Cleaned accumulator 65
18/03/19 07:43:24 TRACE BlockInfoManager: Task 10 releasing lock for broadcast_4
18/03/19 07:43:24 INFO Executor: Finished task 0.0 in stage 3.0 (TID 10). 918 bytes result sent to driver
18/03/19 07:43:24 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_3.0, runningTasks: 1
18/03/19 07:43:24 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 12, localhost, executor driver, partition 2, PROCESS_LOCAL, 7866 bytes)
18/03/19 07:43:24 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 10) in 730 ms on localhost (executor driver) (1/8)
18/03/19 07:43:24 INFO Executor: Running task 2.0 in stage 3.0 (TID 12)
18/03/19 07:43:24 INFO Executor: Finished task 1.0 in stage 3.0 (TID 11). 875 bytes result sent to driver
18/03/19 07:43:24 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_3.0, runningTasks: 1
18/03/19 07:43:24 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 13, localhost, executor driver, partition 3, PROCESS_LOCAL, 7866 bytes)
18/03/19 07:43:24 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 11) in 732 ms on localhost (executor driver) (2/8)
18/03/19 07:43:24 INFO Executor: Running task 3.0 in stage 3.0 (TID 13)
18/03/19 07:43:24 INFO HadoopRDD: Input split: file:/Data/user.csv:67108864+33554432
18/03/19 07:43:24 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:24 INFO HadoopRDD: Input split: file:/Data/user.csv:100663296+33554432
18/03/19 07:43:24 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:24 INFO Executor: Finished task 2.0 in stage 3.0 (TID 12). 875 bytes result sent to driver
18/03/19 07:43:24 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_3.0, runningTasks: 1
18/03/19 07:43:24 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 14, localhost, executor driver, partition 4, PROCESS_LOCAL, 7866 bytes)
18/03/19 07:43:24 INFO Executor: Running task 4.0 in stage 3.0 (TID 14)
18/03/19 07:43:24 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 12) in 571 ms on localhost (executor driver) (3/8)
18/03/19 07:43:24 INFO HadoopRDD: Input split: file:/Data/user.csv:134217728+33554432
18/03/19 07:43:24 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:24 INFO Executor: Finished task 3.0 in stage 3.0 (TID 13). 875 bytes result sent to driver
18/03/19 07:43:24 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_3.0, runningTasks: 1
18/03/19 07:43:24 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 15, localhost, executor driver, partition 5, PROCESS_LOCAL, 7866 bytes)
18/03/19 07:43:24 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 13) in 591 ms on localhost (executor driver) (4/8)
18/03/19 07:43:24 INFO Executor: Running task 5.0 in stage 3.0 (TID 15)
18/03/19 07:43:24 INFO HadoopRDD: Input split: file:/Data/user.csv:167772160+33554432
18/03/19 07:43:24 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:25 INFO Executor: Finished task 4.0 in stage 3.0 (TID 14). 875 bytes result sent to driver
18/03/19 07:43:25 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_3.0, runningTasks: 1
18/03/19 07:43:25 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 16, localhost, executor driver, partition 6, PROCESS_LOCAL, 7866 bytes)
18/03/19 07:43:25 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 14) in 556 ms on localhost (executor driver) (5/8)
18/03/19 07:43:25 INFO Executor: Running task 6.0 in stage 3.0 (TID 16)
18/03/19 07:43:25 INFO HadoopRDD: Input split: file:/Data/user.csv:201326592+33554432
18/03/19 07:43:25 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:25 INFO Executor: Finished task 5.0 in stage 3.0 (TID 15). 875 bytes result sent to driver
18/03/19 07:43:25 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_3.0, runningTasks: 1
18/03/19 07:43:25 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 17, localhost, executor driver, partition 7, PROCESS_LOCAL, 7866 bytes)
18/03/19 07:43:25 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 15) in 562 ms on localhost (executor driver) (6/8)
18/03/19 07:43:25 INFO Executor: Running task 7.0 in stage 3.0 (TID 17)
18/03/19 07:43:25 INFO HadoopRDD: Input split: file:/Data/user.csv:234881024+21712488
18/03/19 07:43:25 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:25 INFO Executor: Finished task 7.0 in stage 3.0 (TID 17). 875 bytes result sent to driver
18/03/19 07:43:25 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_3.0, runningTasks: 1
18/03/19 07:43:25 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
18/03/19 07:43:25 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 17) in 348 ms on localhost (executor driver) (7/8)
18/03/19 07:43:26 INFO Executor: Finished task 6.0 in stage 3.0 (TID 16). 875 bytes result sent to driver
18/03/19 07:43:26 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_3.0, runningTasks: 0
18/03/19 07:43:26 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 16) in 529 ms on localhost (executor driver) (8/8)
18/03/19 07:43:26 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/03/19 07:43:26 INFO DAGScheduler: ResultStage 3 (count at SBMJ_GB.scala:35) finished in 2.396 s
18/03/19 07:43:26 DEBUG DAGScheduler: After removal of stage 3, remaining stages = 0
18/03/19 07:43:26 INFO DAGScheduler: Job 3 finished: count at SBMJ_GB.scala:35, took 2.407570 s
1500000
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to put broadcast_5
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_5
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_5
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_5
18/03/19 07:43:26 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 214.5 KB, free 852.2 MB)
18/03/19 07:43:26 DEBUG BlockManager: Put block broadcast_5 locally took  13 ms
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_5
18/03/19 07:43:26 DEBUG BlockManager: Putting block broadcast_5 without replication took  13 ms
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to put broadcast_5_piece0
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_5_piece0
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_5_piece0
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_5_piece0
18/03/19 07:43:26 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.4 KB, free 852.1 MB)
18/03/19 07:43:26 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.8.100:40919 (size: 20.4 KB, free: 852.6 MB)
18/03/19 07:43:26 DEBUG BlockManagerMaster: Updated info of block broadcast_5_piece0
18/03/19 07:43:26 DEBUG BlockManager: Told master about block broadcast_5_piece0
18/03/19 07:43:26 DEBUG BlockManager: Put block broadcast_5_piece0 locally took  2 ms
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_5_piece0
18/03/19 07:43:26 DEBUG BlockManager: Putting block broadcast_5_piece0 without replication took  3 ms
18/03/19 07:43:26 INFO SparkContext: Created broadcast 5 from textFile at SBMJ_GB.scala:40
18/03/19 07:43:26 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$30) +++
18/03/19 07:43:26 DEBUG ClosureCleaner:  + declared fields: 2
18/03/19 07:43:26 DEBUG ClosureCleaner:      public static final long org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$30.serialVersionUID
18/03/19 07:43:26 DEBUG ClosureCleaner:      private final org.apache.spark.SparkContext$$anonfun$hadoopFile$1 org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$30.$outer
18/03/19 07:43:26 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:26 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$30.apply(java.lang.Object)
18/03/19 07:43:26 DEBUG ClosureCleaner:      public final void org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$30.apply(org.apache.hadoop.mapred.JobConf)
18/03/19 07:43:26 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + outer classes: 2
18/03/19 07:43:26 DEBUG ClosureCleaner:      org.apache.spark.SparkContext$$anonfun$hadoopFile$1
18/03/19 07:43:26 DEBUG ClosureCleaner:      org.apache.spark.SparkContext
18/03/19 07:43:26 DEBUG ClosureCleaner:  + outer objects: 2
18/03/19 07:43:26 DEBUG ClosureCleaner:      <function0>
18/03/19 07:43:26 DEBUG ClosureCleaner:      org.apache.spark.SparkContext@165e389b
18/03/19 07:43:26 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:43:26 DEBUG ClosureCleaner:  + fields accessed by starting closure: 4
18/03/19 07:43:26 DEBUG ClosureCleaner:      (class java.lang.Object,Set())
18/03/19 07:43:26 DEBUG ClosureCleaner:      (class org.apache.spark.SparkContext$$anonfun$hadoopFile$1,Set(path$6))
18/03/19 07:43:26 DEBUG ClosureCleaner:      (class scala.runtime.AbstractFunction0,Set())
18/03/19 07:43:26 DEBUG ClosureCleaner:      (class org.apache.spark.SparkContext,Set())
18/03/19 07:43:26 DEBUG ClosureCleaner:  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.SparkContext,org.apache.spark.SparkContext@165e389b)
18/03/19 07:43:26 DEBUG ClosureCleaner:  + cloning the object <function0> of class org.apache.spark.SparkContext$$anonfun$hadoopFile$1
18/03/19 07:43:26 DEBUG ClosureCleaner:  + cleaning cloned closure <function0> recursively (org.apache.spark.SparkContext$$anonfun$hadoopFile$1)
18/03/19 07:43:26 DEBUG ClosureCleaner: +++ Cleaning closure <function0> (org.apache.spark.SparkContext$$anonfun$hadoopFile$1) +++
18/03/19 07:43:26 DEBUG ClosureCleaner:  + declared fields: 7
18/03/19 07:43:26 DEBUG ClosureCleaner:      public static final long org.apache.spark.SparkContext$$anonfun$hadoopFile$1.serialVersionUID
18/03/19 07:43:26 DEBUG ClosureCleaner:      private final org.apache.spark.SparkContext org.apache.spark.SparkContext$$anonfun$hadoopFile$1.$outer
18/03/19 07:43:26 DEBUG ClosureCleaner:      public final java.lang.String org.apache.spark.SparkContext$$anonfun$hadoopFile$1.path$6
18/03/19 07:43:26 DEBUG ClosureCleaner:      private final java.lang.Class org.apache.spark.SparkContext$$anonfun$hadoopFile$1.inputFormatClass$1
18/03/19 07:43:26 DEBUG ClosureCleaner:      private final java.lang.Class org.apache.spark.SparkContext$$anonfun$hadoopFile$1.keyClass$1
18/03/19 07:43:26 DEBUG ClosureCleaner:      private final java.lang.Class org.apache.spark.SparkContext$$anonfun$hadoopFile$1.valueClass$1
18/03/19 07:43:26 DEBUG ClosureCleaner:      private final int org.apache.spark.SparkContext$$anonfun$hadoopFile$1.minPartitions$3
18/03/19 07:43:26 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:26 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$hadoopFile$1.apply()
18/03/19 07:43:26 DEBUG ClosureCleaner:      public final org.apache.spark.rdd.HadoopRDD org.apache.spark.SparkContext$$anonfun$hadoopFile$1.apply()
18/03/19 07:43:26 DEBUG ClosureCleaner:  + inner classes: 1
18/03/19 07:43:26 DEBUG ClosureCleaner:      org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$30
18/03/19 07:43:26 DEBUG ClosureCleaner:  + outer classes: 1
18/03/19 07:43:26 DEBUG ClosureCleaner:      org.apache.spark.SparkContext
18/03/19 07:43:26 DEBUG ClosureCleaner:  + outer objects: 1
18/03/19 07:43:26 DEBUG ClosureCleaner:      org.apache.spark.SparkContext@165e389b
18/03/19 07:43:26 DEBUG ClosureCleaner:  + fields accessed by starting closure: 4
18/03/19 07:43:26 DEBUG ClosureCleaner:      (class java.lang.Object,Set())
18/03/19 07:43:26 DEBUG ClosureCleaner:      (class org.apache.spark.SparkContext$$anonfun$hadoopFile$1,Set(path$6))
18/03/19 07:43:26 DEBUG ClosureCleaner:      (class scala.runtime.AbstractFunction0,Set())
18/03/19 07:43:26 DEBUG ClosureCleaner:      (class org.apache.spark.SparkContext,Set())
18/03/19 07:43:26 DEBUG ClosureCleaner:  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.SparkContext,org.apache.spark.SparkContext@165e389b)
18/03/19 07:43:26 DEBUG ClosureCleaner:  + the starting closure doesn't actually need org.apache.spark.SparkContext@165e389b, so we null it out
18/03/19 07:43:26 DEBUG ClosureCleaner:  +++ closure <function0> (org.apache.spark.SparkContext$$anonfun$hadoopFile$1) is now cleaned +++
18/03/19 07:43:26 DEBUG ClosureCleaner:  +++ closure <function1> (org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$30) is now cleaned +++
18/03/19 07:43:26 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (org.apache.spark.SparkContext$$anonfun$textFile$1$$anonfun$apply$8) +++
18/03/19 07:43:26 DEBUG ClosureCleaner:  + declared fields: 1
18/03/19 07:43:26 DEBUG ClosureCleaner:      public static final long org.apache.spark.SparkContext$$anonfun$textFile$1$$anonfun$apply$8.serialVersionUID
18/03/19 07:43:26 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:26 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$textFile$1$$anonfun$apply$8.apply(java.lang.Object)
18/03/19 07:43:26 DEBUG ClosureCleaner:      public final java.lang.String org.apache.spark.SparkContext$$anonfun$textFile$1$$anonfun$apply$8.apply(scala.Tuple2)
18/03/19 07:43:26 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:43:26 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:43:26 DEBUG ClosureCleaner:  +++ closure <function1> (org.apache.spark.SparkContext$$anonfun$textFile$1$$anonfun$apply$8) is now cleaned +++
18/03/19 07:43:26 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (Joins.SBMJ_GB$$anonfun$5) +++
18/03/19 07:43:26 DEBUG ClosureCleaner:  + declared fields: 1
18/03/19 07:43:26 DEBUG ClosureCleaner:      public static final long Joins.SBMJ_GB$$anonfun$5.serialVersionUID
18/03/19 07:43:26 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:26 DEBUG ClosureCleaner:      public final java.lang.Object Joins.SBMJ_GB$$anonfun$5.apply(java.lang.Object)
18/03/19 07:43:26 DEBUG ClosureCleaner:      public final boolean Joins.SBMJ_GB$$anonfun$5.apply(java.lang.String)
18/03/19 07:43:26 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:43:26 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:43:26 DEBUG ClosureCleaner:  +++ closure <function1> (Joins.SBMJ_GB$$anonfun$5) is now cleaned +++
18/03/19 07:43:26 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (Joins.SBMJ_GB$$anonfun$6) +++
18/03/19 07:43:26 DEBUG ClosureCleaner:  + declared fields: 1
18/03/19 07:43:26 DEBUG ClosureCleaner:      public static final long Joins.SBMJ_GB$$anonfun$6.serialVersionUID
18/03/19 07:43:26 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:26 DEBUG ClosureCleaner:      public final java.lang.Object Joins.SBMJ_GB$$anonfun$6.apply(java.lang.Object)
18/03/19 07:43:26 DEBUG ClosureCleaner:      public final java.lang.String Joins.SBMJ_GB$$anonfun$6.apply(java.lang.String)
18/03/19 07:43:26 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:43:26 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:43:26 DEBUG ClosureCleaner:  +++ closure <function1> (Joins.SBMJ_GB$$anonfun$6) is now cleaned +++
18/03/19 07:43:26 DEBUG BlockManager: Getting local block broadcast_5
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_5
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 acquired read lock for broadcast_5
18/03/19 07:43:26 DEBUG BlockManager: Level for block broadcast_5 is StorageLevel(disk, memory, deserialized, 1 replicas)
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_5
18/03/19 07:43:26 DEBUG HadoopRDD: Creating new JobConf and caching it for later re-use
18/03/19 07:43:26 DEBUG FileInputFormat: Time taken to get FileStatuses: 46
18/03/19 07:43:26 INFO FileInputFormat: Total input paths to process : 1
18/03/19 07:43:26 DEBUG FileInputFormat: Total # of splits generated by getSplits: 96, TimeTaken: 47
18/03/19 07:43:26 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28) +++
18/03/19 07:43:26 DEBUG ClosureCleaner:  + declared fields: 3
18/03/19 07:43:26 DEBUG ClosureCleaner:      public static final long org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28.serialVersionUID
18/03/19 07:43:26 DEBUG ClosureCleaner:      private final org.apache.spark.rdd.RDD$$anonfun$take$1 org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28.$outer
18/03/19 07:43:26 DEBUG ClosureCleaner:      private final int org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28.left$1
18/03/19 07:43:26 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:26 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28.apply(java.lang.Object)
18/03/19 07:43:26 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28.apply(scala.collection.Iterator)
18/03/19 07:43:26 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + outer classes: 2
18/03/19 07:43:26 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD$$anonfun$take$1
18/03/19 07:43:26 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD
18/03/19 07:43:26 DEBUG ClosureCleaner:  + outer objects: 2
18/03/19 07:43:26 DEBUG ClosureCleaner:      <function0>
18/03/19 07:43:26 DEBUG ClosureCleaner:      MapPartitionsRDD[9] at map at SBMJ_GB.scala:40
18/03/19 07:43:26 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:43:26 DEBUG ClosureCleaner:  + fields accessed by starting closure: 4
18/03/19 07:43:26 DEBUG ClosureCleaner:      (class java.lang.Object,Set())
18/03/19 07:43:26 DEBUG ClosureCleaner:      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
18/03/19 07:43:26 DEBUG ClosureCleaner:      (class scala.runtime.AbstractFunction0,Set())
18/03/19 07:43:26 DEBUG ClosureCleaner:      (class org.apache.spark.rdd.RDD$$anonfun$take$1,Set($outer))
18/03/19 07:43:26 DEBUG ClosureCleaner:  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[9] at map at SBMJ_GB.scala:40)
18/03/19 07:43:26 DEBUG ClosureCleaner:  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$take$1
18/03/19 07:43:26 DEBUG ClosureCleaner:  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$take$1)
18/03/19 07:43:26 DEBUG ClosureCleaner: +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$take$1) +++
18/03/19 07:43:26 DEBUG ClosureCleaner:  + declared fields: 3
18/03/19 07:43:26 DEBUG ClosureCleaner:      public static final long org.apache.spark.rdd.RDD$$anonfun$take$1.serialVersionUID
18/03/19 07:43:26 DEBUG ClosureCleaner:      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$take$1.$outer
18/03/19 07:43:26 DEBUG ClosureCleaner:      public final int org.apache.spark.rdd.RDD$$anonfun$take$1.num$2
18/03/19 07:43:26 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:26 DEBUG ClosureCleaner:      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$take$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
18/03/19 07:43:26 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$take$1.apply()
18/03/19 07:43:26 DEBUG ClosureCleaner:  + inner classes: 2
18/03/19 07:43:26 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$apply$49
18/03/19 07:43:26 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28
18/03/19 07:43:26 DEBUG ClosureCleaner:  + outer classes: 1
18/03/19 07:43:26 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD
18/03/19 07:43:26 DEBUG ClosureCleaner:  + outer objects: 1
18/03/19 07:43:26 DEBUG ClosureCleaner:      MapPartitionsRDD[9] at map at SBMJ_GB.scala:40
18/03/19 07:43:26 DEBUG ClosureCleaner:  + fields accessed by starting closure: 4
18/03/19 07:43:26 DEBUG ClosureCleaner:      (class java.lang.Object,Set())
18/03/19 07:43:26 DEBUG ClosureCleaner:      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
18/03/19 07:43:26 DEBUG ClosureCleaner:      (class scala.runtime.AbstractFunction0,Set())
18/03/19 07:43:26 DEBUG ClosureCleaner:      (class org.apache.spark.rdd.RDD$$anonfun$take$1,Set($outer))
18/03/19 07:43:26 DEBUG ClosureCleaner:  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[9] at map at SBMJ_GB.scala:40)
18/03/19 07:43:26 DEBUG ClosureCleaner:  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$take$1) is now cleaned +++
18/03/19 07:43:26 DEBUG ClosureCleaner:  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28) is now cleaned +++
18/03/19 07:43:26 DEBUG ClosureCleaner: +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
18/03/19 07:43:26 DEBUG ClosureCleaner:  + declared fields: 2
18/03/19 07:43:26 DEBUG ClosureCleaner:      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
18/03/19 07:43:26 DEBUG ClosureCleaner:      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
18/03/19 07:43:26 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:26 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
18/03/19 07:43:26 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
18/03/19 07:43:26 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:43:26 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:43:26 DEBUG ClosureCleaner:  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
18/03/19 07:43:26 INFO SparkContext: Starting job: take at SBMJ_GB.scala:47
18/03/19 07:43:26 INFO DAGScheduler: Got job 4 (take at SBMJ_GB.scala:47) with 1 output partitions
18/03/19 07:43:26 INFO DAGScheduler: Final stage: ResultStage 4 (take at SBMJ_GB.scala:47)
18/03/19 07:43:26 INFO DAGScheduler: Parents of final stage: List()
18/03/19 07:43:26 INFO DAGScheduler: Missing parents: List()
18/03/19 07:43:26 DEBUG DAGScheduler: submitStage(ResultStage 4)
18/03/19 07:43:26 DEBUG DAGScheduler: missing: List()
18/03/19 07:43:26 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[9] at map at SBMJ_GB.scala:40), which has no missing parents
18/03/19 07:43:26 DEBUG DAGScheduler: submitMissingTasks(ResultStage 4)
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to put broadcast_6
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_6
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_6
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_6
18/03/19 07:43:26 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 3.6 KB, free 852.1 MB)
18/03/19 07:43:26 DEBUG BlockManager: Put block broadcast_6 locally took  3 ms
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_6
18/03/19 07:43:26 DEBUG BlockManager: Putting block broadcast_6 without replication took  3 ms
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to put broadcast_6_piece0
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_6_piece0
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_6_piece0
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_6_piece0
18/03/19 07:43:26 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.1 KB, free 852.1 MB)
18/03/19 07:43:26 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.8.100:40919 (size: 2.1 KB, free: 852.6 MB)
18/03/19 07:43:26 DEBUG BlockManagerMaster: Updated info of block broadcast_6_piece0
18/03/19 07:43:26 DEBUG BlockManager: Told master about block broadcast_6_piece0
18/03/19 07:43:26 DEBUG BlockManager: Put block broadcast_6_piece0 locally took  2 ms
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_6_piece0
18/03/19 07:43:26 DEBUG BlockManager: Putting block broadcast_6_piece0 without replication took  2 ms
18/03/19 07:43:26 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1039
18/03/19 07:43:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[9] at map at SBMJ_GB.scala:40) (first 15 tasks are for partitions Vector(0))
18/03/19 07:43:26 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
18/03/19 07:43:26 DEBUG TaskSetManager: Epoch for TaskSet 4.0: 0
18/03/19 07:43:26 DEBUG TaskSetManager: Valid locality levels for TaskSet 4.0: NO_PREF, ANY
18/03/19 07:43:26 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_4.0, runningTasks: 0
18/03/19 07:43:26 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:26 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
18/03/19 07:43:26 INFO Executor: Running task 0.0 in stage 4.0 (TID 18)
18/03/19 07:43:26 DEBUG BlockManager: Getting local block broadcast_6
18/03/19 07:43:26 TRACE BlockInfoManager: Task 18 trying to acquire read lock for broadcast_6
18/03/19 07:43:26 TRACE BlockInfoManager: Task 18 acquired read lock for broadcast_6
18/03/19 07:43:26 DEBUG BlockManager: Level for block broadcast_6 is StorageLevel(disk, memory, deserialized, 1 replicas)
18/03/19 07:43:26 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:0+33554432
18/03/19 07:43:26 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:26 TRACE BlockInfoManager: Task 18 releasing lock for broadcast_6
18/03/19 07:43:26 INFO Executor: Finished task 0.0 in stage 4.0 (TID 18). 943 bytes result sent to driver
18/03/19 07:43:26 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_4.0, runningTasks: 0
18/03/19 07:43:26 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 18) in 26 ms on localhost (executor driver) (1/1)
18/03/19 07:43:26 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
783193,16758
271105,7612
1032749,10584
460028,2542
395356,12584
155355,22882
157984,21371
630380,1200
1207995,10175
836168,23472
18/03/19 07:43:26 INFO DAGScheduler: ResultStage 4 (take at SBMJ_GB.scala:47) finished in 0.043 s
18/03/19 07:43:26 DEBUG DAGScheduler: After removal of stage 4, remaining stages = 0
18/03/19 07:43:26 INFO DAGScheduler: Job 4 finished: take at SBMJ_GB.scala:47, took 0.051783 s
18/03/19 07:43:26 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
18/03/19 07:43:26 DEBUG ClosureCleaner:  + declared fields: 1
18/03/19 07:43:26 DEBUG ClosureCleaner:      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
18/03/19 07:43:26 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:26 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
18/03/19 07:43:26 DEBUG ClosureCleaner:      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
18/03/19 07:43:26 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:43:26 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:43:26 DEBUG ClosureCleaner:  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
18/03/19 07:43:26 DEBUG ClosureCleaner: +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
18/03/19 07:43:26 DEBUG ClosureCleaner:  + declared fields: 2
18/03/19 07:43:26 DEBUG ClosureCleaner:      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
18/03/19 07:43:26 DEBUG ClosureCleaner:      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
18/03/19 07:43:26 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:43:26 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
18/03/19 07:43:26 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
18/03/19 07:43:26 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:43:26 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:43:26 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:43:26 DEBUG ClosureCleaner:  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
18/03/19 07:43:26 INFO SparkContext: Starting job: count at SBMJ_GB.scala:48
18/03/19 07:43:26 INFO DAGScheduler: Got job 5 (count at SBMJ_GB.scala:48) with 96 output partitions
18/03/19 07:43:26 INFO DAGScheduler: Final stage: ResultStage 5 (count at SBMJ_GB.scala:48)
18/03/19 07:43:26 INFO DAGScheduler: Parents of final stage: List()
18/03/19 07:43:26 INFO DAGScheduler: Missing parents: List()
18/03/19 07:43:26 DEBUG DAGScheduler: submitStage(ResultStage 5)
18/03/19 07:43:26 DEBUG DAGScheduler: missing: List()
18/03/19 07:43:26 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[9] at map at SBMJ_GB.scala:40), which has no missing parents
18/03/19 07:43:26 DEBUG DAGScheduler: submitMissingTasks(ResultStage 5)
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to put broadcast_7
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_7
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_7
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_7
18/03/19 07:43:26 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 3.4 KB, free 852.1 MB)
18/03/19 07:43:26 DEBUG BlockManager: Put block broadcast_7 locally took  2 ms
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_7
18/03/19 07:43:26 DEBUG BlockManager: Putting block broadcast_7 without replication took  2 ms
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to put broadcast_7_piece0
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_7_piece0
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_7_piece0
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_7_piece0
18/03/19 07:43:26 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2034.0 B, free 852.1 MB)
18/03/19 07:43:26 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.8.100:40919 (size: 2034.0 B, free: 852.6 MB)
18/03/19 07:43:26 DEBUG BlockManagerMaster: Updated info of block broadcast_7_piece0
18/03/19 07:43:26 DEBUG BlockManager: Told master about block broadcast_7_piece0
18/03/19 07:43:26 DEBUG BlockManager: Put block broadcast_7_piece0 locally took  3 ms
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_7_piece0
18/03/19 07:43:26 DEBUG BlockManager: Putting block broadcast_7_piece0 without replication took  3 ms
18/03/19 07:43:26 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1039
18/03/19 07:43:26 INFO DAGScheduler: Submitting 96 missing tasks from ResultStage 5 (MapPartitionsRDD[9] at map at SBMJ_GB.scala:40) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
18/03/19 07:43:26 INFO TaskSchedulerImpl: Adding task set 5.0 with 96 tasks
18/03/19 07:43:26 DEBUG TaskSetManager: Epoch for TaskSet 5.0: 0
18/03/19 07:43:26 DEBUG TaskSetManager: Valid locality levels for TaskSet 5.0: NO_PREF, ANY
18/03/19 07:43:26 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 0
18/03/19 07:43:26 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:26 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 20, localhost, executor driver, partition 1, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:26 INFO Executor: Running task 0.0 in stage 5.0 (TID 19)
18/03/19 07:43:26 INFO Executor: Running task 1.0 in stage 5.0 (TID 20)
18/03/19 07:43:26 DEBUG BlockManager: Getting local block broadcast_7
18/03/19 07:43:26 TRACE BlockInfoManager: Task 19 trying to acquire read lock for broadcast_7
18/03/19 07:43:26 TRACE BlockInfoManager: Task 19 acquired read lock for broadcast_7
18/03/19 07:43:26 DEBUG BlockManager: Level for block broadcast_7 is StorageLevel(disk, memory, deserialized, 1 replicas)
18/03/19 07:43:26 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:0+33554432
18/03/19 07:43:26 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:26 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:33554432+33554432
18/03/19 07:43:26 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(87)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 87
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 87
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(97)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 97
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 97
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(124)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 124
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 124
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(94)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 94
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 94
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(90)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 90
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 90
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(88)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 88
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 88
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(96)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 96
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 96
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(123)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 123
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 123
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(122)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 122
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 122
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(107)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 107
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 107
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(93)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 93
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 93
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(82)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 82
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 82
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(83)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 83
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 83
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(79)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 79
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 79
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(101)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 101
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 101
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(91)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 91
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 91
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(84)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 84
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 84
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(75)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 75
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 75
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(4)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning broadcast 4
18/03/19 07:43:26 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 4
18/03/19 07:43:26 DEBUG BlockManagerSlaveEndpoint: removing broadcast 4
18/03/19 07:43:26 DEBUG BlockManager: Removing broadcast 4
18/03/19 07:43:26 DEBUG BlockManager: Removing block broadcast_4_piece0
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_4_piece0
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_4_piece0
18/03/19 07:43:26 DEBUG MemoryStore: Block broadcast_4_piece0 of size 2135 dropped from memory (free 893514188)
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to remove block broadcast_4_piece0
18/03/19 07:43:26 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.8.100:40919 in memory (size: 2.1 KB, free: 852.6 MB)
18/03/19 07:43:26 DEBUG BlockManagerMaster: Updated info of block broadcast_4_piece0
18/03/19 07:43:26 DEBUG BlockManager: Told master about block broadcast_4_piece0
18/03/19 07:43:26 DEBUG BlockManager: Removing block broadcast_4
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_4
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_4
18/03/19 07:43:26 DEBUG MemoryStore: Block broadcast_4 of size 3808 dropped from memory (free 893517996)
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to remove block broadcast_4
18/03/19 07:43:26 DEBUG BlockManagerSlaveEndpoint: Done removing broadcast 4, response is 0
18/03/19 07:43:26 DEBUG BlockManagerSlaveEndpoint: Sent response: 0 to 192.168.8.100:45639
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaned broadcast 4
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(98)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 98
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 98
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(120)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 120
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 120
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(121)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 121
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 121
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(80)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 80
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 80
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(76)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 76
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 76
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(95)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 95
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 95
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(100)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 100
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 100
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(106)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 106
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 106
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(113)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 113
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 113
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(78)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 78
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 78
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(104)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 104
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 104
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(110)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 110
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 110
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(118)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 118
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 118
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(117)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 117
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 117
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(6)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning broadcast 6
18/03/19 07:43:26 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 6
18/03/19 07:43:26 DEBUG BlockManagerSlaveEndpoint: removing broadcast 6
18/03/19 07:43:26 DEBUG BlockManager: Removing broadcast 6
18/03/19 07:43:26 DEBUG BlockManager: Removing block broadcast_6_piece0
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_6_piece0
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_6_piece0
18/03/19 07:43:26 DEBUG MemoryStore: Block broadcast_6_piece0 of size 2105 dropped from memory (free 893520101)
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to remove block broadcast_6_piece0
18/03/19 07:43:26 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.8.100:40919 in memory (size: 2.1 KB, free: 852.6 MB)
18/03/19 07:43:26 DEBUG BlockManagerMaster: Updated info of block broadcast_6_piece0
18/03/19 07:43:26 DEBUG BlockManager: Told master about block broadcast_6_piece0
18/03/19 07:43:26 DEBUG BlockManager: Removing block broadcast_6
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_6
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_6
18/03/19 07:43:26 DEBUG MemoryStore: Block broadcast_6 of size 3672 dropped from memory (free 893523773)
18/03/19 07:43:26 TRACE BlockInfoManager: Task -1024 trying to remove block broadcast_6
18/03/19 07:43:26 DEBUG BlockManagerSlaveEndpoint: Done removing broadcast 6, response is 0
18/03/19 07:43:26 DEBUG BlockManagerSlaveEndpoint: Sent response: 0 to 192.168.8.100:45639
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaned broadcast 6
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(105)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 105
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 105
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(85)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 85
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 85
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(119)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 119
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 119
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(81)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 81
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 81
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(92)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 92
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 92
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(99)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 99
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 99
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(115)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 115
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 115
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(116)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 116
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 116
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(89)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 89
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 89
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(103)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 103
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 103
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(102)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 102
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 102
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(108)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 108
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 108
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(112)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 112
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 112
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(77)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 77
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 77
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(114)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 114
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 114
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(109)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 109
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 109
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(111)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 111
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 111
18/03/19 07:43:26 DEBUG ContextCleaner: Got cleaning task CleanAccum(86)
18/03/19 07:43:26 DEBUG ContextCleaner: Cleaning accumulator 86
18/03/19 07:43:26 INFO ContextCleaner: Cleaned accumulator 86
18/03/19 07:43:28 INFO Executor: Finished task 1.0 in stage 5.0 (TID 20). 875 bytes result sent to driver
18/03/19 07:43:28 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:28 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 21, localhost, executor driver, partition 2, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:28 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 20) in 2453 ms on localhost (executor driver) (1/96)
18/03/19 07:43:28 INFO Executor: Running task 2.0 in stage 5.0 (TID 21)
18/03/19 07:43:28 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:67108864+33554432
18/03/19 07:43:28 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:29 TRACE BlockInfoManager: Task 19 releasing lock for broadcast_7
18/03/19 07:43:29 INFO Executor: Finished task 0.0 in stage 5.0 (TID 19). 875 bytes result sent to driver
18/03/19 07:43:29 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:29 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 22, localhost, executor driver, partition 3, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:29 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 19) in 2915 ms on localhost (executor driver) (2/96)
18/03/19 07:43:29 INFO Executor: Running task 3.0 in stage 5.0 (TID 22)
18/03/19 07:43:29 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:100663296+33554432
18/03/19 07:43:29 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:32 INFO Executor: Finished task 2.0 in stage 5.0 (TID 21). 875 bytes result sent to driver
18/03/19 07:43:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:32 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 23, localhost, executor driver, partition 4, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:32 INFO Executor: Running task 4.0 in stage 5.0 (TID 23)
18/03/19 07:43:32 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 21) in 3855 ms on localhost (executor driver) (3/96)
18/03/19 07:43:32 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:134217728+33554432
18/03/19 07:43:32 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:32 INFO Executor: Finished task 3.0 in stage 5.0 (TID 22). 875 bytes result sent to driver
18/03/19 07:43:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:32 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 24, localhost, executor driver, partition 5, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:32 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 22) in 3680 ms on localhost (executor driver) (4/96)
18/03/19 07:43:32 INFO Executor: Running task 5.0 in stage 5.0 (TID 24)
18/03/19 07:43:32 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:167772160+33554432
18/03/19 07:43:32 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:34 INFO Executor: Finished task 5.0 in stage 5.0 (TID 24). 875 bytes result sent to driver
18/03/19 07:43:34 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:34 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 25, localhost, executor driver, partition 6, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:34 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 24) in 1909 ms on localhost (executor driver) (5/96)
18/03/19 07:43:34 INFO Executor: Running task 6.0 in stage 5.0 (TID 25)
18/03/19 07:43:34 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:201326592+33554432
18/03/19 07:43:34 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:35 INFO Executor: Finished task 4.0 in stage 5.0 (TID 23). 875 bytes result sent to driver
18/03/19 07:43:35 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:35 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 26, localhost, executor driver, partition 7, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:35 INFO Executor: Running task 7.0 in stage 5.0 (TID 26)
18/03/19 07:43:35 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 23) in 2723 ms on localhost (executor driver) (6/96)
18/03/19 07:43:35 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:234881024+33554432
18/03/19 07:43:35 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:37 INFO Executor: Finished task 6.0 in stage 5.0 (TID 25). 875 bytes result sent to driver
18/03/19 07:43:37 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:37 INFO TaskSetManager: Starting task 8.0 in stage 5.0 (TID 27, localhost, executor driver, partition 8, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:37 INFO Executor: Running task 8.0 in stage 5.0 (TID 27)
18/03/19 07:43:37 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 25) in 2353 ms on localhost (executor driver) (7/96)
18/03/19 07:43:37 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:268435456+33554432
18/03/19 07:43:37 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:37 INFO Executor: Finished task 7.0 in stage 5.0 (TID 26). 875 bytes result sent to driver
18/03/19 07:43:37 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:37 INFO TaskSetManager: Starting task 9.0 in stage 5.0 (TID 28, localhost, executor driver, partition 9, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:37 INFO Executor: Running task 9.0 in stage 5.0 (TID 28)
18/03/19 07:43:37 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 26) in 2117 ms on localhost (executor driver) (8/96)
18/03/19 07:43:37 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:301989888+33554432
18/03/19 07:43:37 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:39 INFO Executor: Finished task 8.0 in stage 5.0 (TID 27). 875 bytes result sent to driver
18/03/19 07:43:39 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:39 INFO TaskSetManager: Starting task 10.0 in stage 5.0 (TID 29, localhost, executor driver, partition 10, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:39 INFO Executor: Running task 10.0 in stage 5.0 (TID 29)
18/03/19 07:43:39 INFO TaskSetManager: Finished task 8.0 in stage 5.0 (TID 27) in 2430 ms on localhost (executor driver) (9/96)
18/03/19 07:43:39 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:335544320+33554432
18/03/19 07:43:39 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:39 INFO Executor: Finished task 9.0 in stage 5.0 (TID 28). 875 bytes result sent to driver
18/03/19 07:43:39 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:39 INFO TaskSetManager: Starting task 11.0 in stage 5.0 (TID 30, localhost, executor driver, partition 11, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:39 INFO TaskSetManager: Finished task 9.0 in stage 5.0 (TID 28) in 2248 ms on localhost (executor driver) (10/96)
18/03/19 07:43:39 INFO Executor: Running task 11.0 in stage 5.0 (TID 30)
18/03/19 07:43:39 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:369098752+33554432
18/03/19 07:43:39 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:41 INFO Executor: Finished task 10.0 in stage 5.0 (TID 29). 918 bytes result sent to driver
18/03/19 07:43:41 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:41 INFO TaskSetManager: Starting task 12.0 in stage 5.0 (TID 31, localhost, executor driver, partition 12, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:41 INFO Executor: Running task 12.0 in stage 5.0 (TID 31)
18/03/19 07:43:41 INFO TaskSetManager: Finished task 10.0 in stage 5.0 (TID 29) in 2068 ms on localhost (executor driver) (11/96)
18/03/19 07:43:41 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:402653184+33554432
18/03/19 07:43:41 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:41 INFO Executor: Finished task 11.0 in stage 5.0 (TID 30). 875 bytes result sent to driver
18/03/19 07:43:41 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:41 INFO TaskSetManager: Starting task 13.0 in stage 5.0 (TID 32, localhost, executor driver, partition 13, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:41 INFO Executor: Running task 13.0 in stage 5.0 (TID 32)
18/03/19 07:43:41 INFO TaskSetManager: Finished task 11.0 in stage 5.0 (TID 30) in 2224 ms on localhost (executor driver) (12/96)
18/03/19 07:43:41 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:436207616+33554432
18/03/19 07:43:41 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:43 INFO Executor: Finished task 12.0 in stage 5.0 (TID 31). 875 bytes result sent to driver
18/03/19 07:43:43 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:43 INFO TaskSetManager: Starting task 14.0 in stage 5.0 (TID 33, localhost, executor driver, partition 14, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:43 INFO Executor: Running task 14.0 in stage 5.0 (TID 33)
18/03/19 07:43:43 INFO TaskSetManager: Finished task 12.0 in stage 5.0 (TID 31) in 2277 ms on localhost (executor driver) (13/96)
18/03/19 07:43:43 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:469762048+33554432
18/03/19 07:43:43 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:43 INFO Executor: Finished task 13.0 in stage 5.0 (TID 32). 875 bytes result sent to driver
18/03/19 07:43:44 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:44 INFO TaskSetManager: Starting task 15.0 in stage 5.0 (TID 34, localhost, executor driver, partition 15, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:44 INFO Executor: Running task 15.0 in stage 5.0 (TID 34)
18/03/19 07:43:44 INFO TaskSetManager: Finished task 13.0 in stage 5.0 (TID 32) in 2096 ms on localhost (executor driver) (14/96)
18/03/19 07:43:44 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:503316480+33554432
18/03/19 07:43:44 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:45 INFO Executor: Finished task 14.0 in stage 5.0 (TID 33). 875 bytes result sent to driver
18/03/19 07:43:45 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:45 INFO TaskSetManager: Starting task 16.0 in stage 5.0 (TID 35, localhost, executor driver, partition 16, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:45 INFO TaskSetManager: Finished task 14.0 in stage 5.0 (TID 33) in 2055 ms on localhost (executor driver) (15/96)
18/03/19 07:43:45 INFO Executor: Running task 16.0 in stage 5.0 (TID 35)
18/03/19 07:43:45 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:536870912+33554432
18/03/19 07:43:45 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:46 INFO Executor: Finished task 15.0 in stage 5.0 (TID 34). 875 bytes result sent to driver
18/03/19 07:43:46 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:46 INFO TaskSetManager: Starting task 17.0 in stage 5.0 (TID 36, localhost, executor driver, partition 17, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:46 INFO TaskSetManager: Finished task 15.0 in stage 5.0 (TID 34) in 2242 ms on localhost (executor driver) (16/96)
18/03/19 07:43:46 INFO Executor: Running task 17.0 in stage 5.0 (TID 36)
18/03/19 07:43:46 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:570425344+33554432
18/03/19 07:43:46 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:48 INFO Executor: Finished task 16.0 in stage 5.0 (TID 35). 875 bytes result sent to driver
18/03/19 07:43:48 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:48 INFO TaskSetManager: Starting task 18.0 in stage 5.0 (TID 37, localhost, executor driver, partition 18, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:48 INFO Executor: Running task 18.0 in stage 5.0 (TID 37)
18/03/19 07:43:48 INFO TaskSetManager: Finished task 16.0 in stage 5.0 (TID 35) in 2541 ms on localhost (executor driver) (17/96)
18/03/19 07:43:48 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:603979776+33554432
18/03/19 07:43:48 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:49 INFO Executor: Finished task 17.0 in stage 5.0 (TID 36). 918 bytes result sent to driver
18/03/19 07:43:49 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:49 INFO TaskSetManager: Starting task 19.0 in stage 5.0 (TID 38, localhost, executor driver, partition 19, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:49 INFO TaskSetManager: Finished task 17.0 in stage 5.0 (TID 36) in 2920 ms on localhost (executor driver) (18/96)
18/03/19 07:43:49 INFO Executor: Running task 19.0 in stage 5.0 (TID 38)
18/03/19 07:43:49 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:637534208+33554432
18/03/19 07:43:49 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:50 INFO Executor: Finished task 18.0 in stage 5.0 (TID 37). 918 bytes result sent to driver
18/03/19 07:43:50 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:50 INFO TaskSetManager: Starting task 20.0 in stage 5.0 (TID 39, localhost, executor driver, partition 20, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:50 INFO Executor: Running task 20.0 in stage 5.0 (TID 39)
18/03/19 07:43:50 INFO TaskSetManager: Finished task 18.0 in stage 5.0 (TID 37) in 2052 ms on localhost (executor driver) (19/96)
18/03/19 07:43:50 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:671088640+33554432
18/03/19 07:43:50 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:51 INFO Executor: Finished task 19.0 in stage 5.0 (TID 38). 832 bytes result sent to driver
18/03/19 07:43:51 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:51 INFO TaskSetManager: Starting task 21.0 in stage 5.0 (TID 40, localhost, executor driver, partition 21, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:51 INFO Executor: Running task 21.0 in stage 5.0 (TID 40)
18/03/19 07:43:51 INFO TaskSetManager: Finished task 19.0 in stage 5.0 (TID 38) in 2128 ms on localhost (executor driver) (20/96)
18/03/19 07:43:51 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:704643072+33554432
18/03/19 07:43:51 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:52 INFO Executor: Finished task 20.0 in stage 5.0 (TID 39). 875 bytes result sent to driver
18/03/19 07:43:52 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:52 INFO TaskSetManager: Starting task 22.0 in stage 5.0 (TID 41, localhost, executor driver, partition 22, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:52 INFO TaskSetManager: Finished task 20.0 in stage 5.0 (TID 39) in 2233 ms on localhost (executor driver) (21/96)
18/03/19 07:43:52 INFO Executor: Running task 22.0 in stage 5.0 (TID 41)
18/03/19 07:43:52 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:738197504+33554432
18/03/19 07:43:52 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:53 INFO Executor: Finished task 21.0 in stage 5.0 (TID 40). 875 bytes result sent to driver
18/03/19 07:43:53 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:53 INFO TaskSetManager: Starting task 23.0 in stage 5.0 (TID 42, localhost, executor driver, partition 23, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:53 INFO TaskSetManager: Finished task 21.0 in stage 5.0 (TID 40) in 2242 ms on localhost (executor driver) (22/96)
18/03/19 07:43:53 INFO Executor: Running task 23.0 in stage 5.0 (TID 42)
18/03/19 07:43:53 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:771751936+33554432
18/03/19 07:43:53 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:55 INFO Executor: Finished task 22.0 in stage 5.0 (TID 41). 875 bytes result sent to driver
18/03/19 07:43:55 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:55 INFO TaskSetManager: Starting task 24.0 in stage 5.0 (TID 43, localhost, executor driver, partition 24, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:55 INFO TaskSetManager: Finished task 22.0 in stage 5.0 (TID 41) in 3020 ms on localhost (executor driver) (23/96)
18/03/19 07:43:55 INFO Executor: Running task 24.0 in stage 5.0 (TID 43)
18/03/19 07:43:55 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:805306368+33554432
18/03/19 07:43:55 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:56 INFO Executor: Finished task 23.0 in stage 5.0 (TID 42). 875 bytes result sent to driver
18/03/19 07:43:56 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:56 INFO TaskSetManager: Starting task 25.0 in stage 5.0 (TID 44, localhost, executor driver, partition 25, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:56 INFO TaskSetManager: Finished task 23.0 in stage 5.0 (TID 42) in 3232 ms on localhost (executor driver) (24/96)
18/03/19 07:43:56 INFO Executor: Running task 25.0 in stage 5.0 (TID 44)
18/03/19 07:43:56 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:838860800+33554432
18/03/19 07:43:56 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:58 INFO Executor: Finished task 24.0 in stage 5.0 (TID 43). 875 bytes result sent to driver
18/03/19 07:43:58 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:58 INFO TaskSetManager: Starting task 26.0 in stage 5.0 (TID 45, localhost, executor driver, partition 26, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:58 INFO TaskSetManager: Finished task 24.0 in stage 5.0 (TID 43) in 2579 ms on localhost (executor driver) (25/96)
18/03/19 07:43:58 INFO Executor: Running task 26.0 in stage 5.0 (TID 45)
18/03/19 07:43:58 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:872415232+33554432
18/03/19 07:43:58 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:43:59 INFO Executor: Finished task 25.0 in stage 5.0 (TID 44). 875 bytes result sent to driver
18/03/19 07:43:59 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:43:59 INFO TaskSetManager: Starting task 27.0 in stage 5.0 (TID 46, localhost, executor driver, partition 27, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:43:59 INFO Executor: Running task 27.0 in stage 5.0 (TID 46)
18/03/19 07:43:59 INFO TaskSetManager: Finished task 25.0 in stage 5.0 (TID 44) in 2603 ms on localhost (executor driver) (26/96)
18/03/19 07:43:59 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:905969664+33554432
18/03/19 07:43:59 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:00 INFO Executor: Finished task 26.0 in stage 5.0 (TID 45). 875 bytes result sent to driver
18/03/19 07:44:00 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:00 INFO TaskSetManager: Starting task 28.0 in stage 5.0 (TID 47, localhost, executor driver, partition 28, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:00 INFO Executor: Running task 28.0 in stage 5.0 (TID 47)
18/03/19 07:44:00 INFO TaskSetManager: Finished task 26.0 in stage 5.0 (TID 45) in 2288 ms on localhost (executor driver) (27/96)
18/03/19 07:44:00 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:939524096+33554432
18/03/19 07:44:00 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:01 INFO Executor: Finished task 27.0 in stage 5.0 (TID 46). 875 bytes result sent to driver
18/03/19 07:44:01 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:01 INFO TaskSetManager: Starting task 29.0 in stage 5.0 (TID 48, localhost, executor driver, partition 29, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:01 INFO Executor: Running task 29.0 in stage 5.0 (TID 48)
18/03/19 07:44:01 INFO TaskSetManager: Finished task 27.0 in stage 5.0 (TID 46) in 2222 ms on localhost (executor driver) (28/96)
18/03/19 07:44:01 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:973078528+33554432
18/03/19 07:44:01 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:02 INFO Executor: Finished task 28.0 in stage 5.0 (TID 47). 875 bytes result sent to driver
18/03/19 07:44:02 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:02 INFO TaskSetManager: Starting task 30.0 in stage 5.0 (TID 49, localhost, executor driver, partition 30, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:02 INFO TaskSetManager: Finished task 28.0 in stage 5.0 (TID 47) in 2008 ms on localhost (executor driver) (29/96)
18/03/19 07:44:02 INFO Executor: Running task 30.0 in stage 5.0 (TID 49)
18/03/19 07:44:02 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1006632960+33554432
18/03/19 07:44:02 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:04 INFO Executor: Finished task 29.0 in stage 5.0 (TID 48). 918 bytes result sent to driver
18/03/19 07:44:04 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:04 INFO TaskSetManager: Starting task 31.0 in stage 5.0 (TID 50, localhost, executor driver, partition 31, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:04 INFO Executor: Running task 31.0 in stage 5.0 (TID 50)
18/03/19 07:44:04 INFO TaskSetManager: Finished task 29.0 in stage 5.0 (TID 48) in 2635 ms on localhost (executor driver) (30/96)
18/03/19 07:44:04 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1040187392+33554432
18/03/19 07:44:04 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:04 INFO Executor: Finished task 30.0 in stage 5.0 (TID 49). 875 bytes result sent to driver
18/03/19 07:44:04 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:04 INFO TaskSetManager: Starting task 32.0 in stage 5.0 (TID 51, localhost, executor driver, partition 32, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:04 INFO Executor: Running task 32.0 in stage 5.0 (TID 51)
18/03/19 07:44:04 INFO TaskSetManager: Finished task 30.0 in stage 5.0 (TID 49) in 2153 ms on localhost (executor driver) (31/96)
18/03/19 07:44:04 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1073741824+33554432
18/03/19 07:44:04 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:06 INFO Executor: Finished task 31.0 in stage 5.0 (TID 50). 875 bytes result sent to driver
18/03/19 07:44:06 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:06 INFO TaskSetManager: Starting task 33.0 in stage 5.0 (TID 52, localhost, executor driver, partition 33, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:06 INFO Executor: Running task 33.0 in stage 5.0 (TID 52)
18/03/19 07:44:06 INFO TaskSetManager: Finished task 31.0 in stage 5.0 (TID 50) in 2305 ms on localhost (executor driver) (32/96)
18/03/19 07:44:06 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1107296256+33554432
18/03/19 07:44:06 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:07 INFO Executor: Finished task 32.0 in stage 5.0 (TID 51). 875 bytes result sent to driver
18/03/19 07:44:07 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:07 INFO TaskSetManager: Starting task 34.0 in stage 5.0 (TID 53, localhost, executor driver, partition 34, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:07 INFO TaskSetManager: Finished task 32.0 in stage 5.0 (TID 51) in 2195 ms on localhost (executor driver) (33/96)
18/03/19 07:44:07 INFO Executor: Running task 34.0 in stage 5.0 (TID 53)
18/03/19 07:44:07 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1140850688+33554432
18/03/19 07:44:07 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:08 INFO Executor: Finished task 33.0 in stage 5.0 (TID 52). 875 bytes result sent to driver
18/03/19 07:44:08 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:08 INFO TaskSetManager: Starting task 35.0 in stage 5.0 (TID 54, localhost, executor driver, partition 35, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:08 INFO TaskSetManager: Finished task 33.0 in stage 5.0 (TID 52) in 2318 ms on localhost (executor driver) (34/96)
18/03/19 07:44:08 INFO Executor: Running task 35.0 in stage 5.0 (TID 54)
18/03/19 07:44:08 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1174405120+33554432
18/03/19 07:44:08 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:09 INFO Executor: Finished task 34.0 in stage 5.0 (TID 53). 875 bytes result sent to driver
18/03/19 07:44:09 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:09 INFO TaskSetManager: Starting task 36.0 in stage 5.0 (TID 55, localhost, executor driver, partition 36, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:09 INFO TaskSetManager: Finished task 34.0 in stage 5.0 (TID 53) in 2326 ms on localhost (executor driver) (35/96)
18/03/19 07:44:09 INFO Executor: Running task 36.0 in stage 5.0 (TID 55)
18/03/19 07:44:09 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1207959552+33554432
18/03/19 07:44:09 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:11 INFO Executor: Finished task 35.0 in stage 5.0 (TID 54). 875 bytes result sent to driver
18/03/19 07:44:11 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:11 INFO TaskSetManager: Starting task 37.0 in stage 5.0 (TID 56, localhost, executor driver, partition 37, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:11 INFO Executor: Running task 37.0 in stage 5.0 (TID 56)
18/03/19 07:44:11 INFO TaskSetManager: Finished task 35.0 in stage 5.0 (TID 54) in 2240 ms on localhost (executor driver) (36/96)
18/03/19 07:44:11 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1241513984+33554432
18/03/19 07:44:11 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:11 INFO Executor: Finished task 36.0 in stage 5.0 (TID 55). 875 bytes result sent to driver
18/03/19 07:44:11 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:11 INFO TaskSetManager: Starting task 38.0 in stage 5.0 (TID 57, localhost, executor driver, partition 38, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:11 INFO Executor: Running task 38.0 in stage 5.0 (TID 57)
18/03/19 07:44:11 INFO TaskSetManager: Finished task 36.0 in stage 5.0 (TID 55) in 2196 ms on localhost (executor driver) (37/96)
18/03/19 07:44:11 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1275068416+33554432
18/03/19 07:44:11 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:13 INFO Executor: Finished task 37.0 in stage 5.0 (TID 56). 875 bytes result sent to driver
18/03/19 07:44:13 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:13 INFO TaskSetManager: Starting task 39.0 in stage 5.0 (TID 58, localhost, executor driver, partition 39, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:13 INFO Executor: Running task 39.0 in stage 5.0 (TID 58)
18/03/19 07:44:13 INFO TaskSetManager: Finished task 37.0 in stage 5.0 (TID 56) in 2140 ms on localhost (executor driver) (38/96)
18/03/19 07:44:13 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1308622848+33554432
18/03/19 07:44:13 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:13 INFO Executor: Finished task 38.0 in stage 5.0 (TID 57). 875 bytes result sent to driver
18/03/19 07:44:13 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:13 INFO TaskSetManager: Starting task 40.0 in stage 5.0 (TID 59, localhost, executor driver, partition 40, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:13 INFO TaskSetManager: Finished task 38.0 in stage 5.0 (TID 57) in 2440 ms on localhost (executor driver) (39/96)
18/03/19 07:44:13 INFO Executor: Running task 40.0 in stage 5.0 (TID 59)
18/03/19 07:44:13 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1342177280+33554432
18/03/19 07:44:13 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:15 INFO Executor: Finished task 39.0 in stage 5.0 (TID 58). 875 bytes result sent to driver
18/03/19 07:44:15 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:15 INFO TaskSetManager: Starting task 41.0 in stage 5.0 (TID 60, localhost, executor driver, partition 41, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:15 INFO Executor: Running task 41.0 in stage 5.0 (TID 60)
18/03/19 07:44:15 INFO TaskSetManager: Finished task 39.0 in stage 5.0 (TID 58) in 2138 ms on localhost (executor driver) (40/96)
18/03/19 07:44:15 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1375731712+33554432
18/03/19 07:44:15 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:16 INFO Executor: Finished task 40.0 in stage 5.0 (TID 59). 875 bytes result sent to driver
18/03/19 07:44:16 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:16 INFO TaskSetManager: Starting task 42.0 in stage 5.0 (TID 61, localhost, executor driver, partition 42, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:16 INFO Executor: Running task 42.0 in stage 5.0 (TID 61)
18/03/19 07:44:16 INFO TaskSetManager: Finished task 40.0 in stage 5.0 (TID 59) in 2336 ms on localhost (executor driver) (41/96)
18/03/19 07:44:16 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1409286144+33554432
18/03/19 07:44:16 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:17 INFO Executor: Finished task 41.0 in stage 5.0 (TID 60). 875 bytes result sent to driver
18/03/19 07:44:17 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:17 INFO TaskSetManager: Starting task 43.0 in stage 5.0 (TID 62, localhost, executor driver, partition 43, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:17 INFO Executor: Running task 43.0 in stage 5.0 (TID 62)
18/03/19 07:44:17 INFO TaskSetManager: Finished task 41.0 in stage 5.0 (TID 60) in 2575 ms on localhost (executor driver) (42/96)
18/03/19 07:44:17 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1442840576+33554432
18/03/19 07:44:17 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:18 TRACE HeartbeatReceiver: Checking for hosts with no recent heartbeats in HeartbeatReceiver.
18/03/19 07:44:18 INFO Executor: Finished task 42.0 in stage 5.0 (TID 61). 875 bytes result sent to driver
18/03/19 07:44:18 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:18 INFO TaskSetManager: Starting task 44.0 in stage 5.0 (TID 63, localhost, executor driver, partition 44, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:18 INFO Executor: Running task 44.0 in stage 5.0 (TID 63)
18/03/19 07:44:18 INFO TaskSetManager: Finished task 42.0 in stage 5.0 (TID 61) in 2494 ms on localhost (executor driver) (43/96)
18/03/19 07:44:18 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1476395008+33554432
18/03/19 07:44:18 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:20 INFO Executor: Finished task 43.0 in stage 5.0 (TID 62). 832 bytes result sent to driver
18/03/19 07:44:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:20 INFO TaskSetManager: Starting task 45.0 in stage 5.0 (TID 64, localhost, executor driver, partition 45, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:20 INFO TaskSetManager: Finished task 43.0 in stage 5.0 (TID 62) in 2394 ms on localhost (executor driver) (44/96)
18/03/19 07:44:20 INFO Executor: Running task 45.0 in stage 5.0 (TID 64)
18/03/19 07:44:20 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1509949440+33554432
18/03/19 07:44:20 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:20 INFO Executor: Finished task 44.0 in stage 5.0 (TID 63). 875 bytes result sent to driver
18/03/19 07:44:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:20 INFO TaskSetManager: Starting task 46.0 in stage 5.0 (TID 65, localhost, executor driver, partition 46, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:20 INFO TaskSetManager: Finished task 44.0 in stage 5.0 (TID 63) in 2019 ms on localhost (executor driver) (45/96)
18/03/19 07:44:20 INFO Executor: Running task 46.0 in stage 5.0 (TID 65)
18/03/19 07:44:20 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1543503872+33554432
18/03/19 07:44:20 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:22 INFO Executor: Finished task 45.0 in stage 5.0 (TID 64). 832 bytes result sent to driver
18/03/19 07:44:22 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:22 INFO TaskSetManager: Starting task 47.0 in stage 5.0 (TID 66, localhost, executor driver, partition 47, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:22 INFO Executor: Running task 47.0 in stage 5.0 (TID 66)
18/03/19 07:44:22 INFO TaskSetManager: Finished task 45.0 in stage 5.0 (TID 64) in 2339 ms on localhost (executor driver) (46/96)
18/03/19 07:44:22 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1577058304+33554432
18/03/19 07:44:22 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:23 INFO Executor: Finished task 46.0 in stage 5.0 (TID 65). 875 bytes result sent to driver
18/03/19 07:44:23 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:23 INFO TaskSetManager: Starting task 48.0 in stage 5.0 (TID 67, localhost, executor driver, partition 48, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:23 INFO Executor: Running task 48.0 in stage 5.0 (TID 67)
18/03/19 07:44:23 INFO TaskSetManager: Finished task 46.0 in stage 5.0 (TID 65) in 2471 ms on localhost (executor driver) (47/96)
18/03/19 07:44:23 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1610612736+33554432
18/03/19 07:44:23 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:25 INFO Executor: Finished task 47.0 in stage 5.0 (TID 66). 875 bytes result sent to driver
18/03/19 07:44:25 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:25 INFO TaskSetManager: Starting task 49.0 in stage 5.0 (TID 68, localhost, executor driver, partition 49, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:25 INFO TaskSetManager: Finished task 47.0 in stage 5.0 (TID 66) in 2513 ms on localhost (executor driver) (48/96)
18/03/19 07:44:25 INFO Executor: Running task 49.0 in stage 5.0 (TID 68)
18/03/19 07:44:25 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1644167168+33554432
18/03/19 07:44:25 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:25 INFO Executor: Finished task 48.0 in stage 5.0 (TID 67). 832 bytes result sent to driver
18/03/19 07:44:25 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:25 INFO TaskSetManager: Starting task 50.0 in stage 5.0 (TID 69, localhost, executor driver, partition 50, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:25 INFO Executor: Running task 50.0 in stage 5.0 (TID 69)
18/03/19 07:44:25 INFO TaskSetManager: Finished task 48.0 in stage 5.0 (TID 67) in 1956 ms on localhost (executor driver) (49/96)
18/03/19 07:44:25 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1677721600+33554432
18/03/19 07:44:25 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:27 INFO Executor: Finished task 50.0 in stage 5.0 (TID 69). 875 bytes result sent to driver
18/03/19 07:44:27 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:27 INFO TaskSetManager: Starting task 51.0 in stage 5.0 (TID 70, localhost, executor driver, partition 51, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:27 INFO TaskSetManager: Finished task 50.0 in stage 5.0 (TID 69) in 1995 ms on localhost (executor driver) (50/96)
18/03/19 07:44:27 INFO Executor: Running task 51.0 in stage 5.0 (TID 70)
18/03/19 07:44:27 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1711276032+33554432
18/03/19 07:44:27 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:27 INFO Executor: Finished task 49.0 in stage 5.0 (TID 68). 875 bytes result sent to driver
18/03/19 07:44:27 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:27 INFO TaskSetManager: Starting task 52.0 in stage 5.0 (TID 71, localhost, executor driver, partition 52, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:27 INFO Executor: Running task 52.0 in stage 5.0 (TID 71)
18/03/19 07:44:27 INFO TaskSetManager: Finished task 49.0 in stage 5.0 (TID 68) in 2337 ms on localhost (executor driver) (51/96)
18/03/19 07:44:27 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1744830464+33554432
18/03/19 07:44:27 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:29 INFO Executor: Finished task 51.0 in stage 5.0 (TID 70). 875 bytes result sent to driver
18/03/19 07:44:29 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:29 INFO TaskSetManager: Starting task 53.0 in stage 5.0 (TID 72, localhost, executor driver, partition 53, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:29 INFO Executor: Running task 53.0 in stage 5.0 (TID 72)
18/03/19 07:44:29 INFO TaskSetManager: Finished task 51.0 in stage 5.0 (TID 70) in 2470 ms on localhost (executor driver) (52/96)
18/03/19 07:44:29 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1778384896+33554432
18/03/19 07:44:29 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:29 INFO Executor: Finished task 52.0 in stage 5.0 (TID 71). 875 bytes result sent to driver
18/03/19 07:44:29 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:29 INFO TaskSetManager: Starting task 54.0 in stage 5.0 (TID 73, localhost, executor driver, partition 54, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:29 INFO TaskSetManager: Finished task 52.0 in stage 5.0 (TID 71) in 2479 ms on localhost (executor driver) (53/96)
18/03/19 07:44:29 INFO Executor: Running task 54.0 in stage 5.0 (TID 73)
18/03/19 07:44:29 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1811939328+33554432
18/03/19 07:44:29 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:32 INFO Executor: Finished task 54.0 in stage 5.0 (TID 73). 875 bytes result sent to driver
18/03/19 07:44:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:32 INFO TaskSetManager: Starting task 55.0 in stage 5.0 (TID 74, localhost, executor driver, partition 55, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:32 INFO TaskSetManager: Finished task 54.0 in stage 5.0 (TID 73) in 2239 ms on localhost (executor driver) (54/96)
18/03/19 07:44:32 INFO Executor: Running task 55.0 in stage 5.0 (TID 74)
18/03/19 07:44:32 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1845493760+33554432
18/03/19 07:44:32 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:32 INFO Executor: Finished task 53.0 in stage 5.0 (TID 72). 832 bytes result sent to driver
18/03/19 07:44:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:32 INFO TaskSetManager: Starting task 56.0 in stage 5.0 (TID 75, localhost, executor driver, partition 56, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:32 INFO Executor: Running task 56.0 in stage 5.0 (TID 75)
18/03/19 07:44:32 INFO TaskSetManager: Finished task 53.0 in stage 5.0 (TID 72) in 2518 ms on localhost (executor driver) (55/96)
18/03/19 07:44:32 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1879048192+33554432
18/03/19 07:44:32 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:34 INFO Executor: Finished task 56.0 in stage 5.0 (TID 75). 875 bytes result sent to driver
18/03/19 07:44:34 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:34 INFO TaskSetManager: Starting task 57.0 in stage 5.0 (TID 76, localhost, executor driver, partition 57, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:34 INFO Executor: Running task 57.0 in stage 5.0 (TID 76)
18/03/19 07:44:34 INFO TaskSetManager: Finished task 56.0 in stage 5.0 (TID 75) in 2364 ms on localhost (executor driver) (56/96)
18/03/19 07:44:34 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1912602624+33554432
18/03/19 07:44:34 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:34 INFO Executor: Finished task 55.0 in stage 5.0 (TID 74). 875 bytes result sent to driver
18/03/19 07:44:34 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:34 INFO TaskSetManager: Starting task 58.0 in stage 5.0 (TID 77, localhost, executor driver, partition 58, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:34 INFO TaskSetManager: Finished task 55.0 in stage 5.0 (TID 74) in 2672 ms on localhost (executor driver) (57/96)
18/03/19 07:44:34 INFO Executor: Running task 58.0 in stage 5.0 (TID 77)
18/03/19 07:44:34 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1946157056+33554432
18/03/19 07:44:34 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:36 INFO Executor: Finished task 57.0 in stage 5.0 (TID 76). 875 bytes result sent to driver
18/03/19 07:44:36 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:36 INFO TaskSetManager: Starting task 59.0 in stage 5.0 (TID 78, localhost, executor driver, partition 59, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:36 INFO Executor: Running task 59.0 in stage 5.0 (TID 78)
18/03/19 07:44:36 INFO TaskSetManager: Finished task 57.0 in stage 5.0 (TID 76) in 2250 ms on localhost (executor driver) (58/96)
18/03/19 07:44:36 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1979711488+33554432
18/03/19 07:44:36 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:37 INFO Executor: Finished task 58.0 in stage 5.0 (TID 77). 918 bytes result sent to driver
18/03/19 07:44:37 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:37 INFO TaskSetManager: Starting task 60.0 in stage 5.0 (TID 79, localhost, executor driver, partition 60, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:37 INFO Executor: Running task 60.0 in stage 5.0 (TID 79)
18/03/19 07:44:37 INFO TaskSetManager: Finished task 58.0 in stage 5.0 (TID 77) in 2478 ms on localhost (executor driver) (59/96)
18/03/19 07:44:37 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2013265920+33554432
18/03/19 07:44:37 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:39 INFO Executor: Finished task 59.0 in stage 5.0 (TID 78). 875 bytes result sent to driver
18/03/19 07:44:39 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:39 INFO TaskSetManager: Starting task 61.0 in stage 5.0 (TID 80, localhost, executor driver, partition 61, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:39 INFO Executor: Running task 61.0 in stage 5.0 (TID 80)
18/03/19 07:44:39 INFO TaskSetManager: Finished task 59.0 in stage 5.0 (TID 78) in 2148 ms on localhost (executor driver) (60/96)
18/03/19 07:44:39 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2046820352+33554432
18/03/19 07:44:39 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:39 INFO Executor: Finished task 60.0 in stage 5.0 (TID 79). 875 bytes result sent to driver
18/03/19 07:44:39 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:39 INFO TaskSetManager: Starting task 62.0 in stage 5.0 (TID 81, localhost, executor driver, partition 62, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:39 INFO TaskSetManager: Finished task 60.0 in stage 5.0 (TID 79) in 2149 ms on localhost (executor driver) (61/96)
18/03/19 07:44:39 INFO Executor: Running task 62.0 in stage 5.0 (TID 81)
18/03/19 07:44:39 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2080374784+33554432
18/03/19 07:44:39 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:41 INFO Executor: Finished task 61.0 in stage 5.0 (TID 80). 875 bytes result sent to driver
18/03/19 07:44:41 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:41 INFO TaskSetManager: Starting task 63.0 in stage 5.0 (TID 82, localhost, executor driver, partition 63, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:41 INFO Executor: Running task 63.0 in stage 5.0 (TID 82)
18/03/19 07:44:41 INFO TaskSetManager: Finished task 61.0 in stage 5.0 (TID 80) in 2346 ms on localhost (executor driver) (62/96)
18/03/19 07:44:41 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2113929216+33554432
18/03/19 07:44:41 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:41 INFO Executor: Finished task 62.0 in stage 5.0 (TID 81). 875 bytes result sent to driver
18/03/19 07:44:41 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:41 INFO TaskSetManager: Starting task 64.0 in stage 5.0 (TID 83, localhost, executor driver, partition 64, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:41 INFO Executor: Running task 64.0 in stage 5.0 (TID 83)
18/03/19 07:44:41 INFO TaskSetManager: Finished task 62.0 in stage 5.0 (TID 81) in 2277 ms on localhost (executor driver) (63/96)
18/03/19 07:44:41 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2147483648+33554432
18/03/19 07:44:41 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:44 INFO Executor: Finished task 63.0 in stage 5.0 (TID 82). 875 bytes result sent to driver
18/03/19 07:44:44 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:44 INFO TaskSetManager: Starting task 65.0 in stage 5.0 (TID 84, localhost, executor driver, partition 65, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:44 INFO Executor: Running task 65.0 in stage 5.0 (TID 84)
18/03/19 07:44:44 INFO TaskSetManager: Finished task 63.0 in stage 5.0 (TID 82) in 2809 ms on localhost (executor driver) (64/96)
18/03/19 07:44:44 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2181038080+33554432
18/03/19 07:44:44 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:44 INFO Executor: Finished task 64.0 in stage 5.0 (TID 83). 832 bytes result sent to driver
18/03/19 07:44:44 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:44 INFO TaskSetManager: Starting task 66.0 in stage 5.0 (TID 85, localhost, executor driver, partition 66, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:44 INFO TaskSetManager: Finished task 64.0 in stage 5.0 (TID 83) in 3165 ms on localhost (executor driver) (65/96)
18/03/19 07:44:44 INFO Executor: Running task 66.0 in stage 5.0 (TID 85)
18/03/19 07:44:44 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2214592512+33554432
18/03/19 07:44:44 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:46 INFO Executor: Finished task 65.0 in stage 5.0 (TID 84). 918 bytes result sent to driver
18/03/19 07:44:46 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:46 INFO TaskSetManager: Starting task 67.0 in stage 5.0 (TID 86, localhost, executor driver, partition 67, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:46 INFO Executor: Running task 67.0 in stage 5.0 (TID 86)
18/03/19 07:44:46 INFO TaskSetManager: Finished task 65.0 in stage 5.0 (TID 84) in 2413 ms on localhost (executor driver) (66/96)
18/03/19 07:44:46 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2248146944+33554432
18/03/19 07:44:46 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:47 INFO Executor: Finished task 66.0 in stage 5.0 (TID 85). 875 bytes result sent to driver
18/03/19 07:44:47 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:47 INFO TaskSetManager: Starting task 68.0 in stage 5.0 (TID 87, localhost, executor driver, partition 68, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:47 INFO Executor: Running task 68.0 in stage 5.0 (TID 87)
18/03/19 07:44:47 INFO TaskSetManager: Finished task 66.0 in stage 5.0 (TID 85) in 2331 ms on localhost (executor driver) (67/96)
18/03/19 07:44:47 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2281701376+33554432
18/03/19 07:44:47 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:48 INFO Executor: Finished task 67.0 in stage 5.0 (TID 86). 875 bytes result sent to driver
18/03/19 07:44:48 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:48 INFO TaskSetManager: Starting task 69.0 in stage 5.0 (TID 88, localhost, executor driver, partition 69, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:48 INFO TaskSetManager: Finished task 67.0 in stage 5.0 (TID 86) in 2227 ms on localhost (executor driver) (68/96)
18/03/19 07:44:48 INFO Executor: Running task 69.0 in stage 5.0 (TID 88)
18/03/19 07:44:48 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2315255808+33554432
18/03/19 07:44:48 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:49 INFO Executor: Finished task 68.0 in stage 5.0 (TID 87). 875 bytes result sent to driver
18/03/19 07:44:49 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:49 INFO TaskSetManager: Starting task 70.0 in stage 5.0 (TID 89, localhost, executor driver, partition 70, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:49 INFO Executor: Running task 70.0 in stage 5.0 (TID 89)
18/03/19 07:44:49 INFO TaskSetManager: Finished task 68.0 in stage 5.0 (TID 87) in 2289 ms on localhost (executor driver) (69/96)
18/03/19 07:44:49 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2348810240+33554432
18/03/19 07:44:49 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:50 INFO Executor: Finished task 69.0 in stage 5.0 (TID 88). 832 bytes result sent to driver
18/03/19 07:44:50 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:50 INFO TaskSetManager: Starting task 71.0 in stage 5.0 (TID 90, localhost, executor driver, partition 71, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:50 INFO TaskSetManager: Finished task 69.0 in stage 5.0 (TID 88) in 2113 ms on localhost (executor driver) (70/96)
18/03/19 07:44:50 INFO Executor: Running task 71.0 in stage 5.0 (TID 90)
18/03/19 07:44:50 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2382364672+33554432
18/03/19 07:44:50 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:51 INFO Executor: Finished task 70.0 in stage 5.0 (TID 89). 875 bytes result sent to driver
18/03/19 07:44:51 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:51 INFO TaskSetManager: Starting task 72.0 in stage 5.0 (TID 91, localhost, executor driver, partition 72, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:51 INFO Executor: Running task 72.0 in stage 5.0 (TID 91)
18/03/19 07:44:51 INFO TaskSetManager: Finished task 70.0 in stage 5.0 (TID 89) in 2162 ms on localhost (executor driver) (71/96)
18/03/19 07:44:51 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2415919104+33554432
18/03/19 07:44:51 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:53 INFO Executor: Finished task 71.0 in stage 5.0 (TID 90). 875 bytes result sent to driver
18/03/19 07:44:53 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:53 INFO TaskSetManager: Starting task 73.0 in stage 5.0 (TID 92, localhost, executor driver, partition 73, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:53 INFO Executor: Running task 73.0 in stage 5.0 (TID 92)
18/03/19 07:44:53 INFO TaskSetManager: Finished task 71.0 in stage 5.0 (TID 90) in 2458 ms on localhost (executor driver) (72/96)
18/03/19 07:44:53 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2449473536+33554432
18/03/19 07:44:53 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:53 INFO Executor: Finished task 72.0 in stage 5.0 (TID 91). 832 bytes result sent to driver
18/03/19 07:44:53 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:53 INFO TaskSetManager: Starting task 74.0 in stage 5.0 (TID 93, localhost, executor driver, partition 74, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:53 INFO Executor: Running task 74.0 in stage 5.0 (TID 93)
18/03/19 07:44:53 INFO TaskSetManager: Finished task 72.0 in stage 5.0 (TID 91) in 2148 ms on localhost (executor driver) (73/96)
18/03/19 07:44:53 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2483027968+33554432
18/03/19 07:44:53 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:55 INFO Executor: Finished task 73.0 in stage 5.0 (TID 92). 832 bytes result sent to driver
18/03/19 07:44:55 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:55 INFO TaskSetManager: Starting task 75.0 in stage 5.0 (TID 94, localhost, executor driver, partition 75, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:55 INFO Executor: Running task 75.0 in stage 5.0 (TID 94)
18/03/19 07:44:55 INFO TaskSetManager: Finished task 73.0 in stage 5.0 (TID 92) in 2367 ms on localhost (executor driver) (74/96)
18/03/19 07:44:55 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2516582400+33554432
18/03/19 07:44:55 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:55 INFO Executor: Finished task 74.0 in stage 5.0 (TID 93). 875 bytes result sent to driver
18/03/19 07:44:55 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:55 INFO TaskSetManager: Starting task 76.0 in stage 5.0 (TID 95, localhost, executor driver, partition 76, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:55 INFO Executor: Running task 76.0 in stage 5.0 (TID 95)
18/03/19 07:44:55 INFO TaskSetManager: Finished task 74.0 in stage 5.0 (TID 93) in 2019 ms on localhost (executor driver) (75/96)
18/03/19 07:44:55 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2550136832+33554432
18/03/19 07:44:55 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:57 INFO Executor: Finished task 75.0 in stage 5.0 (TID 94). 875 bytes result sent to driver
18/03/19 07:44:57 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:57 INFO TaskSetManager: Starting task 77.0 in stage 5.0 (TID 96, localhost, executor driver, partition 77, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:57 INFO TaskSetManager: Finished task 75.0 in stage 5.0 (TID 94) in 2019 ms on localhost (executor driver) (76/96)
18/03/19 07:44:57 INFO Executor: Running task 77.0 in stage 5.0 (TID 96)
18/03/19 07:44:57 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2583691264+33554432
18/03/19 07:44:57 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:44:58 INFO Executor: Finished task 76.0 in stage 5.0 (TID 95). 875 bytes result sent to driver
18/03/19 07:44:58 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:44:58 INFO TaskSetManager: Starting task 78.0 in stage 5.0 (TID 97, localhost, executor driver, partition 78, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:44:58 INFO TaskSetManager: Finished task 76.0 in stage 5.0 (TID 95) in 2845 ms on localhost (executor driver) (77/96)
18/03/19 07:44:58 INFO Executor: Running task 78.0 in stage 5.0 (TID 97)
18/03/19 07:44:58 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2617245696+33554432
18/03/19 07:44:58 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:01 INFO Executor: Finished task 77.0 in stage 5.0 (TID 96). 875 bytes result sent to driver
18/03/19 07:45:01 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:45:01 INFO TaskSetManager: Starting task 79.0 in stage 5.0 (TID 98, localhost, executor driver, partition 79, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:01 INFO Executor: Running task 79.0 in stage 5.0 (TID 98)
18/03/19 07:45:01 INFO TaskSetManager: Finished task 77.0 in stage 5.0 (TID 96) in 3685 ms on localhost (executor driver) (78/96)
18/03/19 07:45:01 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2650800128+33554432
18/03/19 07:45:01 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:02 INFO Executor: Finished task 78.0 in stage 5.0 (TID 97). 875 bytes result sent to driver
18/03/19 07:45:02 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:45:02 INFO TaskSetManager: Starting task 80.0 in stage 5.0 (TID 99, localhost, executor driver, partition 80, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:02 INFO Executor: Running task 80.0 in stage 5.0 (TID 99)
18/03/19 07:45:02 INFO TaskSetManager: Finished task 78.0 in stage 5.0 (TID 97) in 4100 ms on localhost (executor driver) (79/96)
18/03/19 07:45:02 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2684354560+33554432
18/03/19 07:45:02 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:04 INFO Executor: Finished task 79.0 in stage 5.0 (TID 98). 875 bytes result sent to driver
18/03/19 07:45:04 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:45:04 INFO TaskSetManager: Starting task 81.0 in stage 5.0 (TID 100, localhost, executor driver, partition 81, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:04 INFO Executor: Running task 81.0 in stage 5.0 (TID 100)
18/03/19 07:45:04 INFO TaskSetManager: Finished task 79.0 in stage 5.0 (TID 98) in 2982 ms on localhost (executor driver) (80/96)
18/03/19 07:45:04 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2717908992+33554432
18/03/19 07:45:04 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:06 INFO Executor: Finished task 80.0 in stage 5.0 (TID 99). 875 bytes result sent to driver
18/03/19 07:45:06 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:45:06 INFO TaskSetManager: Starting task 82.0 in stage 5.0 (TID 101, localhost, executor driver, partition 82, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:06 INFO Executor: Running task 82.0 in stage 5.0 (TID 101)
18/03/19 07:45:06 INFO TaskSetManager: Finished task 80.0 in stage 5.0 (TID 99) in 3518 ms on localhost (executor driver) (81/96)
18/03/19 07:45:06 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2751463424+33554432
18/03/19 07:45:06 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:08 INFO Executor: Finished task 81.0 in stage 5.0 (TID 100). 875 bytes result sent to driver
18/03/19 07:45:08 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:45:08 INFO TaskSetManager: Starting task 83.0 in stage 5.0 (TID 102, localhost, executor driver, partition 83, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:08 INFO Executor: Running task 83.0 in stage 5.0 (TID 102)
18/03/19 07:45:08 INFO TaskSetManager: Finished task 81.0 in stage 5.0 (TID 100) in 3620 ms on localhost (executor driver) (82/96)
18/03/19 07:45:08 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2785017856+33554432
18/03/19 07:45:08 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:10 INFO Executor: Finished task 82.0 in stage 5.0 (TID 101). 875 bytes result sent to driver
18/03/19 07:45:10 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:45:10 INFO TaskSetManager: Starting task 84.0 in stage 5.0 (TID 103, localhost, executor driver, partition 84, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:10 INFO TaskSetManager: Finished task 82.0 in stage 5.0 (TID 101) in 4093 ms on localhost (executor driver) (83/96)
18/03/19 07:45:10 INFO Executor: Running task 84.0 in stage 5.0 (TID 103)
18/03/19 07:45:10 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2818572288+33554432
18/03/19 07:45:10 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:11 INFO Executor: Finished task 83.0 in stage 5.0 (TID 102). 875 bytes result sent to driver
18/03/19 07:45:11 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:45:11 INFO TaskSetManager: Starting task 85.0 in stage 5.0 (TID 104, localhost, executor driver, partition 85, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:11 INFO Executor: Running task 85.0 in stage 5.0 (TID 104)
18/03/19 07:45:11 INFO TaskSetManager: Finished task 83.0 in stage 5.0 (TID 102) in 3528 ms on localhost (executor driver) (84/96)
18/03/19 07:45:11 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2852126720+33554432
18/03/19 07:45:11 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:13 INFO Executor: Finished task 84.0 in stage 5.0 (TID 103). 875 bytes result sent to driver
18/03/19 07:45:13 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:45:13 INFO TaskSetManager: Starting task 86.0 in stage 5.0 (TID 105, localhost, executor driver, partition 86, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:13 INFO Executor: Running task 86.0 in stage 5.0 (TID 105)
18/03/19 07:45:13 INFO TaskSetManager: Finished task 84.0 in stage 5.0 (TID 103) in 2968 ms on localhost (executor driver) (85/96)
18/03/19 07:45:13 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2885681152+33554432
18/03/19 07:45:13 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:15 INFO Executor: Finished task 85.0 in stage 5.0 (TID 104). 875 bytes result sent to driver
18/03/19 07:45:15 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:45:15 INFO TaskSetManager: Starting task 87.0 in stage 5.0 (TID 106, localhost, executor driver, partition 87, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:15 INFO TaskSetManager: Finished task 85.0 in stage 5.0 (TID 104) in 4392 ms on localhost (executor driver) (86/96)
18/03/19 07:45:15 INFO Executor: Running task 87.0 in stage 5.0 (TID 106)
18/03/19 07:45:15 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2919235584+33554432
18/03/19 07:45:15 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:17 INFO Executor: Finished task 86.0 in stage 5.0 (TID 105). 875 bytes result sent to driver
18/03/19 07:45:17 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:45:17 INFO TaskSetManager: Starting task 88.0 in stage 5.0 (TID 107, localhost, executor driver, partition 88, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:17 INFO Executor: Running task 88.0 in stage 5.0 (TID 107)
18/03/19 07:45:17 INFO TaskSetManager: Finished task 86.0 in stage 5.0 (TID 105) in 3717 ms on localhost (executor driver) (87/96)
18/03/19 07:45:17 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2952790016+33554432
18/03/19 07:45:17 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:18 TRACE HeartbeatReceiver: Checking for hosts with no recent heartbeats in HeartbeatReceiver.
18/03/19 07:45:19 INFO Executor: Finished task 87.0 in stage 5.0 (TID 106). 875 bytes result sent to driver
18/03/19 07:45:19 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:45:19 INFO TaskSetManager: Starting task 89.0 in stage 5.0 (TID 108, localhost, executor driver, partition 89, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:19 INFO Executor: Running task 89.0 in stage 5.0 (TID 108)
18/03/19 07:45:19 INFO TaskSetManager: Finished task 87.0 in stage 5.0 (TID 106) in 3947 ms on localhost (executor driver) (88/96)
18/03/19 07:45:19 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2986344448+33554432
18/03/19 07:45:19 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:20 INFO Executor: Finished task 88.0 in stage 5.0 (TID 107). 832 bytes result sent to driver
18/03/19 07:45:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:45:20 INFO TaskSetManager: Starting task 90.0 in stage 5.0 (TID 109, localhost, executor driver, partition 90, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:20 INFO Executor: Running task 90.0 in stage 5.0 (TID 109)
18/03/19 07:45:20 INFO TaskSetManager: Finished task 88.0 in stage 5.0 (TID 107) in 3159 ms on localhost (executor driver) (89/96)
18/03/19 07:45:20 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:3019898880+33554432
18/03/19 07:45:20 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:23 INFO Executor: Finished task 90.0 in stage 5.0 (TID 109). 832 bytes result sent to driver
18/03/19 07:45:23 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:45:23 INFO TaskSetManager: Starting task 91.0 in stage 5.0 (TID 110, localhost, executor driver, partition 91, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:23 INFO Executor: Running task 91.0 in stage 5.0 (TID 110)
18/03/19 07:45:23 INFO TaskSetManager: Finished task 90.0 in stage 5.0 (TID 109) in 3134 ms on localhost (executor driver) (90/96)
18/03/19 07:45:23 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:3053453312+33554432
18/03/19 07:45:23 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:23 INFO Executor: Finished task 89.0 in stage 5.0 (TID 108). 875 bytes result sent to driver
18/03/19 07:45:23 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:45:23 INFO TaskSetManager: Starting task 92.0 in stage 5.0 (TID 111, localhost, executor driver, partition 92, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:23 INFO Executor: Running task 92.0 in stage 5.0 (TID 111)
18/03/19 07:45:23 INFO TaskSetManager: Finished task 89.0 in stage 5.0 (TID 108) in 3612 ms on localhost (executor driver) (91/96)
18/03/19 07:45:23 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:3087007744+33554432
18/03/19 07:45:23 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:25 INFO Executor: Finished task 92.0 in stage 5.0 (TID 111). 875 bytes result sent to driver
18/03/19 07:45:25 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:45:25 INFO TaskSetManager: Starting task 93.0 in stage 5.0 (TID 112, localhost, executor driver, partition 93, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:25 INFO Executor: Running task 93.0 in stage 5.0 (TID 112)
18/03/19 07:45:25 INFO TaskSetManager: Finished task 92.0 in stage 5.0 (TID 111) in 2424 ms on localhost (executor driver) (92/96)
18/03/19 07:45:25 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:3120562176+33554432
18/03/19 07:45:25 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:26 INFO Executor: Finished task 91.0 in stage 5.0 (TID 110). 875 bytes result sent to driver
18/03/19 07:45:26 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:45:26 INFO TaskSetManager: Starting task 94.0 in stage 5.0 (TID 113, localhost, executor driver, partition 94, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:26 INFO Executor: Running task 94.0 in stage 5.0 (TID 113)
18/03/19 07:45:26 INFO TaskSetManager: Finished task 91.0 in stage 5.0 (TID 110) in 2563 ms on localhost (executor driver) (93/96)
18/03/19 07:45:26 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:3154116608+33554432
18/03/19 07:45:26 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:28 INFO Executor: Finished task 93.0 in stage 5.0 (TID 112). 875 bytes result sent to driver
18/03/19 07:45:28 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:45:28 INFO TaskSetManager: Starting task 95.0 in stage 5.0 (TID 114, localhost, executor driver, partition 95, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:28 INFO Executor: Running task 95.0 in stage 5.0 (TID 114)
18/03/19 07:45:28 INFO TaskSetManager: Finished task 93.0 in stage 5.0 (TID 112) in 2483 ms on localhost (executor driver) (94/96)
18/03/19 07:45:28 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:3187671040+19265026
18/03/19 07:45:28 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:28 INFO Executor: Finished task 94.0 in stage 5.0 (TID 113). 875 bytes result sent to driver
18/03/19 07:45:28 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 1
18/03/19 07:45:28 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
18/03/19 07:45:28 INFO TaskSetManager: Finished task 94.0 in stage 5.0 (TID 113) in 2510 ms on localhost (executor driver) (95/96)
18/03/19 07:45:29 INFO Executor: Finished task 95.0 in stage 5.0 (TID 114). 875 bytes result sent to driver
18/03/19 07:45:29 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5.0, runningTasks: 0
18/03/19 07:45:29 INFO TaskSetManager: Finished task 95.0 in stage 5.0 (TID 114) in 731 ms on localhost (executor driver) (96/96)
18/03/19 07:45:29 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/03/19 07:45:29 INFO DAGScheduler: ResultStage 5 (count at SBMJ_GB.scala:48) finished in 122.878 s
18/03/19 07:45:29 DEBUG DAGScheduler: After removal of stage 5, remaining stages = 0
18/03/19 07:45:29 INFO DAGScheduler: Job 5 finished: count at SBMJ_GB.scala:48, took 122.897617 s
18/03/19 07:45:29 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (Joins.SBMJ_GB$$anonfun$7) +++
18/03/19 07:45:29 DEBUG ClosureCleaner:  + declared fields: 1
18/03/19 07:45:29 DEBUG ClosureCleaner:      public static final long Joins.SBMJ_GB$$anonfun$7.serialVersionUID
100000000
18/03/19 07:45:29 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:45:29 DEBUG ClosureCleaner:      public final java.lang.Object Joins.SBMJ_GB$$anonfun$7.apply(java.lang.Object)
18/03/19 07:45:29 DEBUG ClosureCleaner:      public final scala.collection.mutable.ArrayOps Joins.SBMJ_GB$$anonfun$7.apply(java.lang.String)
18/03/19 07:45:29 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:45:29 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:45:29 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:45:29 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:45:29 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:45:29 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:45:29 DEBUG ClosureCleaner:  +++ closure <function1> (Joins.SBMJ_GB$$anonfun$7) is now cleaned +++
18/03/19 07:45:29 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (Joins.SBMJ_GB$$anonfun$8) +++
18/03/19 07:45:29 DEBUG ClosureCleaner:  + declared fields: 1
18/03/19 07:45:29 DEBUG ClosureCleaner:      public static final long Joins.SBMJ_GB$$anonfun$8.serialVersionUID
18/03/19 07:45:29 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:45:29 DEBUG ClosureCleaner:      public final java.lang.Object Joins.SBMJ_GB$$anonfun$8.apply(java.lang.Object)
18/03/19 07:45:29 DEBUG ClosureCleaner:      public final scala.Tuple2 Joins.SBMJ_GB$$anonfun$8.apply(java.lang.String)
18/03/19 07:45:29 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:45:29 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:45:29 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:45:29 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:45:29 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:45:29 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:45:29 DEBUG ClosureCleaner:  +++ closure <function1> (Joins.SBMJ_GB$$anonfun$8) is now cleaned +++
18/03/19 07:45:29 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28) +++
18/03/19 07:45:29 DEBUG ClosureCleaner:  + declared fields: 3
18/03/19 07:45:29 DEBUG ClosureCleaner:      public static final long org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28.serialVersionUID
18/03/19 07:45:29 DEBUG ClosureCleaner:      private final org.apache.spark.rdd.RDD$$anonfun$take$1 org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28.$outer
18/03/19 07:45:29 DEBUG ClosureCleaner:      private final int org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28.left$1
18/03/19 07:45:29 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:45:29 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28.apply(java.lang.Object)
18/03/19 07:45:29 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28.apply(scala.collection.Iterator)
18/03/19 07:45:29 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:45:29 DEBUG ClosureCleaner:  + outer classes: 2
18/03/19 07:45:29 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD$$anonfun$take$1
18/03/19 07:45:29 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD
18/03/19 07:45:29 DEBUG ClosureCleaner:  + outer objects: 2
18/03/19 07:45:29 DEBUG ClosureCleaner:      <function0>
18/03/19 07:45:29 DEBUG ClosureCleaner:      MapPartitionsRDD[11] at map at SBMJ_GB.scala:52
18/03/19 07:45:29 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:45:29 DEBUG ClosureCleaner:  + fields accessed by starting closure: 4
18/03/19 07:45:29 DEBUG ClosureCleaner:      (class java.lang.Object,Set())
18/03/19 07:45:29 DEBUG ClosureCleaner:      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
18/03/19 07:45:29 DEBUG ClosureCleaner:      (class scala.runtime.AbstractFunction0,Set())
18/03/19 07:45:29 DEBUG ClosureCleaner:      (class org.apache.spark.rdd.RDD$$anonfun$take$1,Set($outer))
18/03/19 07:45:29 DEBUG ClosureCleaner:  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[11] at map at SBMJ_GB.scala:52)
18/03/19 07:45:29 DEBUG ClosureCleaner:  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$take$1
18/03/19 07:45:29 DEBUG ClosureCleaner:  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$take$1)
18/03/19 07:45:29 DEBUG ClosureCleaner: +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$take$1) +++
18/03/19 07:45:29 DEBUG ClosureCleaner:  + declared fields: 3
18/03/19 07:45:29 DEBUG ClosureCleaner:      public static final long org.apache.spark.rdd.RDD$$anonfun$take$1.serialVersionUID
18/03/19 07:45:29 DEBUG ClosureCleaner:      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$take$1.$outer
18/03/19 07:45:29 DEBUG ClosureCleaner:      public final int org.apache.spark.rdd.RDD$$anonfun$take$1.num$2
18/03/19 07:45:29 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:45:29 DEBUG ClosureCleaner:      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$take$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
18/03/19 07:45:29 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$take$1.apply()
18/03/19 07:45:29 DEBUG ClosureCleaner:  + inner classes: 2
18/03/19 07:45:29 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$apply$49
18/03/19 07:45:29 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28
18/03/19 07:45:29 DEBUG ClosureCleaner:  + outer classes: 1
18/03/19 07:45:29 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD
18/03/19 07:45:29 DEBUG ClosureCleaner:  + outer objects: 1
18/03/19 07:45:29 DEBUG ClosureCleaner:      MapPartitionsRDD[11] at map at SBMJ_GB.scala:52
18/03/19 07:45:29 DEBUG ClosureCleaner:  + fields accessed by starting closure: 4
18/03/19 07:45:29 DEBUG ClosureCleaner:      (class java.lang.Object,Set())
18/03/19 07:45:29 DEBUG ClosureCleaner:      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
18/03/19 07:45:29 DEBUG ClosureCleaner:      (class scala.runtime.AbstractFunction0,Set())
18/03/19 07:45:29 DEBUG ClosureCleaner:      (class org.apache.spark.rdd.RDD$$anonfun$take$1,Set($outer))
18/03/19 07:45:29 DEBUG ClosureCleaner:  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[11] at map at SBMJ_GB.scala:52)
18/03/19 07:45:29 DEBUG ClosureCleaner:  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$take$1) is now cleaned +++
18/03/19 07:45:29 DEBUG ClosureCleaner:  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28) is now cleaned +++
18/03/19 07:45:29 DEBUG ClosureCleaner: +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
18/03/19 07:45:29 DEBUG ClosureCleaner:  + declared fields: 2
18/03/19 07:45:29 DEBUG ClosureCleaner:      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
18/03/19 07:45:29 DEBUG ClosureCleaner:      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
18/03/19 07:45:29 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:45:29 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
18/03/19 07:45:29 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
18/03/19 07:45:29 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:45:29 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:45:29 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:45:29 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:45:29 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:45:29 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:45:29 DEBUG ClosureCleaner:  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
18/03/19 07:45:29 INFO SparkContext: Starting job: take at SBMJ_GB.scala:53
18/03/19 07:45:29 INFO DAGScheduler: Got job 6 (take at SBMJ_GB.scala:53) with 1 output partitions
18/03/19 07:45:29 INFO DAGScheduler: Final stage: ResultStage 6 (take at SBMJ_GB.scala:53)
18/03/19 07:45:29 INFO DAGScheduler: Parents of final stage: List()
18/03/19 07:45:29 INFO DAGScheduler: Missing parents: List()
18/03/19 07:45:29 DEBUG DAGScheduler: submitStage(ResultStage 6)
18/03/19 07:45:29 DEBUG DAGScheduler: missing: List()
18/03/19 07:45:29 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[11] at map at SBMJ_GB.scala:52), which has no missing parents
18/03/19 07:45:29 DEBUG DAGScheduler: submitMissingTasks(ResultStage 6)
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 trying to put broadcast_8
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_8
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_8
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_8
18/03/19 07:45:29 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 3.9 KB, free 852.1 MB)
18/03/19 07:45:29 DEBUG BlockManager: Put block broadcast_8 locally took  2 ms
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_8
18/03/19 07:45:29 DEBUG BlockManager: Putting block broadcast_8 without replication took  2 ms
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 trying to put broadcast_8_piece0
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_8_piece0
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_8_piece0
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_8_piece0
18/03/19 07:45:29 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.1 KB, free 852.1 MB)
18/03/19 07:45:29 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.8.100:40919 (size: 2.1 KB, free: 852.6 MB)
18/03/19 07:45:29 DEBUG BlockManagerMaster: Updated info of block broadcast_8_piece0
18/03/19 07:45:29 DEBUG BlockManager: Told master about block broadcast_8_piece0
18/03/19 07:45:29 DEBUG BlockManager: Put block broadcast_8_piece0 locally took  2 ms
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_8_piece0
18/03/19 07:45:29 DEBUG BlockManager: Putting block broadcast_8_piece0 without replication took  2 ms
18/03/19 07:45:29 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1039
18/03/19 07:45:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[11] at map at SBMJ_GB.scala:52) (first 15 tasks are for partitions Vector(0))
18/03/19 07:45:29 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
18/03/19 07:45:29 DEBUG TaskSetManager: Epoch for TaskSet 6.0: 0
18/03/19 07:45:29 DEBUG TaskSetManager: Valid locality levels for TaskSet 6.0: NO_PREF, ANY
18/03/19 07:45:29 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_6.0, runningTasks: 0
18/03/19 07:45:29 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 115, localhost, executor driver, partition 0, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:29 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
18/03/19 07:45:29 INFO Executor: Running task 0.0 in stage 6.0 (TID 115)
18/03/19 07:45:29 DEBUG BlockManager: Getting local block broadcast_8
18/03/19 07:45:29 TRACE BlockInfoManager: Task 115 trying to acquire read lock for broadcast_8
18/03/19 07:45:29 TRACE BlockInfoManager: Task 115 acquired read lock for broadcast_8
18/03/19 07:45:29 DEBUG BlockManager: Level for block broadcast_8 is StorageLevel(disk, memory, deserialized, 1 replicas)
18/03/19 07:45:29 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:0+33554432
18/03/19 07:45:29 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:29 TRACE BlockInfoManager: Task 115 releasing lock for broadcast_8
18/03/19 07:45:29 INFO Executor: Finished task 0.0 in stage 6.0 (TID 115). 1171 bytes result sent to driver
18/03/19 07:45:29 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_6.0, runningTasks: 0
18/03/19 07:45:29 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 115) in 4 ms on localhost (executor driver) (1/1)
18/03/19 07:45:29 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/03/19 07:45:29 INFO DAGScheduler: ResultStage 6 (take at SBMJ_GB.scala:53) finished in 0.014 s
18/03/19 07:45:29 DEBUG DAGScheduler: After removal of stage 6, remaining stages = 0
18/03/19 07:45:29 INFO DAGScheduler: Job 6 finished: take at SBMJ_GB.scala:53, took 0.017459 s
18/03/19 07:45:29 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
(783193,16758)
(271105,7612)
(1032749,10584)
(460028,2542)
(395356,12584)
(155355,22882)
(157984,21371)
(630380,1200)
(1207995,10175)
(836168,23472)
18/03/19 07:45:29 DEBUG ClosureCleaner:  + declared fields: 1
18/03/19 07:45:29 DEBUG ClosureCleaner:      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
18/03/19 07:45:29 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:45:29 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
18/03/19 07:45:29 DEBUG ClosureCleaner:      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
18/03/19 07:45:29 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:45:29 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:45:29 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:45:29 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:45:29 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:45:29 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:45:29 DEBUG ClosureCleaner:  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
18/03/19 07:45:29 DEBUG ClosureCleaner: +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
18/03/19 07:45:29 DEBUG ClosureCleaner:  + declared fields: 2
18/03/19 07:45:29 DEBUG ClosureCleaner:      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
18/03/19 07:45:29 DEBUG ClosureCleaner:      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
18/03/19 07:45:29 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:45:29 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
18/03/19 07:45:29 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
18/03/19 07:45:29 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:45:29 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:45:29 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:45:29 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:45:29 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:45:29 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:45:29 DEBUG ClosureCleaner:  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
18/03/19 07:45:29 INFO SparkContext: Starting job: count at SBMJ_GB.scala:54
18/03/19 07:45:29 INFO DAGScheduler: Got job 7 (count at SBMJ_GB.scala:54) with 96 output partitions
18/03/19 07:45:29 INFO DAGScheduler: Final stage: ResultStage 7 (count at SBMJ_GB.scala:54)
18/03/19 07:45:29 INFO DAGScheduler: Parents of final stage: List()
18/03/19 07:45:29 INFO DAGScheduler: Missing parents: List()
18/03/19 07:45:29 DEBUG DAGScheduler: submitStage(ResultStage 7)
18/03/19 07:45:29 DEBUG DAGScheduler: missing: List()
18/03/19 07:45:29 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[11] at map at SBMJ_GB.scala:52), which has no missing parents
18/03/19 07:45:29 DEBUG DAGScheduler: submitMissingTasks(ResultStage 7)
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 trying to put broadcast_9
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_9
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_9
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_9
18/03/19 07:45:29 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 3.7 KB, free 852.1 MB)
18/03/19 07:45:29 DEBUG BlockManager: Put block broadcast_9 locally took  1 ms
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_9
18/03/19 07:45:29 DEBUG BlockManager: Putting block broadcast_9 without replication took  1 ms
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 trying to put broadcast_9_piece0
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_9_piece0
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_9_piece0
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_9_piece0
18/03/19 07:45:29 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.1 KB, free 852.1 MB)
18/03/19 07:45:29 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.8.100:40919 (size: 2.1 KB, free: 852.6 MB)
18/03/19 07:45:29 DEBUG BlockManagerMaster: Updated info of block broadcast_9_piece0
18/03/19 07:45:29 DEBUG BlockManager: Told master about block broadcast_9_piece0
18/03/19 07:45:29 DEBUG BlockManager: Put block broadcast_9_piece0 locally took  1 ms
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_9_piece0
18/03/19 07:45:29 DEBUG BlockManager: Putting block broadcast_9_piece0 without replication took  1 ms
18/03/19 07:45:29 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1039
18/03/19 07:45:29 INFO DAGScheduler: Submitting 96 missing tasks from ResultStage 7 (MapPartitionsRDD[11] at map at SBMJ_GB.scala:52) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
18/03/19 07:45:29 INFO TaskSchedulerImpl: Adding task set 7.0 with 96 tasks
18/03/19 07:45:29 DEBUG TaskSetManager: Epoch for TaskSet 7.0: 0
18/03/19 07:45:29 DEBUG TaskSetManager: Valid locality levels for TaskSet 7.0: NO_PREF, ANY
18/03/19 07:45:29 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 0
18/03/19 07:45:29 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 116, localhost, executor driver, partition 0, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:29 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 117, localhost, executor driver, partition 1, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:29 INFO Executor: Running task 0.0 in stage 7.0 (TID 116)
18/03/19 07:45:29 INFO Executor: Running task 1.0 in stage 7.0 (TID 117)
18/03/19 07:45:29 DEBUG BlockManager: Getting local block broadcast_9
18/03/19 07:45:29 TRACE BlockInfoManager: Task 116 trying to acquire read lock for broadcast_9
18/03/19 07:45:29 TRACE BlockInfoManager: Task 116 acquired read lock for broadcast_9
18/03/19 07:45:29 DEBUG BlockManager: Level for block broadcast_9 is StorageLevel(disk, memory, deserialized, 1 replicas)
18/03/19 07:45:29 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:0+33554432
18/03/19 07:45:29 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:29 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:33554432+33554432
18/03/19 07:45:29 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanAccum(153)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning accumulator 153
18/03/19 07:45:29 INFO ContextCleaner: Cleaned accumulator 153
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanAccum(173)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning accumulator 173
18/03/19 07:45:29 INFO ContextCleaner: Cleaned accumulator 173
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanAccum(156)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning accumulator 156
18/03/19 07:45:29 INFO ContextCleaner: Cleaned accumulator 156
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanAccum(155)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning accumulator 155
18/03/19 07:45:29 INFO ContextCleaner: Cleaned accumulator 155
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanAccum(160)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning accumulator 160
18/03/19 07:45:29 INFO ContextCleaner: Cleaned accumulator 160
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanAccum(150)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning accumulator 150
18/03/19 07:45:29 INFO ContextCleaner: Cleaned accumulator 150
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanAccum(157)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning accumulator 157
18/03/19 07:45:29 INFO ContextCleaner: Cleaned accumulator 157
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanAccum(174)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning accumulator 174
18/03/19 07:45:29 INFO ContextCleaner: Cleaned accumulator 174
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanAccum(170)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning accumulator 170
18/03/19 07:45:29 INFO ContextCleaner: Cleaned accumulator 170
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanAccum(166)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning accumulator 166
18/03/19 07:45:29 INFO ContextCleaner: Cleaned accumulator 166
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanAccum(158)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning accumulator 158
18/03/19 07:45:29 INFO ContextCleaner: Cleaned accumulator 158
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanAccum(171)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning accumulator 171
18/03/19 07:45:29 INFO ContextCleaner: Cleaned accumulator 171
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanAccum(159)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning accumulator 159
18/03/19 07:45:29 INFO ContextCleaner: Cleaned accumulator 159
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanAccum(154)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning accumulator 154
18/03/19 07:45:29 INFO ContextCleaner: Cleaned accumulator 154
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanAccum(161)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning accumulator 161
18/03/19 07:45:29 INFO ContextCleaner: Cleaned accumulator 161
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanAccum(162)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning accumulator 162
18/03/19 07:45:29 INFO ContextCleaner: Cleaned accumulator 162
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanAccum(163)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning accumulator 163
18/03/19 07:45:29 INFO ContextCleaner: Cleaned accumulator 163
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanAccum(164)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning accumulator 164
18/03/19 07:45:29 INFO ContextCleaner: Cleaned accumulator 164
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanAccum(151)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning accumulator 151
18/03/19 07:45:29 INFO ContextCleaner: Cleaned accumulator 151
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(8)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning broadcast 8
18/03/19 07:45:29 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 8
18/03/19 07:45:29 DEBUG BlockManagerSlaveEndpoint: removing broadcast 8
18/03/19 07:45:29 DEBUG BlockManager: Removing broadcast 8
18/03/19 07:45:29 DEBUG BlockManager: Removing block broadcast_8
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_8
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_8
18/03/19 07:45:29 DEBUG MemoryStore: Block broadcast_8 of size 3984 dropped from memory (free 893515660)
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 trying to remove block broadcast_8
18/03/19 07:45:29 DEBUG BlockManager: Removing block broadcast_8_piece0
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_8_piece0
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_8_piece0
18/03/19 07:45:29 DEBUG MemoryStore: Block broadcast_8_piece0 of size 2184 dropped from memory (free 893517844)
18/03/19 07:45:29 TRACE BlockInfoManager: Task -1024 trying to remove block broadcast_8_piece0
18/03/19 07:45:29 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 192.168.8.100:40919 in memory (size: 2.1 KB, free: 852.6 MB)
18/03/19 07:45:29 DEBUG BlockManagerMaster: Updated info of block broadcast_8_piece0
18/03/19 07:45:29 DEBUG BlockManager: Told master about block broadcast_8_piece0
18/03/19 07:45:29 DEBUG BlockManagerSlaveEndpoint: Done removing broadcast 8, response is 0
18/03/19 07:45:29 DEBUG BlockManagerSlaveEndpoint: Sent response: 0 to 192.168.8.100:45639
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaned broadcast 8
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanAccum(152)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning accumulator 152
18/03/19 07:45:29 INFO ContextCleaner: Cleaned accumulator 152
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanAccum(165)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning accumulator 165
18/03/19 07:45:29 INFO ContextCleaner: Cleaned accumulator 165
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanAccum(169)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning accumulator 169
18/03/19 07:45:29 INFO ContextCleaner: Cleaned accumulator 169
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanAccum(172)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning accumulator 172
18/03/19 07:45:29 INFO ContextCleaner: Cleaned accumulator 172
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanAccum(168)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning accumulator 168
18/03/19 07:45:29 INFO ContextCleaner: Cleaned accumulator 168
18/03/19 07:45:29 DEBUG ContextCleaner: Got cleaning task CleanAccum(167)
18/03/19 07:45:29 DEBUG ContextCleaner: Cleaning accumulator 167
18/03/19 07:45:29 INFO ContextCleaner: Cleaned accumulator 167
18/03/19 07:45:32 INFO Executor: Finished task 1.0 in stage 7.0 (TID 117). 875 bytes result sent to driver
18/03/19 07:45:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:45:32 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 118, localhost, executor driver, partition 2, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:32 INFO Executor: Running task 2.0 in stage 7.0 (TID 118)
18/03/19 07:45:32 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 117) in 3370 ms on localhost (executor driver) (1/96)
18/03/19 07:45:32 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:67108864+33554432
18/03/19 07:45:32 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:33 TRACE BlockInfoManager: Task 116 releasing lock for broadcast_9
18/03/19 07:45:33 INFO Executor: Finished task 0.0 in stage 7.0 (TID 116). 875 bytes result sent to driver
18/03/19 07:45:33 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:45:33 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 119, localhost, executor driver, partition 3, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:33 INFO Executor: Running task 3.0 in stage 7.0 (TID 119)
18/03/19 07:45:33 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 116) in 3698 ms on localhost (executor driver) (2/96)
18/03/19 07:45:33 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:100663296+33554432
18/03/19 07:45:33 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:36 INFO Executor: Finished task 2.0 in stage 7.0 (TID 118). 875 bytes result sent to driver
18/03/19 07:45:36 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:45:36 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 120, localhost, executor driver, partition 4, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:36 INFO Executor: Running task 4.0 in stage 7.0 (TID 120)
18/03/19 07:45:36 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 118) in 3322 ms on localhost (executor driver) (3/96)
18/03/19 07:45:36 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:134217728+33554432
18/03/19 07:45:36 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:36 INFO Executor: Finished task 3.0 in stage 7.0 (TID 119). 875 bytes result sent to driver
18/03/19 07:45:36 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:45:36 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 121, localhost, executor driver, partition 5, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:36 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 119) in 3204 ms on localhost (executor driver) (4/96)
18/03/19 07:45:36 INFO Executor: Running task 5.0 in stage 7.0 (TID 121)
18/03/19 07:45:36 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:167772160+33554432
18/03/19 07:45:36 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:39 INFO Executor: Finished task 4.0 in stage 7.0 (TID 120). 918 bytes result sent to driver
18/03/19 07:45:39 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:45:39 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 122, localhost, executor driver, partition 6, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:39 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 120) in 3189 ms on localhost (executor driver) (5/96)
18/03/19 07:45:39 INFO Executor: Running task 6.0 in stage 7.0 (TID 122)
18/03/19 07:45:39 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:201326592+33554432
18/03/19 07:45:39 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:39 INFO Executor: Finished task 5.0 in stage 7.0 (TID 121). 875 bytes result sent to driver
18/03/19 07:45:39 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:45:39 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 123, localhost, executor driver, partition 7, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:39 INFO Executor: Running task 7.0 in stage 7.0 (TID 123)
18/03/19 07:45:39 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 121) in 2999 ms on localhost (executor driver) (6/96)
18/03/19 07:45:39 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:234881024+33554432
18/03/19 07:45:39 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:41 INFO Executor: Finished task 6.0 in stage 7.0 (TID 122). 875 bytes result sent to driver
18/03/19 07:45:41 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:45:41 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 124, localhost, executor driver, partition 8, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:41 INFO Executor: Running task 8.0 in stage 7.0 (TID 124)
18/03/19 07:45:41 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 122) in 2377 ms on localhost (executor driver) (7/96)
18/03/19 07:45:41 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:268435456+33554432
18/03/19 07:45:41 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:43 INFO Executor: Finished task 7.0 in stage 7.0 (TID 123). 832 bytes result sent to driver
18/03/19 07:45:43 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:45:43 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 125, localhost, executor driver, partition 9, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:43 INFO Executor: Running task 9.0 in stage 7.0 (TID 125)
18/03/19 07:45:43 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 123) in 3945 ms on localhost (executor driver) (8/96)
18/03/19 07:45:43 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:301989888+33554432
18/03/19 07:45:43 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:44 INFO Executor: Finished task 8.0 in stage 7.0 (TID 124). 832 bytes result sent to driver
18/03/19 07:45:44 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:45:44 INFO TaskSetManager: Starting task 10.0 in stage 7.0 (TID 126, localhost, executor driver, partition 10, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:44 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 124) in 3112 ms on localhost (executor driver) (9/96)
18/03/19 07:45:44 INFO Executor: Running task 10.0 in stage 7.0 (TID 126)
18/03/19 07:45:44 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:335544320+33554432
18/03/19 07:45:44 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:46 INFO Executor: Finished task 9.0 in stage 7.0 (TID 125). 875 bytes result sent to driver
18/03/19 07:45:46 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:45:46 INFO TaskSetManager: Starting task 11.0 in stage 7.0 (TID 127, localhost, executor driver, partition 11, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:46 INFO Executor: Running task 11.0 in stage 7.0 (TID 127)
18/03/19 07:45:46 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 125) in 3407 ms on localhost (executor driver) (10/96)
18/03/19 07:45:46 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:369098752+33554432
18/03/19 07:45:46 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:47 INFO Executor: Finished task 10.0 in stage 7.0 (TID 126). 832 bytes result sent to driver
18/03/19 07:45:47 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:45:47 INFO TaskSetManager: Starting task 12.0 in stage 7.0 (TID 128, localhost, executor driver, partition 12, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:47 INFO TaskSetManager: Finished task 10.0 in stage 7.0 (TID 126) in 2787 ms on localhost (executor driver) (11/96)
18/03/19 07:45:47 INFO Executor: Running task 12.0 in stage 7.0 (TID 128)
18/03/19 07:45:47 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:402653184+33554432
18/03/19 07:45:47 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:49 INFO Executor: Finished task 11.0 in stage 7.0 (TID 127). 875 bytes result sent to driver
18/03/19 07:45:49 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:45:49 INFO TaskSetManager: Starting task 13.0 in stage 7.0 (TID 129, localhost, executor driver, partition 13, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:49 INFO TaskSetManager: Finished task 11.0 in stage 7.0 (TID 127) in 3004 ms on localhost (executor driver) (12/96)
18/03/19 07:45:49 INFO Executor: Running task 13.0 in stage 7.0 (TID 129)
18/03/19 07:45:49 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:436207616+33554432
18/03/19 07:45:49 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:50 INFO Executor: Finished task 12.0 in stage 7.0 (TID 128). 832 bytes result sent to driver
18/03/19 07:45:50 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:45:50 INFO TaskSetManager: Starting task 14.0 in stage 7.0 (TID 130, localhost, executor driver, partition 14, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:50 INFO TaskSetManager: Finished task 12.0 in stage 7.0 (TID 128) in 3092 ms on localhost (executor driver) (13/96)
18/03/19 07:45:50 INFO Executor: Running task 14.0 in stage 7.0 (TID 130)
18/03/19 07:45:50 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:469762048+33554432
18/03/19 07:45:50 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:52 INFO Executor: Finished task 13.0 in stage 7.0 (TID 129). 875 bytes result sent to driver
18/03/19 07:45:52 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:45:52 INFO TaskSetManager: Starting task 15.0 in stage 7.0 (TID 131, localhost, executor driver, partition 15, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:52 INFO Executor: Running task 15.0 in stage 7.0 (TID 131)
18/03/19 07:45:52 INFO TaskSetManager: Finished task 13.0 in stage 7.0 (TID 129) in 2665 ms on localhost (executor driver) (14/96)
18/03/19 07:45:52 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:503316480+33554432
18/03/19 07:45:52 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:53 INFO Executor: Finished task 14.0 in stage 7.0 (TID 130). 875 bytes result sent to driver
18/03/19 07:45:53 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:45:53 INFO TaskSetManager: Starting task 16.0 in stage 7.0 (TID 132, localhost, executor driver, partition 16, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:53 INFO Executor: Running task 16.0 in stage 7.0 (TID 132)
18/03/19 07:45:53 INFO TaskSetManager: Finished task 14.0 in stage 7.0 (TID 130) in 3252 ms on localhost (executor driver) (15/96)
18/03/19 07:45:53 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:536870912+33554432
18/03/19 07:45:53 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:55 INFO Executor: Finished task 15.0 in stage 7.0 (TID 131). 875 bytes result sent to driver
18/03/19 07:45:55 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:45:55 INFO TaskSetManager: Starting task 17.0 in stage 7.0 (TID 133, localhost, executor driver, partition 17, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:55 INFO Executor: Running task 17.0 in stage 7.0 (TID 133)
18/03/19 07:45:55 INFO TaskSetManager: Finished task 15.0 in stage 7.0 (TID 131) in 3441 ms on localhost (executor driver) (16/96)
18/03/19 07:45:55 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:570425344+33554432
18/03/19 07:45:55 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:56 INFO Executor: Finished task 16.0 in stage 7.0 (TID 132). 875 bytes result sent to driver
18/03/19 07:45:56 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:45:56 INFO TaskSetManager: Starting task 18.0 in stage 7.0 (TID 134, localhost, executor driver, partition 18, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:56 INFO Executor: Running task 18.0 in stage 7.0 (TID 134)
18/03/19 07:45:56 INFO TaskSetManager: Finished task 16.0 in stage 7.0 (TID 132) in 3099 ms on localhost (executor driver) (17/96)
18/03/19 07:45:56 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:603979776+33554432
18/03/19 07:45:56 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:45:58 INFO Executor: Finished task 17.0 in stage 7.0 (TID 133). 832 bytes result sent to driver
18/03/19 07:45:58 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:45:58 INFO TaskSetManager: Starting task 19.0 in stage 7.0 (TID 135, localhost, executor driver, partition 19, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:45:58 INFO TaskSetManager: Finished task 17.0 in stage 7.0 (TID 133) in 3024 ms on localhost (executor driver) (18/96)
18/03/19 07:45:58 INFO Executor: Running task 19.0 in stage 7.0 (TID 135)
18/03/19 07:45:58 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:637534208+33554432
18/03/19 07:45:58 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:00 INFO Executor: Finished task 18.0 in stage 7.0 (TID 134). 875 bytes result sent to driver
18/03/19 07:46:00 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:00 INFO TaskSetManager: Starting task 20.0 in stage 7.0 (TID 136, localhost, executor driver, partition 20, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:00 INFO Executor: Running task 20.0 in stage 7.0 (TID 136)
18/03/19 07:46:00 INFO TaskSetManager: Finished task 18.0 in stage 7.0 (TID 134) in 3201 ms on localhost (executor driver) (19/96)
18/03/19 07:46:00 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:671088640+33554432
18/03/19 07:46:00 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:02 INFO Executor: Finished task 19.0 in stage 7.0 (TID 135). 918 bytes result sent to driver
18/03/19 07:46:02 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:02 INFO TaskSetManager: Starting task 21.0 in stage 7.0 (TID 137, localhost, executor driver, partition 21, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:02 INFO TaskSetManager: Finished task 19.0 in stage 7.0 (TID 135) in 3532 ms on localhost (executor driver) (20/96)
18/03/19 07:46:02 INFO Executor: Running task 21.0 in stage 7.0 (TID 137)
18/03/19 07:46:02 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:704643072+33554432
18/03/19 07:46:02 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:02 INFO Executor: Finished task 20.0 in stage 7.0 (TID 136). 875 bytes result sent to driver
18/03/19 07:46:02 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:02 INFO TaskSetManager: Starting task 22.0 in stage 7.0 (TID 138, localhost, executor driver, partition 22, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:02 INFO Executor: Running task 22.0 in stage 7.0 (TID 138)
18/03/19 07:46:02 INFO TaskSetManager: Finished task 20.0 in stage 7.0 (TID 136) in 2661 ms on localhost (executor driver) (21/96)
18/03/19 07:46:02 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:738197504+33554432
18/03/19 07:46:02 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:05 INFO Executor: Finished task 21.0 in stage 7.0 (TID 137). 875 bytes result sent to driver
18/03/19 07:46:05 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:05 INFO TaskSetManager: Starting task 23.0 in stage 7.0 (TID 139, localhost, executor driver, partition 23, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:05 INFO Executor: Running task 23.0 in stage 7.0 (TID 139)
18/03/19 07:46:05 INFO TaskSetManager: Finished task 21.0 in stage 7.0 (TID 137) in 3114 ms on localhost (executor driver) (22/96)
18/03/19 07:46:05 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:771751936+33554432
18/03/19 07:46:05 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:05 INFO Executor: Finished task 22.0 in stage 7.0 (TID 138). 875 bytes result sent to driver
18/03/19 07:46:05 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:05 INFO TaskSetManager: Starting task 24.0 in stage 7.0 (TID 140, localhost, executor driver, partition 24, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:05 INFO TaskSetManager: Finished task 22.0 in stage 7.0 (TID 138) in 3090 ms on localhost (executor driver) (23/96)
18/03/19 07:46:05 INFO Executor: Running task 24.0 in stage 7.0 (TID 140)
18/03/19 07:46:05 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:805306368+33554432
18/03/19 07:46:05 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:08 INFO Executor: Finished task 23.0 in stage 7.0 (TID 139). 832 bytes result sent to driver
18/03/19 07:46:08 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:08 INFO TaskSetManager: Starting task 25.0 in stage 7.0 (TID 141, localhost, executor driver, partition 25, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:08 INFO TaskSetManager: Finished task 23.0 in stage 7.0 (TID 139) in 2831 ms on localhost (executor driver) (24/96)
18/03/19 07:46:08 INFO Executor: Running task 25.0 in stage 7.0 (TID 141)
18/03/19 07:46:08 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:838860800+33554432
18/03/19 07:46:08 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:09 INFO Executor: Finished task 24.0 in stage 7.0 (TID 140). 875 bytes result sent to driver
18/03/19 07:46:09 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:09 INFO TaskSetManager: Starting task 26.0 in stage 7.0 (TID 142, localhost, executor driver, partition 26, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:09 INFO TaskSetManager: Finished task 24.0 in stage 7.0 (TID 140) in 3122 ms on localhost (executor driver) (25/96)
18/03/19 07:46:09 INFO Executor: Running task 26.0 in stage 7.0 (TID 142)
18/03/19 07:46:09 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:872415232+33554432
18/03/19 07:46:09 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:11 INFO Executor: Finished task 25.0 in stage 7.0 (TID 141). 875 bytes result sent to driver
18/03/19 07:46:11 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:11 INFO TaskSetManager: Starting task 27.0 in stage 7.0 (TID 143, localhost, executor driver, partition 27, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:11 INFO TaskSetManager: Finished task 25.0 in stage 7.0 (TID 141) in 3189 ms on localhost (executor driver) (26/96)
18/03/19 07:46:11 INFO Executor: Running task 27.0 in stage 7.0 (TID 143)
18/03/19 07:46:11 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:905969664+33554432
18/03/19 07:46:11 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:11 INFO Executor: Finished task 26.0 in stage 7.0 (TID 142). 875 bytes result sent to driver
18/03/19 07:46:11 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:11 INFO TaskSetManager: Starting task 28.0 in stage 7.0 (TID 144, localhost, executor driver, partition 28, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:11 INFO Executor: Running task 28.0 in stage 7.0 (TID 144)
18/03/19 07:46:11 INFO TaskSetManager: Finished task 26.0 in stage 7.0 (TID 142) in 2876 ms on localhost (executor driver) (27/96)
18/03/19 07:46:11 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:939524096+33554432
18/03/19 07:46:11 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:14 INFO Executor: Finished task 27.0 in stage 7.0 (TID 143). 875 bytes result sent to driver
18/03/19 07:46:14 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:14 INFO TaskSetManager: Starting task 29.0 in stage 7.0 (TID 145, localhost, executor driver, partition 29, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:14 INFO TaskSetManager: Finished task 27.0 in stage 7.0 (TID 143) in 3005 ms on localhost (executor driver) (28/96)
18/03/19 07:46:14 INFO Executor: Running task 29.0 in stage 7.0 (TID 145)
18/03/19 07:46:14 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:973078528+33554432
18/03/19 07:46:14 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:15 INFO Executor: Finished task 28.0 in stage 7.0 (TID 144). 832 bytes result sent to driver
18/03/19 07:46:15 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:15 INFO TaskSetManager: Starting task 30.0 in stage 7.0 (TID 146, localhost, executor driver, partition 30, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:15 INFO Executor: Running task 30.0 in stage 7.0 (TID 146)
18/03/19 07:46:15 INFO TaskSetManager: Finished task 28.0 in stage 7.0 (TID 144) in 3133 ms on localhost (executor driver) (29/96)
18/03/19 07:46:15 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1006632960+33554432
18/03/19 07:46:15 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:17 INFO Executor: Finished task 29.0 in stage 7.0 (TID 145). 875 bytes result sent to driver
18/03/19 07:46:17 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:17 INFO TaskSetManager: Starting task 31.0 in stage 7.0 (TID 147, localhost, executor driver, partition 31, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:17 INFO Executor: Running task 31.0 in stage 7.0 (TID 147)
18/03/19 07:46:17 INFO TaskSetManager: Finished task 29.0 in stage 7.0 (TID 145) in 3112 ms on localhost (executor driver) (30/96)
18/03/19 07:46:17 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1040187392+33554432
18/03/19 07:46:17 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:18 INFO Executor: Finished task 30.0 in stage 7.0 (TID 146). 875 bytes result sent to driver
18/03/19 07:46:18 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:18 INFO TaskSetManager: Starting task 32.0 in stage 7.0 (TID 148, localhost, executor driver, partition 32, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:18 INFO Executor: Running task 32.0 in stage 7.0 (TID 148)
18/03/19 07:46:18 INFO TaskSetManager: Finished task 30.0 in stage 7.0 (TID 146) in 3283 ms on localhost (executor driver) (31/96)
18/03/19 07:46:18 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1073741824+33554432
18/03/19 07:46:18 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:18 TRACE HeartbeatReceiver: Checking for hosts with no recent heartbeats in HeartbeatReceiver.
18/03/19 07:46:20 INFO Executor: Finished task 31.0 in stage 7.0 (TID 147). 875 bytes result sent to driver
18/03/19 07:46:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:20 INFO TaskSetManager: Starting task 33.0 in stage 7.0 (TID 149, localhost, executor driver, partition 33, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:20 INFO Executor: Running task 33.0 in stage 7.0 (TID 149)
18/03/19 07:46:20 INFO TaskSetManager: Finished task 31.0 in stage 7.0 (TID 147) in 3229 ms on localhost (executor driver) (32/96)
18/03/19 07:46:20 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1107296256+33554432
18/03/19 07:46:20 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:21 INFO Executor: Finished task 32.0 in stage 7.0 (TID 148). 875 bytes result sent to driver
18/03/19 07:46:21 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:21 INFO TaskSetManager: Starting task 34.0 in stage 7.0 (TID 150, localhost, executor driver, partition 34, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:21 INFO Executor: Running task 34.0 in stage 7.0 (TID 150)
18/03/19 07:46:21 INFO TaskSetManager: Finished task 32.0 in stage 7.0 (TID 148) in 2900 ms on localhost (executor driver) (33/96)
18/03/19 07:46:21 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1140850688+33554432
18/03/19 07:46:21 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:23 INFO Executor: Finished task 34.0 in stage 7.0 (TID 150). 875 bytes result sent to driver
18/03/19 07:46:23 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:23 INFO TaskSetManager: Starting task 35.0 in stage 7.0 (TID 151, localhost, executor driver, partition 35, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:23 INFO Executor: Running task 35.0 in stage 7.0 (TID 151)
18/03/19 07:46:23 INFO TaskSetManager: Finished task 34.0 in stage 7.0 (TID 150) in 2601 ms on localhost (executor driver) (34/96)
18/03/19 07:46:23 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1174405120+33554432
18/03/19 07:46:23 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:24 INFO Executor: Finished task 33.0 in stage 7.0 (TID 149). 875 bytes result sent to driver
18/03/19 07:46:24 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:24 INFO TaskSetManager: Starting task 36.0 in stage 7.0 (TID 152, localhost, executor driver, partition 36, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:24 INFO Executor: Running task 36.0 in stage 7.0 (TID 152)
18/03/19 07:46:24 INFO TaskSetManager: Finished task 33.0 in stage 7.0 (TID 149) in 3706 ms on localhost (executor driver) (35/96)
18/03/19 07:46:24 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1207959552+33554432
18/03/19 07:46:24 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:26 INFO Executor: Finished task 35.0 in stage 7.0 (TID 151). 875 bytes result sent to driver
18/03/19 07:46:26 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:26 INFO TaskSetManager: Starting task 37.0 in stage 7.0 (TID 153, localhost, executor driver, partition 37, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:26 INFO Executor: Running task 37.0 in stage 7.0 (TID 153)
18/03/19 07:46:26 INFO TaskSetManager: Finished task 35.0 in stage 7.0 (TID 151) in 2967 ms on localhost (executor driver) (36/96)
18/03/19 07:46:26 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1241513984+33554432
18/03/19 07:46:26 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:27 INFO Executor: Finished task 36.0 in stage 7.0 (TID 152). 832 bytes result sent to driver
18/03/19 07:46:27 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:27 INFO TaskSetManager: Starting task 38.0 in stage 7.0 (TID 154, localhost, executor driver, partition 38, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:27 INFO Executor: Running task 38.0 in stage 7.0 (TID 154)
18/03/19 07:46:27 INFO TaskSetManager: Finished task 36.0 in stage 7.0 (TID 152) in 2856 ms on localhost (executor driver) (37/96)
18/03/19 07:46:27 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1275068416+33554432
18/03/19 07:46:27 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:30 INFO Executor: Finished task 37.0 in stage 7.0 (TID 153). 875 bytes result sent to driver
18/03/19 07:46:30 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:30 INFO TaskSetManager: Starting task 39.0 in stage 7.0 (TID 155, localhost, executor driver, partition 39, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:30 INFO Executor: Running task 39.0 in stage 7.0 (TID 155)
18/03/19 07:46:30 INFO TaskSetManager: Finished task 37.0 in stage 7.0 (TID 153) in 3475 ms on localhost (executor driver) (38/96)
18/03/19 07:46:30 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1308622848+33554432
18/03/19 07:46:30 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:30 INFO Executor: Finished task 38.0 in stage 7.0 (TID 154). 875 bytes result sent to driver
18/03/19 07:46:30 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:30 INFO TaskSetManager: Starting task 40.0 in stage 7.0 (TID 156, localhost, executor driver, partition 40, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:30 INFO Executor: Running task 40.0 in stage 7.0 (TID 156)
18/03/19 07:46:30 INFO TaskSetManager: Finished task 38.0 in stage 7.0 (TID 154) in 3084 ms on localhost (executor driver) (39/96)
18/03/19 07:46:30 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1342177280+33554432
18/03/19 07:46:30 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:32 INFO Executor: Finished task 40.0 in stage 7.0 (TID 156). 875 bytes result sent to driver
18/03/19 07:46:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:32 INFO TaskSetManager: Starting task 41.0 in stage 7.0 (TID 157, localhost, executor driver, partition 41, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:32 INFO TaskSetManager: Finished task 40.0 in stage 7.0 (TID 156) in 2420 ms on localhost (executor driver) (40/96)
18/03/19 07:46:32 INFO Executor: Running task 41.0 in stage 7.0 (TID 157)
18/03/19 07:46:32 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1375731712+33554432
18/03/19 07:46:32 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:33 INFO Executor: Finished task 39.0 in stage 7.0 (TID 155). 832 bytes result sent to driver
18/03/19 07:46:33 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:33 INFO TaskSetManager: Starting task 42.0 in stage 7.0 (TID 158, localhost, executor driver, partition 42, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:33 INFO Executor: Running task 42.0 in stage 7.0 (TID 158)
18/03/19 07:46:33 INFO TaskSetManager: Finished task 39.0 in stage 7.0 (TID 155) in 3501 ms on localhost (executor driver) (41/96)
18/03/19 07:46:33 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1409286144+33554432
18/03/19 07:46:33 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:35 INFO Executor: Finished task 41.0 in stage 7.0 (TID 157). 875 bytes result sent to driver
18/03/19 07:46:35 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:35 INFO TaskSetManager: Starting task 43.0 in stage 7.0 (TID 159, localhost, executor driver, partition 43, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:35 INFO Executor: Running task 43.0 in stage 7.0 (TID 159)
18/03/19 07:46:35 INFO TaskSetManager: Finished task 41.0 in stage 7.0 (TID 157) in 3189 ms on localhost (executor driver) (42/96)
18/03/19 07:46:35 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1442840576+33554432
18/03/19 07:46:35 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:36 INFO Executor: Finished task 42.0 in stage 7.0 (TID 158). 875 bytes result sent to driver
18/03/19 07:46:36 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:36 INFO TaskSetManager: Starting task 44.0 in stage 7.0 (TID 160, localhost, executor driver, partition 44, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:36 INFO Executor: Running task 44.0 in stage 7.0 (TID 160)
18/03/19 07:46:36 INFO TaskSetManager: Finished task 42.0 in stage 7.0 (TID 158) in 2709 ms on localhost (executor driver) (43/96)
18/03/19 07:46:36 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1476395008+33554432
18/03/19 07:46:36 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:39 INFO Executor: Finished task 43.0 in stage 7.0 (TID 159). 832 bytes result sent to driver
18/03/19 07:46:39 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:39 INFO TaskSetManager: Starting task 45.0 in stage 7.0 (TID 161, localhost, executor driver, partition 45, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:39 INFO TaskSetManager: Finished task 43.0 in stage 7.0 (TID 159) in 3079 ms on localhost (executor driver) (44/96)
18/03/19 07:46:39 INFO Executor: Running task 45.0 in stage 7.0 (TID 161)
18/03/19 07:46:39 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1509949440+33554432
18/03/19 07:46:39 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:39 INFO Executor: Finished task 44.0 in stage 7.0 (TID 160). 832 bytes result sent to driver
18/03/19 07:46:39 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:39 INFO TaskSetManager: Starting task 46.0 in stage 7.0 (TID 162, localhost, executor driver, partition 46, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:39 INFO Executor: Running task 46.0 in stage 7.0 (TID 162)
18/03/19 07:46:39 INFO TaskSetManager: Finished task 44.0 in stage 7.0 (TID 160) in 2920 ms on localhost (executor driver) (45/96)
18/03/19 07:46:39 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1543503872+33554432
18/03/19 07:46:39 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:42 INFO Executor: Finished task 45.0 in stage 7.0 (TID 161). 875 bytes result sent to driver
18/03/19 07:46:42 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:42 INFO TaskSetManager: Starting task 47.0 in stage 7.0 (TID 163, localhost, executor driver, partition 47, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:42 INFO Executor: Running task 47.0 in stage 7.0 (TID 163)
18/03/19 07:46:42 INFO TaskSetManager: Finished task 45.0 in stage 7.0 (TID 161) in 2967 ms on localhost (executor driver) (46/96)
18/03/19 07:46:42 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1577058304+33554432
18/03/19 07:46:42 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:42 INFO Executor: Finished task 46.0 in stage 7.0 (TID 162). 875 bytes result sent to driver
18/03/19 07:46:42 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:42 INFO TaskSetManager: Starting task 48.0 in stage 7.0 (TID 164, localhost, executor driver, partition 48, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:42 INFO TaskSetManager: Finished task 46.0 in stage 7.0 (TID 162) in 3302 ms on localhost (executor driver) (47/96)
18/03/19 07:46:42 INFO Executor: Running task 48.0 in stage 7.0 (TID 164)
18/03/19 07:46:42 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1610612736+33554432
18/03/19 07:46:42 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:45 INFO Executor: Finished task 47.0 in stage 7.0 (TID 163). 875 bytes result sent to driver
18/03/19 07:46:45 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:45 INFO TaskSetManager: Starting task 49.0 in stage 7.0 (TID 165, localhost, executor driver, partition 49, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:45 INFO Executor: Running task 49.0 in stage 7.0 (TID 165)
18/03/19 07:46:45 INFO TaskSetManager: Finished task 47.0 in stage 7.0 (TID 163) in 3151 ms on localhost (executor driver) (48/96)
18/03/19 07:46:45 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1644167168+33554432
18/03/19 07:46:45 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:45 INFO Executor: Finished task 48.0 in stage 7.0 (TID 164). 832 bytes result sent to driver
18/03/19 07:46:45 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:45 INFO TaskSetManager: Starting task 50.0 in stage 7.0 (TID 166, localhost, executor driver, partition 50, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:45 INFO Executor: Running task 50.0 in stage 7.0 (TID 166)
18/03/19 07:46:45 INFO TaskSetManager: Finished task 48.0 in stage 7.0 (TID 164) in 2755 ms on localhost (executor driver) (49/96)
18/03/19 07:46:45 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1677721600+33554432
18/03/19 07:46:45 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:48 INFO Executor: Finished task 49.0 in stage 7.0 (TID 165). 875 bytes result sent to driver
18/03/19 07:46:48 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:48 INFO TaskSetManager: Starting task 51.0 in stage 7.0 (TID 167, localhost, executor driver, partition 51, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:48 INFO Executor: Running task 51.0 in stage 7.0 (TID 167)
18/03/19 07:46:48 INFO TaskSetManager: Finished task 49.0 in stage 7.0 (TID 165) in 2890 ms on localhost (executor driver) (50/96)
18/03/19 07:46:48 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1711276032+33554432
18/03/19 07:46:48 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:48 INFO Executor: Finished task 50.0 in stage 7.0 (TID 166). 875 bytes result sent to driver
18/03/19 07:46:48 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:48 INFO TaskSetManager: Starting task 52.0 in stage 7.0 (TID 168, localhost, executor driver, partition 52, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:48 INFO Executor: Running task 52.0 in stage 7.0 (TID 168)
18/03/19 07:46:48 INFO TaskSetManager: Finished task 50.0 in stage 7.0 (TID 166) in 3001 ms on localhost (executor driver) (51/96)
18/03/19 07:46:48 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1744830464+33554432
18/03/19 07:46:48 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:50 INFO Executor: Finished task 51.0 in stage 7.0 (TID 167). 875 bytes result sent to driver
18/03/19 07:46:50 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:50 INFO TaskSetManager: Starting task 53.0 in stage 7.0 (TID 169, localhost, executor driver, partition 53, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:50 INFO Executor: Running task 53.0 in stage 7.0 (TID 169)
18/03/19 07:46:50 INFO TaskSetManager: Finished task 51.0 in stage 7.0 (TID 167) in 2851 ms on localhost (executor driver) (52/96)
18/03/19 07:46:50 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1778384896+33554432
18/03/19 07:46:50 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:51 INFO Executor: Finished task 52.0 in stage 7.0 (TID 168). 875 bytes result sent to driver
18/03/19 07:46:51 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:51 INFO TaskSetManager: Starting task 54.0 in stage 7.0 (TID 170, localhost, executor driver, partition 54, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:51 INFO Executor: Running task 54.0 in stage 7.0 (TID 170)
18/03/19 07:46:51 INFO TaskSetManager: Finished task 52.0 in stage 7.0 (TID 168) in 2896 ms on localhost (executor driver) (53/96)
18/03/19 07:46:51 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1811939328+33554432
18/03/19 07:46:51 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:53 INFO Executor: Finished task 53.0 in stage 7.0 (TID 169). 832 bytes result sent to driver
18/03/19 07:46:53 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:53 INFO TaskSetManager: Starting task 55.0 in stage 7.0 (TID 171, localhost, executor driver, partition 55, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:53 INFO Executor: Running task 55.0 in stage 7.0 (TID 171)
18/03/19 07:46:53 INFO TaskSetManager: Finished task 53.0 in stage 7.0 (TID 169) in 3058 ms on localhost (executor driver) (54/96)
18/03/19 07:46:53 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1845493760+33554432
18/03/19 07:46:53 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:54 INFO Executor: Finished task 54.0 in stage 7.0 (TID 170). 875 bytes result sent to driver
18/03/19 07:46:54 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:54 INFO TaskSetManager: Starting task 56.0 in stage 7.0 (TID 172, localhost, executor driver, partition 56, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:54 INFO TaskSetManager: Finished task 54.0 in stage 7.0 (TID 170) in 2880 ms on localhost (executor driver) (55/96)
18/03/19 07:46:54 INFO Executor: Running task 56.0 in stage 7.0 (TID 172)
18/03/19 07:46:54 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1879048192+33554432
18/03/19 07:46:54 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:56 INFO Executor: Finished task 55.0 in stage 7.0 (TID 171). 875 bytes result sent to driver
18/03/19 07:46:56 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:56 INFO TaskSetManager: Starting task 57.0 in stage 7.0 (TID 173, localhost, executor driver, partition 57, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:56 INFO TaskSetManager: Finished task 55.0 in stage 7.0 (TID 171) in 2851 ms on localhost (executor driver) (56/96)
18/03/19 07:46:56 INFO Executor: Running task 57.0 in stage 7.0 (TID 173)
18/03/19 07:46:56 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1912602624+33554432
18/03/19 07:46:56 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:57 INFO Executor: Finished task 56.0 in stage 7.0 (TID 172). 875 bytes result sent to driver
18/03/19 07:46:57 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:57 INFO TaskSetManager: Starting task 58.0 in stage 7.0 (TID 174, localhost, executor driver, partition 58, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:57 INFO TaskSetManager: Finished task 56.0 in stage 7.0 (TID 172) in 3466 ms on localhost (executor driver) (57/96)
18/03/19 07:46:57 INFO Executor: Running task 58.0 in stage 7.0 (TID 174)
18/03/19 07:46:57 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1946157056+33554432
18/03/19 07:46:57 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:46:59 INFO Executor: Finished task 57.0 in stage 7.0 (TID 173). 875 bytes result sent to driver
18/03/19 07:46:59 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:46:59 INFO TaskSetManager: Starting task 59.0 in stage 7.0 (TID 175, localhost, executor driver, partition 59, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:46:59 INFO TaskSetManager: Finished task 57.0 in stage 7.0 (TID 173) in 2708 ms on localhost (executor driver) (58/96)
18/03/19 07:46:59 INFO Executor: Running task 59.0 in stage 7.0 (TID 175)
18/03/19 07:46:59 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1979711488+33554432
18/03/19 07:46:59 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:00 INFO Executor: Finished task 58.0 in stage 7.0 (TID 174). 875 bytes result sent to driver
18/03/19 07:47:00 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:00 INFO TaskSetManager: Starting task 60.0 in stage 7.0 (TID 176, localhost, executor driver, partition 60, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:00 INFO Executor: Running task 60.0 in stage 7.0 (TID 176)
18/03/19 07:47:00 INFO TaskSetManager: Finished task 58.0 in stage 7.0 (TID 174) in 2847 ms on localhost (executor driver) (59/96)
18/03/19 07:47:00 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2013265920+33554432
18/03/19 07:47:00 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:03 INFO Executor: Finished task 59.0 in stage 7.0 (TID 175). 875 bytes result sent to driver
18/03/19 07:47:03 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:03 INFO TaskSetManager: Starting task 61.0 in stage 7.0 (TID 177, localhost, executor driver, partition 61, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:03 INFO Executor: Running task 61.0 in stage 7.0 (TID 177)
18/03/19 07:47:03 INFO TaskSetManager: Finished task 59.0 in stage 7.0 (TID 175) in 3588 ms on localhost (executor driver) (60/96)
18/03/19 07:47:03 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2046820352+33554432
18/03/19 07:47:03 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:03 INFO Executor: Finished task 60.0 in stage 7.0 (TID 176). 875 bytes result sent to driver
18/03/19 07:47:03 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:03 INFO TaskSetManager: Starting task 62.0 in stage 7.0 (TID 178, localhost, executor driver, partition 62, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:03 INFO Executor: Running task 62.0 in stage 7.0 (TID 178)
18/03/19 07:47:03 INFO TaskSetManager: Finished task 60.0 in stage 7.0 (TID 176) in 2669 ms on localhost (executor driver) (61/96)
18/03/19 07:47:03 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2080374784+33554432
18/03/19 07:47:03 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:06 INFO Executor: Finished task 61.0 in stage 7.0 (TID 177). 832 bytes result sent to driver
18/03/19 07:47:06 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:06 INFO TaskSetManager: Starting task 63.0 in stage 7.0 (TID 179, localhost, executor driver, partition 63, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:06 INFO Executor: Running task 63.0 in stage 7.0 (TID 179)
18/03/19 07:47:06 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2113929216+33554432
18/03/19 07:47:06 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:06 INFO TaskSetManager: Finished task 61.0 in stage 7.0 (TID 177) in 3112 ms on localhost (executor driver) (62/96)
18/03/19 07:47:06 INFO Executor: Finished task 62.0 in stage 7.0 (TID 178). 875 bytes result sent to driver
18/03/19 07:47:06 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:06 INFO TaskSetManager: Starting task 64.0 in stage 7.0 (TID 180, localhost, executor driver, partition 64, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:06 INFO Executor: Running task 64.0 in stage 7.0 (TID 180)
18/03/19 07:47:06 INFO TaskSetManager: Finished task 62.0 in stage 7.0 (TID 178) in 3261 ms on localhost (executor driver) (63/96)
18/03/19 07:47:06 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2147483648+33554432
18/03/19 07:47:06 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:09 INFO Executor: Finished task 63.0 in stage 7.0 (TID 179). 875 bytes result sent to driver
18/03/19 07:47:09 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:09 INFO TaskSetManager: Starting task 65.0 in stage 7.0 (TID 181, localhost, executor driver, partition 65, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:09 INFO Executor: Running task 65.0 in stage 7.0 (TID 181)
18/03/19 07:47:09 INFO TaskSetManager: Finished task 63.0 in stage 7.0 (TID 179) in 3032 ms on localhost (executor driver) (64/96)
18/03/19 07:47:09 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2181038080+33554432
18/03/19 07:47:09 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:09 INFO Executor: Finished task 64.0 in stage 7.0 (TID 180). 875 bytes result sent to driver
18/03/19 07:47:09 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:09 INFO TaskSetManager: Starting task 66.0 in stage 7.0 (TID 182, localhost, executor driver, partition 66, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:09 INFO TaskSetManager: Finished task 64.0 in stage 7.0 (TID 180) in 3191 ms on localhost (executor driver) (65/96)
18/03/19 07:47:09 INFO Executor: Running task 66.0 in stage 7.0 (TID 182)
18/03/19 07:47:09 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2214592512+33554432
18/03/19 07:47:09 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:12 INFO Executor: Finished task 65.0 in stage 7.0 (TID 181). 832 bytes result sent to driver
18/03/19 07:47:12 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:12 INFO TaskSetManager: Starting task 67.0 in stage 7.0 (TID 183, localhost, executor driver, partition 67, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:12 INFO Executor: Running task 67.0 in stage 7.0 (TID 183)
18/03/19 07:47:12 INFO TaskSetManager: Finished task 65.0 in stage 7.0 (TID 181) in 2934 ms on localhost (executor driver) (66/96)
18/03/19 07:47:12 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2248146944+33554432
18/03/19 07:47:12 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:12 INFO Executor: Finished task 66.0 in stage 7.0 (TID 182). 875 bytes result sent to driver
18/03/19 07:47:12 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:12 INFO TaskSetManager: Starting task 68.0 in stage 7.0 (TID 184, localhost, executor driver, partition 68, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:12 INFO Executor: Running task 68.0 in stage 7.0 (TID 184)
18/03/19 07:47:12 INFO TaskSetManager: Finished task 66.0 in stage 7.0 (TID 182) in 3083 ms on localhost (executor driver) (67/96)
18/03/19 07:47:12 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2281701376+33554432
18/03/19 07:47:12 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:15 INFO Executor: Finished task 67.0 in stage 7.0 (TID 183). 875 bytes result sent to driver
18/03/19 07:47:15 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:15 INFO TaskSetManager: Starting task 69.0 in stage 7.0 (TID 185, localhost, executor driver, partition 69, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:15 INFO Executor: Running task 69.0 in stage 7.0 (TID 185)
18/03/19 07:47:15 INFO TaskSetManager: Finished task 67.0 in stage 7.0 (TID 183) in 3496 ms on localhost (executor driver) (68/96)
18/03/19 07:47:15 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2315255808+33554432
18/03/19 07:47:15 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:15 INFO Executor: Finished task 68.0 in stage 7.0 (TID 184). 875 bytes result sent to driver
18/03/19 07:47:15 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:15 INFO TaskSetManager: Starting task 70.0 in stage 7.0 (TID 186, localhost, executor driver, partition 70, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:15 INFO TaskSetManager: Finished task 68.0 in stage 7.0 (TID 184) in 3088 ms on localhost (executor driver) (69/96)
18/03/19 07:47:15 INFO Executor: Running task 70.0 in stage 7.0 (TID 186)
18/03/19 07:47:15 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2348810240+33554432
18/03/19 07:47:15 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:18 TRACE HeartbeatReceiver: Checking for hosts with no recent heartbeats in HeartbeatReceiver.
18/03/19 07:47:18 INFO Executor: Finished task 69.0 in stage 7.0 (TID 185). 832 bytes result sent to driver
18/03/19 07:47:18 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:18 INFO TaskSetManager: Starting task 71.0 in stage 7.0 (TID 187, localhost, executor driver, partition 71, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:18 INFO Executor: Running task 71.0 in stage 7.0 (TID 187)
18/03/19 07:47:18 INFO TaskSetManager: Finished task 69.0 in stage 7.0 (TID 185) in 3064 ms on localhost (executor driver) (70/96)
18/03/19 07:47:18 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2382364672+33554432
18/03/19 07:47:18 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:18 INFO Executor: Finished task 70.0 in stage 7.0 (TID 186). 875 bytes result sent to driver
18/03/19 07:47:18 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:18 INFO TaskSetManager: Starting task 72.0 in stage 7.0 (TID 188, localhost, executor driver, partition 72, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:18 INFO Executor: Running task 72.0 in stage 7.0 (TID 188)
18/03/19 07:47:18 INFO TaskSetManager: Finished task 70.0 in stage 7.0 (TID 186) in 3050 ms on localhost (executor driver) (71/96)
18/03/19 07:47:18 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2415919104+33554432
18/03/19 07:47:18 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:21 INFO Executor: Finished task 71.0 in stage 7.0 (TID 187). 875 bytes result sent to driver
18/03/19 07:47:21 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:21 INFO TaskSetManager: Starting task 73.0 in stage 7.0 (TID 189, localhost, executor driver, partition 73, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:21 INFO TaskSetManager: Finished task 71.0 in stage 7.0 (TID 187) in 2808 ms on localhost (executor driver) (72/96)
18/03/19 07:47:21 INFO Executor: Running task 73.0 in stage 7.0 (TID 189)
18/03/19 07:47:21 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2449473536+33554432
18/03/19 07:47:21 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:22 INFO Executor: Finished task 72.0 in stage 7.0 (TID 188). 875 bytes result sent to driver
18/03/19 07:47:22 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:22 INFO TaskSetManager: Starting task 74.0 in stage 7.0 (TID 190, localhost, executor driver, partition 74, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:22 INFO TaskSetManager: Finished task 72.0 in stage 7.0 (TID 188) in 3221 ms on localhost (executor driver) (73/96)
18/03/19 07:47:22 INFO Executor: Running task 74.0 in stage 7.0 (TID 190)
18/03/19 07:47:22 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2483027968+33554432
18/03/19 07:47:22 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:24 INFO Executor: Finished task 73.0 in stage 7.0 (TID 189). 875 bytes result sent to driver
18/03/19 07:47:24 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:24 INFO TaskSetManager: Starting task 75.0 in stage 7.0 (TID 191, localhost, executor driver, partition 75, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:24 INFO TaskSetManager: Finished task 73.0 in stage 7.0 (TID 189) in 3113 ms on localhost (executor driver) (74/96)
18/03/19 07:47:24 INFO Executor: Running task 75.0 in stage 7.0 (TID 191)
18/03/19 07:47:24 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2516582400+33554432
18/03/19 07:47:24 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:25 INFO Executor: Finished task 74.0 in stage 7.0 (TID 190). 875 bytes result sent to driver
18/03/19 07:47:25 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:25 INFO TaskSetManager: Starting task 76.0 in stage 7.0 (TID 192, localhost, executor driver, partition 76, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:25 INFO Executor: Running task 76.0 in stage 7.0 (TID 192)
18/03/19 07:47:25 INFO TaskSetManager: Finished task 74.0 in stage 7.0 (TID 190) in 3007 ms on localhost (executor driver) (75/96)
18/03/19 07:47:25 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2550136832+33554432
18/03/19 07:47:25 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:27 INFO Executor: Finished task 75.0 in stage 7.0 (TID 191). 875 bytes result sent to driver
18/03/19 07:47:27 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:27 INFO TaskSetManager: Starting task 77.0 in stage 7.0 (TID 193, localhost, executor driver, partition 77, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:27 INFO TaskSetManager: Finished task 75.0 in stage 7.0 (TID 191) in 3160 ms on localhost (executor driver) (76/96)
18/03/19 07:47:27 INFO Executor: Running task 77.0 in stage 7.0 (TID 193)
18/03/19 07:47:27 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2583691264+33554432
18/03/19 07:47:27 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:27 INFO Executor: Finished task 76.0 in stage 7.0 (TID 192). 875 bytes result sent to driver
18/03/19 07:47:27 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:27 INFO TaskSetManager: Starting task 78.0 in stage 7.0 (TID 194, localhost, executor driver, partition 78, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:27 INFO TaskSetManager: Finished task 76.0 in stage 7.0 (TID 192) in 2886 ms on localhost (executor driver) (77/96)
18/03/19 07:47:27 INFO Executor: Running task 78.0 in stage 7.0 (TID 194)
18/03/19 07:47:27 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2617245696+33554432
18/03/19 07:47:27 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:30 INFO Executor: Finished task 77.0 in stage 7.0 (TID 193). 875 bytes result sent to driver
18/03/19 07:47:30 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:30 INFO TaskSetManager: Starting task 79.0 in stage 7.0 (TID 195, localhost, executor driver, partition 79, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:30 INFO Executor: Running task 79.0 in stage 7.0 (TID 195)
18/03/19 07:47:30 INFO TaskSetManager: Finished task 77.0 in stage 7.0 (TID 193) in 3045 ms on localhost (executor driver) (78/96)
18/03/19 07:47:30 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2650800128+33554432
18/03/19 07:47:30 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:31 INFO Executor: Finished task 78.0 in stage 7.0 (TID 194). 875 bytes result sent to driver
18/03/19 07:47:31 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:31 INFO TaskSetManager: Starting task 80.0 in stage 7.0 (TID 196, localhost, executor driver, partition 80, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:31 INFO Executor: Running task 80.0 in stage 7.0 (TID 196)
18/03/19 07:47:31 INFO TaskSetManager: Finished task 78.0 in stage 7.0 (TID 194) in 3272 ms on localhost (executor driver) (79/96)
18/03/19 07:47:31 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2684354560+33554432
18/03/19 07:47:31 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:33 INFO Executor: Finished task 79.0 in stage 7.0 (TID 195). 875 bytes result sent to driver
18/03/19 07:47:33 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:33 INFO TaskSetManager: Starting task 81.0 in stage 7.0 (TID 197, localhost, executor driver, partition 81, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:33 INFO TaskSetManager: Finished task 79.0 in stage 7.0 (TID 195) in 2986 ms on localhost (executor driver) (80/96)
18/03/19 07:47:33 INFO Executor: Running task 81.0 in stage 7.0 (TID 197)
18/03/19 07:47:33 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2717908992+33554432
18/03/19 07:47:33 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:34 INFO Executor: Finished task 80.0 in stage 7.0 (TID 196). 875 bytes result sent to driver
18/03/19 07:47:34 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:34 INFO TaskSetManager: Starting task 82.0 in stage 7.0 (TID 198, localhost, executor driver, partition 82, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:34 INFO TaskSetManager: Finished task 80.0 in stage 7.0 (TID 196) in 2947 ms on localhost (executor driver) (81/96)
18/03/19 07:47:34 INFO Executor: Running task 82.0 in stage 7.0 (TID 198)
18/03/19 07:47:34 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2751463424+33554432
18/03/19 07:47:34 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:36 INFO Executor: Finished task 82.0 in stage 7.0 (TID 198). 832 bytes result sent to driver
18/03/19 07:47:36 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:36 INFO TaskSetManager: Starting task 83.0 in stage 7.0 (TID 199, localhost, executor driver, partition 83, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:36 INFO TaskSetManager: Finished task 82.0 in stage 7.0 (TID 198) in 2765 ms on localhost (executor driver) (82/96)
18/03/19 07:47:36 INFO Executor: Running task 83.0 in stage 7.0 (TID 199)
18/03/19 07:47:36 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2785017856+33554432
18/03/19 07:47:36 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:37 INFO Executor: Finished task 81.0 in stage 7.0 (TID 197). 875 bytes result sent to driver
18/03/19 07:47:37 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:37 INFO TaskSetManager: Starting task 84.0 in stage 7.0 (TID 200, localhost, executor driver, partition 84, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:37 INFO TaskSetManager: Finished task 81.0 in stage 7.0 (TID 197) in 3432 ms on localhost (executor driver) (83/96)
18/03/19 07:47:37 INFO Executor: Running task 84.0 in stage 7.0 (TID 200)
18/03/19 07:47:37 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2818572288+33554432
18/03/19 07:47:37 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:39 INFO Executor: Finished task 83.0 in stage 7.0 (TID 199). 875 bytes result sent to driver
18/03/19 07:47:39 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:39 INFO TaskSetManager: Starting task 85.0 in stage 7.0 (TID 201, localhost, executor driver, partition 85, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:39 INFO TaskSetManager: Finished task 83.0 in stage 7.0 (TID 199) in 3007 ms on localhost (executor driver) (84/96)
18/03/19 07:47:39 INFO Executor: Running task 85.0 in stage 7.0 (TID 201)
18/03/19 07:47:39 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2852126720+33554432
18/03/19 07:47:39 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:40 INFO Executor: Finished task 84.0 in stage 7.0 (TID 200). 875 bytes result sent to driver
18/03/19 07:47:40 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:40 INFO TaskSetManager: Starting task 86.0 in stage 7.0 (TID 202, localhost, executor driver, partition 86, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:40 INFO Executor: Running task 86.0 in stage 7.0 (TID 202)
18/03/19 07:47:40 INFO TaskSetManager: Finished task 84.0 in stage 7.0 (TID 200) in 2849 ms on localhost (executor driver) (85/96)
18/03/19 07:47:40 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2885681152+33554432
18/03/19 07:47:40 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:42 INFO Executor: Finished task 85.0 in stage 7.0 (TID 201). 875 bytes result sent to driver
18/03/19 07:47:42 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:42 INFO TaskSetManager: Starting task 87.0 in stage 7.0 (TID 203, localhost, executor driver, partition 87, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:42 INFO TaskSetManager: Finished task 85.0 in stage 7.0 (TID 201) in 2878 ms on localhost (executor driver) (86/96)
18/03/19 07:47:42 INFO Executor: Running task 87.0 in stage 7.0 (TID 203)
18/03/19 07:47:42 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2919235584+33554432
18/03/19 07:47:42 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:43 INFO Executor: Finished task 86.0 in stage 7.0 (TID 202). 832 bytes result sent to driver
18/03/19 07:47:43 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:43 INFO TaskSetManager: Starting task 88.0 in stage 7.0 (TID 204, localhost, executor driver, partition 88, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:43 INFO Executor: Running task 88.0 in stage 7.0 (TID 204)
18/03/19 07:47:43 INFO TaskSetManager: Finished task 86.0 in stage 7.0 (TID 202) in 3115 ms on localhost (executor driver) (87/96)
18/03/19 07:47:43 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2952790016+33554432
18/03/19 07:47:43 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:45 INFO Executor: Finished task 87.0 in stage 7.0 (TID 203). 832 bytes result sent to driver
18/03/19 07:47:45 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:45 INFO TaskSetManager: Starting task 89.0 in stage 7.0 (TID 205, localhost, executor driver, partition 89, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:45 INFO Executor: Running task 89.0 in stage 7.0 (TID 205)
18/03/19 07:47:45 INFO TaskSetManager: Finished task 87.0 in stage 7.0 (TID 203) in 2999 ms on localhost (executor driver) (88/96)
18/03/19 07:47:45 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2986344448+33554432
18/03/19 07:47:45 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:46 INFO Executor: Finished task 88.0 in stage 7.0 (TID 204). 832 bytes result sent to driver
18/03/19 07:47:46 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:46 INFO TaskSetManager: Starting task 90.0 in stage 7.0 (TID 206, localhost, executor driver, partition 90, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:46 INFO TaskSetManager: Finished task 88.0 in stage 7.0 (TID 204) in 3215 ms on localhost (executor driver) (89/96)
18/03/19 07:47:46 INFO Executor: Running task 90.0 in stage 7.0 (TID 206)
18/03/19 07:47:46 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:3019898880+33554432
18/03/19 07:47:46 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:49 INFO Executor: Finished task 89.0 in stage 7.0 (TID 205). 875 bytes result sent to driver
18/03/19 07:47:49 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:49 INFO TaskSetManager: Starting task 91.0 in stage 7.0 (TID 207, localhost, executor driver, partition 91, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:49 INFO TaskSetManager: Finished task 89.0 in stage 7.0 (TID 205) in 3330 ms on localhost (executor driver) (90/96)
18/03/19 07:47:49 INFO Executor: Running task 91.0 in stage 7.0 (TID 207)
18/03/19 07:47:49 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:3053453312+33554432
18/03/19 07:47:49 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:49 INFO Executor: Finished task 90.0 in stage 7.0 (TID 206). 832 bytes result sent to driver
18/03/19 07:47:49 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:49 INFO TaskSetManager: Starting task 92.0 in stage 7.0 (TID 208, localhost, executor driver, partition 92, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:49 INFO TaskSetManager: Finished task 90.0 in stage 7.0 (TID 206) in 2887 ms on localhost (executor driver) (91/96)
18/03/19 07:47:49 INFO Executor: Running task 92.0 in stage 7.0 (TID 208)
18/03/19 07:47:49 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:3087007744+33554432
18/03/19 07:47:49 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:52 INFO Executor: Finished task 91.0 in stage 7.0 (TID 207). 832 bytes result sent to driver
18/03/19 07:47:52 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:52 INFO TaskSetManager: Starting task 93.0 in stage 7.0 (TID 209, localhost, executor driver, partition 93, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:52 INFO Executor: Running task 93.0 in stage 7.0 (TID 209)
18/03/19 07:47:52 INFO TaskSetManager: Finished task 91.0 in stage 7.0 (TID 207) in 2943 ms on localhost (executor driver) (92/96)
18/03/19 07:47:52 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:3120562176+33554432
18/03/19 07:47:52 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:52 INFO Executor: Finished task 92.0 in stage 7.0 (TID 208). 875 bytes result sent to driver
18/03/19 07:47:52 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:52 INFO TaskSetManager: Starting task 94.0 in stage 7.0 (TID 210, localhost, executor driver, partition 94, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:52 INFO Executor: Running task 94.0 in stage 7.0 (TID 210)
18/03/19 07:47:52 INFO TaskSetManager: Finished task 92.0 in stage 7.0 (TID 208) in 2850 ms on localhost (executor driver) (93/96)
18/03/19 07:47:52 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:3154116608+33554432
18/03/19 07:47:52 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:55 INFO Executor: Finished task 93.0 in stage 7.0 (TID 209). 875 bytes result sent to driver
18/03/19 07:47:55 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:55 INFO TaskSetManager: Starting task 95.0 in stage 7.0 (TID 211, localhost, executor driver, partition 95, PROCESS_LOCAL, 7874 bytes)
18/03/19 07:47:55 INFO Executor: Running task 95.0 in stage 7.0 (TID 211)
18/03/19 07:47:55 INFO TaskSetManager: Finished task 93.0 in stage 7.0 (TID 209) in 2918 ms on localhost (executor driver) (94/96)
18/03/19 07:47:55 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:3187671040+19265026
18/03/19 07:47:55 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:55 INFO Executor: Finished task 94.0 in stage 7.0 (TID 210). 875 bytes result sent to driver
18/03/19 07:47:55 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 1
18/03/19 07:47:55 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
18/03/19 07:47:55 INFO TaskSetManager: Finished task 94.0 in stage 7.0 (TID 210) in 3190 ms on localhost (executor driver) (95/96)
18/03/19 07:47:56 INFO Executor: Finished task 95.0 in stage 7.0 (TID 211). 875 bytes result sent to driver
18/03/19 07:47:56 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7.0, runningTasks: 0
18/03/19 07:47:56 INFO TaskSetManager: Finished task 95.0 in stage 7.0 (TID 211) in 1140 ms on localhost (executor driver) (96/96)
18/03/19 07:47:56 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
18/03/19 07:47:56 INFO DAGScheduler: ResultStage 7 (count at SBMJ_GB.scala:54) finished in 146.824 s
18/03/19 07:47:56 DEBUG DAGScheduler: After removal of stage 7, remaining stages = 0
18/03/19 07:47:56 INFO DAGScheduler: Job 7 finished: count at SBMJ_GB.scala:54, took 146.838582 s
100000000
18/03/19 07:47:56 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$cogroup$2$$anonfun$apply$43) +++
18/03/19 07:47:56 DEBUG ClosureCleaner:  + declared fields: 1
18/03/19 07:47:56 DEBUG ClosureCleaner:      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$cogroup$2$$anonfun$apply$43.serialVersionUID
18/03/19 07:47:56 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:47:56 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$cogroup$2$$anonfun$apply$43.apply(java.lang.Object)
18/03/19 07:47:56 DEBUG ClosureCleaner:      public final scala.Tuple2 org.apache.spark.rdd.PairRDDFunctions$$anonfun$cogroup$2$$anonfun$apply$43.apply(scala.collection.Iterable[])
18/03/19 07:47:56 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:47:56 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:47:56 DEBUG ClosureCleaner:  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$cogroup$2$$anonfun$apply$43) is now cleaned +++
18/03/19 07:47:56 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$join$1$$anonfun$apply$20) +++
18/03/19 07:47:56 DEBUG ClosureCleaner:  + declared fields: 1
18/03/19 07:47:56 DEBUG ClosureCleaner:      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$join$1$$anonfun$apply$20.serialVersionUID
18/03/19 07:47:56 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:47:56 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$join$1$$anonfun$apply$20.apply(java.lang.Object)
18/03/19 07:47:56 DEBUG ClosureCleaner:      public final scala.collection.Iterator org.apache.spark.rdd.PairRDDFunctions$$anonfun$join$1$$anonfun$apply$20.apply(scala.Tuple2)
18/03/19 07:47:56 DEBUG ClosureCleaner:  + inner classes: 2
18/03/19 07:47:56 DEBUG ClosureCleaner:      org.apache.spark.rdd.PairRDDFunctions$$anonfun$join$1$$anonfun$apply$20$$anonfun$apply$21$$anonfun$apply$22
18/03/19 07:47:56 DEBUG ClosureCleaner:      org.apache.spark.rdd.PairRDDFunctions$$anonfun$join$1$$anonfun$apply$20$$anonfun$apply$21
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:47:56 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:47:56 DEBUG ClosureCleaner:  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$join$1$$anonfun$apply$20) is now cleaned +++
18/03/19 07:47:56 DEBUG CoGroupedRDD: Adding shuffle dependency with MapPartitionsRDD[11] at map at SBMJ_GB.scala:52
18/03/19 07:47:56 DEBUG CoGroupedRDD: Adding shuffle dependency with MapPartitionsRDD[5] at map at SBMJ_GB.scala:33
18/03/19 07:47:56 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1$$anonfun$8) +++
18/03/19 07:47:56 DEBUG ClosureCleaner:  + declared fields: 2
18/03/19 07:47:56 DEBUG ClosureCleaner:      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1$$anonfun$8.serialVersionUID
18/03/19 07:47:56 DEBUG ClosureCleaner:      private final org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1 org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1$$anonfun$8.$outer
18/03/19 07:47:56 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:47:56 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1$$anonfun$8.apply(java.lang.Object)
18/03/19 07:47:56 DEBUG ClosureCleaner:      public final org.apache.spark.util.collection.CompactBuffer org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1$$anonfun$8.apply(java.lang.Object)
18/03/19 07:47:56 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outer classes: 2
18/03/19 07:47:56 DEBUG ClosureCleaner:      org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1
18/03/19 07:47:56 DEBUG ClosureCleaner:      org.apache.spark.rdd.PairRDDFunctions
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outer objects: 2
18/03/19 07:47:56 DEBUG ClosureCleaner:      <function0>
18/03/19 07:47:56 DEBUG ClosureCleaner:      org.apache.spark.rdd.PairRDDFunctions@5b852b49
18/03/19 07:47:56 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:47:56 DEBUG ClosureCleaner:  + fields accessed by starting closure: 4
18/03/19 07:47:56 DEBUG ClosureCleaner:      (class java.lang.Object,Set())
18/03/19 07:47:56 DEBUG ClosureCleaner:      (class org.apache.spark.rdd.PairRDDFunctions,Set(org$apache$spark$rdd$PairRDDFunctions$$vt))
18/03/19 07:47:56 DEBUG ClosureCleaner:      (class org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1,Set($outer))
18/03/19 07:47:56 DEBUG ClosureCleaner:      (class scala.runtime.AbstractFunction0,Set())
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.PairRDDFunctions,org.apache.spark.rdd.PairRDDFunctions@5b852b49)
18/03/19 07:47:56 DEBUG ClosureCleaner:  + cloning the object <function0> of class org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1
18/03/19 07:47:56 DEBUG ClosureCleaner:  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1)
18/03/19 07:47:56 DEBUG ClosureCleaner: +++ Cleaning closure <function0> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1) +++
18/03/19 07:47:56 DEBUG ClosureCleaner:  + declared fields: 3
18/03/19 07:47:56 DEBUG ClosureCleaner:      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1.serialVersionUID
18/03/19 07:47:56 DEBUG ClosureCleaner:      private final org.apache.spark.rdd.PairRDDFunctions org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1.$outer
18/03/19 07:47:56 DEBUG ClosureCleaner:      private final org.apache.spark.Partitioner org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1.partitioner$5
18/03/19 07:47:56 DEBUG ClosureCleaner:  + declared methods: 3
18/03/19 07:47:56 DEBUG ClosureCleaner:      public org.apache.spark.rdd.PairRDDFunctions org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1.org$apache$spark$rdd$PairRDDFunctions$$anonfun$$$outer()
18/03/19 07:47:56 DEBUG ClosureCleaner:      public final org.apache.spark.rdd.RDD org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1.apply()
18/03/19 07:47:56 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1.apply()
18/03/19 07:47:56 DEBUG ClosureCleaner:  + inner classes: 3
18/03/19 07:47:56 DEBUG ClosureCleaner:      org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1$$anonfun$8
18/03/19 07:47:56 DEBUG ClosureCleaner:      org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1$$anonfun$9
18/03/19 07:47:56 DEBUG ClosureCleaner:      org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1$$anonfun$10
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outer classes: 1
18/03/19 07:47:56 DEBUG ClosureCleaner:      org.apache.spark.rdd.PairRDDFunctions
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outer objects: 1
18/03/19 07:47:56 DEBUG ClosureCleaner:      org.apache.spark.rdd.PairRDDFunctions@5b852b49
18/03/19 07:47:56 DEBUG ClosureCleaner:  + fields accessed by starting closure: 4
18/03/19 07:47:56 DEBUG ClosureCleaner:      (class java.lang.Object,Set())
18/03/19 07:47:56 DEBUG ClosureCleaner:      (class org.apache.spark.rdd.PairRDDFunctions,Set(org$apache$spark$rdd$PairRDDFunctions$$vt))
18/03/19 07:47:56 DEBUG ClosureCleaner:      (class org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1,Set($outer))
18/03/19 07:47:56 DEBUG ClosureCleaner:      (class scala.runtime.AbstractFunction0,Set())
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.PairRDDFunctions,org.apache.spark.rdd.PairRDDFunctions@5b852b49)
18/03/19 07:47:56 DEBUG ClosureCleaner:  +++ closure <function0> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1) is now cleaned +++
18/03/19 07:47:56 DEBUG ClosureCleaner:  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1$$anonfun$8) is now cleaned +++
18/03/19 07:47:56 DEBUG ClosureCleaner: +++ Cleaning closure <function2> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1$$anonfun$9) +++
18/03/19 07:47:56 DEBUG ClosureCleaner:  + declared fields: 1
18/03/19 07:47:56 DEBUG ClosureCleaner:      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1$$anonfun$9.serialVersionUID
18/03/19 07:47:56 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:47:56 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1$$anonfun$9.apply(java.lang.Object,java.lang.Object)
18/03/19 07:47:56 DEBUG ClosureCleaner:      public final org.apache.spark.util.collection.CompactBuffer org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1$$anonfun$9.apply(org.apache.spark.util.collection.CompactBuffer,java.lang.Object)
18/03/19 07:47:56 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:47:56 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:47:56 DEBUG ClosureCleaner:  +++ closure <function2> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1$$anonfun$9) is now cleaned +++
18/03/19 07:47:56 DEBUG ClosureCleaner: +++ Cleaning closure <function2> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1$$anonfun$10) +++
18/03/19 07:47:56 DEBUG ClosureCleaner:  + declared fields: 1
18/03/19 07:47:56 DEBUG ClosureCleaner:      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1$$anonfun$10.serialVersionUID
18/03/19 07:47:56 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:47:56 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1$$anonfun$10.apply(java.lang.Object,java.lang.Object)
18/03/19 07:47:56 DEBUG ClosureCleaner:      public final org.apache.spark.util.collection.CompactBuffer org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1$$anonfun$10.apply(org.apache.spark.util.collection.CompactBuffer,org.apache.spark.util.collection.CompactBuffer)
18/03/19 07:47:56 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:47:56 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:47:56 DEBUG ClosureCleaner:  +++ closure <function2> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1$$anonfun$10) is now cleaned +++
18/03/19 07:47:56 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$combineByKeyWithClassTag$1$$anonfun$apply$5) +++
18/03/19 07:47:56 DEBUG ClosureCleaner:  + declared fields: 2
18/03/19 07:47:56 DEBUG ClosureCleaner:      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$combineByKeyWithClassTag$1$$anonfun$apply$5.serialVersionUID
18/03/19 07:47:56 DEBUG ClosureCleaner:      private final org.apache.spark.Aggregator org.apache.spark.rdd.PairRDDFunctions$$anonfun$combineByKeyWithClassTag$1$$anonfun$apply$5.aggregator$1
18/03/19 07:47:56 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:47:56 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$combineByKeyWithClassTag$1$$anonfun$apply$5.apply(java.lang.Object)
18/03/19 07:47:56 DEBUG ClosureCleaner:      public final org.apache.spark.InterruptibleIterator org.apache.spark.rdd.PairRDDFunctions$$anonfun$combineByKeyWithClassTag$1$$anonfun$apply$5.apply(scala.collection.Iterator)
18/03/19 07:47:56 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:47:56 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:47:56 DEBUG ClosureCleaner:  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$combineByKeyWithClassTag$1$$anonfun$apply$5) is now cleaned +++
18/03/19 07:47:56 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (Joins.SBMJ_GB$$anonfun$9) +++
18/03/19 07:47:56 DEBUG ClosureCleaner:  + declared fields: 1
18/03/19 07:47:56 DEBUG ClosureCleaner:      public static final long Joins.SBMJ_GB$$anonfun$9.serialVersionUID
18/03/19 07:47:56 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:47:56 DEBUG ClosureCleaner:      public final java.lang.Object Joins.SBMJ_GB$$anonfun$9.apply(java.lang.Object)
18/03/19 07:47:56 DEBUG ClosureCleaner:      public final scala.Tuple2 Joins.SBMJ_GB$$anonfun$9.apply(scala.collection.Iterable)
18/03/19 07:47:56 DEBUG ClosureCleaner:  + inner classes: 1
18/03/19 07:47:56 DEBUG ClosureCleaner:      Joins.SBMJ_GB$$anonfun$9$$anonfun$apply$1
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:47:56 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:47:56 DEBUG ClosureCleaner:  +++ closure <function1> (Joins.SBMJ_GB$$anonfun$9) is now cleaned +++
18/03/19 07:47:56 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28) +++
18/03/19 07:47:56 DEBUG ClosureCleaner:  + declared fields: 3
18/03/19 07:47:56 DEBUG ClosureCleaner:      public static final long org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28.serialVersionUID
18/03/19 07:47:56 DEBUG ClosureCleaner:      private final org.apache.spark.rdd.RDD$$anonfun$take$1 org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28.$outer
18/03/19 07:47:56 DEBUG ClosureCleaner:      private final int org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28.left$1
18/03/19 07:47:56 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:47:56 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28.apply(java.lang.Object)
18/03/19 07:47:56 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28.apply(scala.collection.Iterator)
18/03/19 07:47:56 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outer classes: 2
18/03/19 07:47:56 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD$$anonfun$take$1
18/03/19 07:47:56 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outer objects: 2
18/03/19 07:47:56 DEBUG ClosureCleaner:      <function0>
18/03/19 07:47:56 DEBUG ClosureCleaner:      MapPartitionsRDD[16] at mapValues at SBMJ_GB.scala:57
18/03/19 07:47:56 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:47:56 DEBUG ClosureCleaner:  + fields accessed by starting closure: 4
18/03/19 07:47:56 DEBUG ClosureCleaner:      (class java.lang.Object,Set())
18/03/19 07:47:56 DEBUG ClosureCleaner:      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
18/03/19 07:47:56 DEBUG ClosureCleaner:      (class scala.runtime.AbstractFunction0,Set())
18/03/19 07:47:56 DEBUG ClosureCleaner:      (class org.apache.spark.rdd.RDD$$anonfun$take$1,Set($outer))
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[16] at mapValues at SBMJ_GB.scala:57)
18/03/19 07:47:56 DEBUG ClosureCleaner:  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$take$1
18/03/19 07:47:56 DEBUG ClosureCleaner:  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$take$1)
18/03/19 07:47:56 DEBUG ClosureCleaner: +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$take$1) +++
18/03/19 07:47:56 DEBUG ClosureCleaner:  + declared fields: 3
18/03/19 07:47:56 DEBUG ClosureCleaner:      public static final long org.apache.spark.rdd.RDD$$anonfun$take$1.serialVersionUID
18/03/19 07:47:56 DEBUG ClosureCleaner:      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$take$1.$outer
18/03/19 07:47:56 DEBUG ClosureCleaner:      public final int org.apache.spark.rdd.RDD$$anonfun$take$1.num$2
18/03/19 07:47:56 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:47:56 DEBUG ClosureCleaner:      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$take$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
18/03/19 07:47:56 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$take$1.apply()
18/03/19 07:47:56 DEBUG ClosureCleaner:  + inner classes: 2
18/03/19 07:47:56 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$apply$49
18/03/19 07:47:56 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outer classes: 1
18/03/19 07:47:56 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outer objects: 1
18/03/19 07:47:56 DEBUG ClosureCleaner:      MapPartitionsRDD[16] at mapValues at SBMJ_GB.scala:57
18/03/19 07:47:56 DEBUG ClosureCleaner:  + fields accessed by starting closure: 4
18/03/19 07:47:56 DEBUG ClosureCleaner:      (class java.lang.Object,Set())
18/03/19 07:47:56 DEBUG ClosureCleaner:      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
18/03/19 07:47:56 DEBUG ClosureCleaner:      (class scala.runtime.AbstractFunction0,Set())
18/03/19 07:47:56 DEBUG ClosureCleaner:      (class org.apache.spark.rdd.RDD$$anonfun$take$1,Set($outer))
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[16] at mapValues at SBMJ_GB.scala:57)
18/03/19 07:47:56 DEBUG ClosureCleaner:  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$take$1) is now cleaned +++
18/03/19 07:47:56 DEBUG ClosureCleaner:  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28) is now cleaned +++
18/03/19 07:47:56 DEBUG ClosureCleaner: +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
18/03/19 07:47:56 DEBUG ClosureCleaner:  + declared fields: 2
18/03/19 07:47:56 DEBUG ClosureCleaner:      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
18/03/19 07:47:56 DEBUG ClosureCleaner:      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
18/03/19 07:47:56 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:47:56 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
18/03/19 07:47:56 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
18/03/19 07:47:56 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:47:56 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:47:56 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:47:56 DEBUG ClosureCleaner:  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
18/03/19 07:47:56 INFO SparkContext: Starting job: take at SBMJ_GB.scala:66
18/03/19 07:47:56 INFO DAGScheduler: Registering RDD 11 (map at SBMJ_GB.scala:52)
18/03/19 07:47:56 INFO DAGScheduler: Registering RDD 5 (map at SBMJ_GB.scala:33)
18/03/19 07:47:56 INFO DAGScheduler: Got job 8 (take at SBMJ_GB.scala:66) with 1 output partitions
18/03/19 07:47:56 INFO DAGScheduler: Final stage: ResultStage 10 (take at SBMJ_GB.scala:66)
18/03/19 07:47:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9, ShuffleMapStage 8)
18/03/19 07:47:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9, ShuffleMapStage 8)
18/03/19 07:47:56 DEBUG DAGScheduler: submitStage(ResultStage 10)
18/03/19 07:47:56 DEBUG DAGScheduler: missing: List(ShuffleMapStage 8, ShuffleMapStage 9)
18/03/19 07:47:56 DEBUG DAGScheduler: submitStage(ShuffleMapStage 8)
18/03/19 07:47:56 DEBUG DAGScheduler: missing: List()
18/03/19 07:47:56 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[11] at map at SBMJ_GB.scala:52), which has no missing parents
18/03/19 07:47:56 DEBUG DAGScheduler: submitMissingTasks(ShuffleMapStage 8)
18/03/19 07:47:56 TRACE BlockInfoManager: Task -1024 trying to put broadcast_10
18/03/19 07:47:56 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_10
18/03/19 07:47:56 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_10
18/03/19 07:47:56 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_10
18/03/19 07:47:56 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 4.5 KB, free 852.1 MB)
18/03/19 07:47:56 DEBUG BlockManager: Put block broadcast_10 locally took  1 ms
18/03/19 07:47:56 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_10
18/03/19 07:47:56 DEBUG BlockManager: Putting block broadcast_10 without replication took  1 ms
18/03/19 07:47:56 TRACE BlockInfoManager: Task -1024 trying to put broadcast_10_piece0
18/03/19 07:47:56 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_10_piece0
18/03/19 07:47:56 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_10_piece0
18/03/19 07:47:56 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_10_piece0
18/03/19 07:47:56 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.5 KB, free 852.1 MB)
18/03/19 07:47:56 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.8.100:40919 (size: 2.5 KB, free: 852.6 MB)
18/03/19 07:47:56 DEBUG BlockManagerMaster: Updated info of block broadcast_10_piece0
18/03/19 07:47:56 DEBUG BlockManager: Told master about block broadcast_10_piece0
18/03/19 07:47:56 DEBUG BlockManager: Put block broadcast_10_piece0 locally took  2 ms
18/03/19 07:47:56 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_10_piece0
18/03/19 07:47:56 DEBUG BlockManager: Putting block broadcast_10_piece0 without replication took  2 ms
18/03/19 07:47:56 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1039
18/03/19 07:47:56 INFO DAGScheduler: Submitting 96 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[11] at map at SBMJ_GB.scala:52) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
18/03/19 07:47:56 INFO TaskSchedulerImpl: Adding task set 8.0 with 96 tasks
18/03/19 07:47:56 DEBUG TaskSetManager: Epoch for TaskSet 8.0: 0
18/03/19 07:47:56 DEBUG TaskSetManager: Valid locality levels for TaskSet 8.0: NO_PREF, ANY
18/03/19 07:47:56 DEBUG DAGScheduler: submitStage(ShuffleMapStage 9)
18/03/19 07:47:56 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 0
18/03/19 07:47:56 DEBUG DAGScheduler: missing: List()
18/03/19 07:47:56 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[5] at map at SBMJ_GB.scala:33), which has no missing parents
18/03/19 07:47:56 DEBUG DAGScheduler: submitMissingTasks(ShuffleMapStage 9)
18/03/19 07:47:56 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 212, localhost, executor driver, partition 0, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:47:56 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 213, localhost, executor driver, partition 1, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:47:56 INFO Executor: Running task 1.0 in stage 8.0 (TID 213)
18/03/19 07:47:56 INFO Executor: Running task 0.0 in stage 8.0 (TID 212)
18/03/19 07:47:56 TRACE BlockInfoManager: Task -1024 trying to put broadcast_11
18/03/19 07:47:56 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_11
18/03/19 07:47:56 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_11
18/03/19 07:47:56 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_11
18/03/19 07:47:56 DEBUG BlockManager: Getting local block broadcast_10
18/03/19 07:47:56 TRACE BlockInfoManager: Task 212 trying to acquire read lock for broadcast_10
18/03/19 07:47:56 TRACE BlockInfoManager: Task 212 acquired read lock for broadcast_10
18/03/19 07:47:56 DEBUG BlockManager: Level for block broadcast_10 is StorageLevel(disk, memory, deserialized, 1 replicas)
18/03/19 07:47:56 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 4.5 KB, free 852.1 MB)
18/03/19 07:47:56 DEBUG BlockManager: Put block broadcast_11 locally took  2 ms
18/03/19 07:47:56 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_11
18/03/19 07:47:56 DEBUG BlockManager: Putting block broadcast_11 without replication took  2 ms
18/03/19 07:47:56 TRACE BlockInfoManager: Task -1024 trying to put broadcast_11_piece0
18/03/19 07:47:56 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_11_piece0
18/03/19 07:47:56 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_11_piece0
18/03/19 07:47:56 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_11_piece0
18/03/19 07:47:56 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.5 KB, free 852.1 MB)
18/03/19 07:47:56 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:0+33554432
18/03/19 07:47:56 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:56 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 192.168.8.100:40919 (size: 2.5 KB, free: 852.5 MB)
18/03/19 07:47:56 DEBUG BlockManagerMaster: Updated info of block broadcast_11_piece0
18/03/19 07:47:56 DEBUG BlockManager: Told master about block broadcast_11_piece0
18/03/19 07:47:56 DEBUG BlockManager: Put block broadcast_11_piece0 locally took  2 ms
18/03/19 07:47:56 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_11_piece0
18/03/19 07:47:56 DEBUG BlockManager: Putting block broadcast_11_piece0 without replication took  2 ms
18/03/19 07:47:56 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:33554432+33554432
18/03/19 07:47:56 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:47:56 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1039
18/03/19 07:47:56 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[5] at map at SBMJ_GB.scala:33) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
18/03/19 07:47:56 INFO TaskSchedulerImpl: Adding task set 9.0 with 8 tasks
18/03/19 07:47:56 DEBUG TaskSetManager: Epoch for TaskSet 9.0: 0
18/03/19 07:47:56 DEBUG TaskSetManager: Valid locality levels for TaskSet 9.0: NO_PREF, ANY
18/03/19 07:47:56 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 2
18/03/19 07:47:56 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:02 TRACE BlockInfoManager: Task 212 releasing lock for broadcast_10
18/03/19 07:48:02 INFO Executor: Finished task 1.0 in stage 8.0 (TID 213). 1163 bytes result sent to driver
18/03/19 07:48:02 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:02 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:02 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 214, localhost, executor driver, partition 2, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:02 INFO Executor: Finished task 0.0 in stage 8.0 (TID 212). 1163 bytes result sent to driver
18/03/19 07:48:02 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:02 INFO Executor: Running task 2.0 in stage 8.0 (TID 214)
18/03/19 07:48:02 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:02 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 215, localhost, executor driver, partition 3, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:02 INFO Executor: Running task 3.0 in stage 8.0 (TID 215)
18/03/19 07:48:02 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 212) in 5759 ms on localhost (executor driver) (1/96)
18/03/19 07:48:02 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 213) in 5757 ms on localhost (executor driver) (2/96)
18/03/19 07:48:02 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:02 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:02 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:100663296+33554432
18/03/19 07:48:02 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:02 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:67108864+33554432
18/03/19 07:48:02 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:06 INFO Executor: Finished task 2.0 in stage 8.0 (TID 214). 1120 bytes result sent to driver
18/03/19 07:48:06 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:06 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:06 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 216, localhost, executor driver, partition 4, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:06 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 214) in 4119 ms on localhost (executor driver) (3/96)
18/03/19 07:48:06 INFO Executor: Running task 4.0 in stage 8.0 (TID 216)
18/03/19 07:48:06 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:06 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:134217728+33554432
18/03/19 07:48:06 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:06 INFO Executor: Finished task 3.0 in stage 8.0 (TID 215). 1120 bytes result sent to driver
18/03/19 07:48:06 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:06 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:06 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 217, localhost, executor driver, partition 5, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:06 INFO Executor: Running task 5.0 in stage 8.0 (TID 217)
18/03/19 07:48:06 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 215) in 4236 ms on localhost (executor driver) (4/96)
18/03/19 07:48:06 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:06 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:167772160+33554432
18/03/19 07:48:06 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(28)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 28
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 28
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(13)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 13
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 13
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(146)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 146
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 146
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(18)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 18
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 18
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(125)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 125
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 125
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(181)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 181
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 181
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(179)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 179
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 179
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(149)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 149
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 149
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(196)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 196
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 196
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(193)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 193
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 193
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(180)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 180
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 180
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(177)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 177
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 177
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(175)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 175
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 175
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(140)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 140
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 140
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(134)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 134
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 134
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(195)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 195
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 195
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(36)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 36
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 36
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(136)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 136
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 136
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(30)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 30
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 30
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(183)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 183
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 183
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(32)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 32
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 32
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(127)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 127
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 127
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(1)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 1
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 1
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(7)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning broadcast 7
18/03/19 07:48:07 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 7
18/03/19 07:48:07 DEBUG BlockManagerSlaveEndpoint: removing broadcast 7
18/03/19 07:48:07 DEBUG BlockManager: Removing broadcast 7
18/03/19 07:48:07 DEBUG BlockManager: Removing block broadcast_7
18/03/19 07:48:07 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_7
18/03/19 07:48:07 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_7
18/03/19 07:48:07 DEBUG MemoryStore: Block broadcast_7 of size 3504 dropped from memory (free 893506989)
18/03/19 07:48:07 TRACE BlockInfoManager: Task -1024 trying to remove block broadcast_7
18/03/19 07:48:07 DEBUG BlockManager: Removing block broadcast_7_piece0
18/03/19 07:48:07 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_7_piece0
18/03/19 07:48:07 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_7_piece0
18/03/19 07:48:07 DEBUG MemoryStore: Block broadcast_7_piece0 of size 2034 dropped from memory (free 893509023)
18/03/19 07:48:07 TRACE BlockInfoManager: Task -1024 trying to remove block broadcast_7_piece0
18/03/19 07:48:07 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 192.168.8.100:40919 in memory (size: 2034.0 B, free: 852.6 MB)
18/03/19 07:48:07 DEBUG BlockManagerMaster: Updated info of block broadcast_7_piece0
18/03/19 07:48:07 DEBUG BlockManager: Told master about block broadcast_7_piece0
18/03/19 07:48:07 DEBUG BlockManagerSlaveEndpoint: Done removing broadcast 7, response is 0
18/03/19 07:48:07 DEBUG BlockManagerSlaveEndpoint: Sent response: 0 to 192.168.8.100:45639
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaned broadcast 7
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(9)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 9
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 9
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(189)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 189
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 189
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(15)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 15
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 15
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(144)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 144
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 144
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(187)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 187
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 187
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(3)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 3
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 3
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(6)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 6
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 6
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(22)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 22
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 22
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(138)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 138
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 138
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(194)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 194
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 194
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(7)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 7
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 7
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(141)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 141
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 141
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(42)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 42
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 42
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(29)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 29
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 29
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(24)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 24
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 24
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(131)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 131
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 131
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(46)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 46
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 46
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(10)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 10
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 10
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(44)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 44
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 44
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(2)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 2
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 2
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(0)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 0
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 0
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(9)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning broadcast 9
18/03/19 07:48:07 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 9
18/03/19 07:48:07 DEBUG BlockManagerSlaveEndpoint: removing broadcast 9
18/03/19 07:48:07 DEBUG BlockManager: Removing broadcast 9
18/03/19 07:48:07 DEBUG BlockManager: Removing block broadcast_9_piece0
18/03/19 07:48:07 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_9_piece0
18/03/19 07:48:07 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_9_piece0
18/03/19 07:48:07 DEBUG MemoryStore: Block broadcast_9_piece0 of size 2113 dropped from memory (free 893511136)
18/03/19 07:48:07 TRACE BlockInfoManager: Task -1024 trying to remove block broadcast_9_piece0
18/03/19 07:48:07 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 192.168.8.100:40919 in memory (size: 2.1 KB, free: 852.6 MB)
18/03/19 07:48:07 DEBUG BlockManagerMaster: Updated info of block broadcast_9_piece0
18/03/19 07:48:07 DEBUG BlockManager: Told master about block broadcast_9_piece0
18/03/19 07:48:07 DEBUG BlockManager: Removing block broadcast_9
18/03/19 07:48:07 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_9
18/03/19 07:48:07 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_9
18/03/19 07:48:07 DEBUG MemoryStore: Block broadcast_9 of size 3816 dropped from memory (free 893514952)
18/03/19 07:48:07 TRACE BlockInfoManager: Task -1024 trying to remove block broadcast_9
18/03/19 07:48:07 DEBUG BlockManagerSlaveEndpoint: Done removing broadcast 9, response is 0
18/03/19 07:48:07 DEBUG BlockManagerSlaveEndpoint: Sent response: 0 to 192.168.8.100:45639
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaned broadcast 9
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(16)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 16
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 16
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(14)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 14
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 14
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(12)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 12
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 12
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(47)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 47
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 47
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(26)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 26
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 26
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(135)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 135
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 135
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(31)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 31
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 31
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(199)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 199
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 199
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(139)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 139
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 139
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(143)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 143
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 143
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(5)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 5
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 5
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(142)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 142
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 142
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(8)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 8
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 8
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(190)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 190
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 190
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(147)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 147
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 147
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(186)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 186
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 186
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(48)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 48
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 48
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(192)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 192
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 192
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(33)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 33
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 33
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(17)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 17
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 17
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(21)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 21
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 21
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(130)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 130
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 130
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(145)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 145
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 145
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(35)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 35
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 35
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(132)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 132
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 132
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(11)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 11
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 11
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(38)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 38
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 38
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(43)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 43
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 43
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(27)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 27
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 27
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(178)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 178
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 178
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(129)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 129
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 129
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(23)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 23
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 23
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(2)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning broadcast 2
18/03/19 07:48:07 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 2
18/03/19 07:48:07 DEBUG BlockManagerSlaveEndpoint: removing broadcast 2
18/03/19 07:48:07 DEBUG BlockManager: Removing broadcast 2
18/03/19 07:48:07 DEBUG BlockManager: Removing block broadcast_2
18/03/19 07:48:07 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_2
18/03/19 07:48:07 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_2
18/03/19 07:48:07 DEBUG MemoryStore: Block broadcast_2 of size 3496 dropped from memory (free 893518448)
18/03/19 07:48:07 TRACE BlockInfoManager: Task -1024 trying to remove block broadcast_2
18/03/19 07:48:07 DEBUG BlockManager: Removing block broadcast_2_piece0
18/03/19 07:48:07 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_2_piece0
18/03/19 07:48:07 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_2_piece0
18/03/19 07:48:07 DEBUG MemoryStore: Block broadcast_2_piece0 of size 2042 dropped from memory (free 893520490)
18/03/19 07:48:07 TRACE BlockInfoManager: Task -1024 trying to remove block broadcast_2_piece0
18/03/19 07:48:07 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.8.100:40919 in memory (size: 2042.0 B, free: 852.6 MB)
18/03/19 07:48:07 DEBUG BlockManagerMaster: Updated info of block broadcast_2_piece0
18/03/19 07:48:07 DEBUG BlockManager: Told master about block broadcast_2_piece0
18/03/19 07:48:07 DEBUG BlockManagerSlaveEndpoint: Done removing broadcast 2, response is 0
18/03/19 07:48:07 DEBUG BlockManagerSlaveEndpoint: Sent response: 0 to 192.168.8.100:45639
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaned broadcast 2
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(126)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 126
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 126
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(40)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 40
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 40
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(37)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 37
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 37
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(182)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 182
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 182
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(128)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 128
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 128
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(41)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 41
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 41
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(184)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 184
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 184
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(25)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 25
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 25
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(188)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 188
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 188
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(185)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 185
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 185
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(148)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 148
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 148
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(49)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 49
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 49
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(191)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 191
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 191
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(176)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 176
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 176
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(137)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 137
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 137
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(198)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 198
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 198
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(133)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 133
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 133
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(197)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 197
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 197
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(19)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 19
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 19
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(20)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 20
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 20
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(4)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 4
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 4
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(34)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 34
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 34
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(39)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 39
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 39
18/03/19 07:48:07 DEBUG ContextCleaner: Got cleaning task CleanAccum(45)
18/03/19 07:48:07 DEBUG ContextCleaner: Cleaning accumulator 45
18/03/19 07:48:07 INFO ContextCleaner: Cleaned accumulator 45
18/03/19 07:48:10 INFO Executor: Finished task 4.0 in stage 8.0 (TID 216). 1120 bytes result sent to driver
18/03/19 07:48:10 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:10 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:10 INFO TaskSetManager: Starting task 6.0 in stage 8.0 (TID 218, localhost, executor driver, partition 6, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:10 INFO Executor: Running task 6.0 in stage 8.0 (TID 218)
18/03/19 07:48:10 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 216) in 3623 ms on localhost (executor driver) (5/96)
18/03/19 07:48:10 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:10 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:201326592+33554432
18/03/19 07:48:10 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:10 INFO Executor: Finished task 5.0 in stage 8.0 (TID 217). 1120 bytes result sent to driver
18/03/19 07:48:10 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:10 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:10 INFO TaskSetManager: Starting task 7.0 in stage 8.0 (TID 219, localhost, executor driver, partition 7, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:10 INFO Executor: Running task 7.0 in stage 8.0 (TID 219)
18/03/19 07:48:10 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 217) in 3582 ms on localhost (executor driver) (6/96)
18/03/19 07:48:10 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:10 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:234881024+33554432
18/03/19 07:48:10 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:14 INFO Executor: Finished task 6.0 in stage 8.0 (TID 218). 1120 bytes result sent to driver
18/03/19 07:48:14 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:14 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:14 INFO TaskSetManager: Starting task 8.0 in stage 8.0 (TID 220, localhost, executor driver, partition 8, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:14 INFO TaskSetManager: Finished task 6.0 in stage 8.0 (TID 218) in 4190 ms on localhost (executor driver) (7/96)
18/03/19 07:48:14 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:14 INFO Executor: Running task 8.0 in stage 8.0 (TID 220)
18/03/19 07:48:14 INFO Executor: Finished task 7.0 in stage 8.0 (TID 219). 1120 bytes result sent to driver
18/03/19 07:48:14 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:268435456+33554432
18/03/19 07:48:14 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:14 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:14 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:14 INFO TaskSetManager: Starting task 9.0 in stage 8.0 (TID 221, localhost, executor driver, partition 9, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:14 INFO Executor: Running task 9.0 in stage 8.0 (TID 221)
18/03/19 07:48:14 INFO TaskSetManager: Finished task 7.0 in stage 8.0 (TID 219) in 4122 ms on localhost (executor driver) (8/96)
18/03/19 07:48:14 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:14 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:301989888+33554432
18/03/19 07:48:14 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:17 INFO Executor: Finished task 8.0 in stage 8.0 (TID 220). 1120 bytes result sent to driver
18/03/19 07:48:17 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:17 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:17 INFO TaskSetManager: Starting task 10.0 in stage 8.0 (TID 222, localhost, executor driver, partition 10, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:17 INFO Executor: Running task 10.0 in stage 8.0 (TID 222)
18/03/19 07:48:17 INFO TaskSetManager: Finished task 8.0 in stage 8.0 (TID 220) in 3145 ms on localhost (executor driver) (9/96)
18/03/19 07:48:17 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:17 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:335544320+33554432
18/03/19 07:48:17 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:17 INFO Executor: Finished task 9.0 in stage 8.0 (TID 221). 1120 bytes result sent to driver
18/03/19 07:48:17 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:17 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:17 INFO TaskSetManager: Starting task 11.0 in stage 8.0 (TID 223, localhost, executor driver, partition 11, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:17 INFO TaskSetManager: Finished task 9.0 in stage 8.0 (TID 221) in 3236 ms on localhost (executor driver) (10/96)
18/03/19 07:48:17 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:17 INFO Executor: Running task 11.0 in stage 8.0 (TID 223)
18/03/19 07:48:17 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:369098752+33554432
18/03/19 07:48:17 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:18 TRACE HeartbeatReceiver: Checking for hosts with no recent heartbeats in HeartbeatReceiver.
18/03/19 07:48:20 INFO Executor: Finished task 10.0 in stage 8.0 (TID 222). 1120 bytes result sent to driver
18/03/19 07:48:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:20 INFO TaskSetManager: Starting task 12.0 in stage 8.0 (TID 224, localhost, executor driver, partition 12, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:20 INFO Executor: Running task 12.0 in stage 8.0 (TID 224)
18/03/19 07:48:20 INFO TaskSetManager: Finished task 10.0 in stage 8.0 (TID 222) in 3265 ms on localhost (executor driver) (11/96)
18/03/19 07:48:20 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:20 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:402653184+33554432
18/03/19 07:48:20 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:20 INFO Executor: Finished task 11.0 in stage 8.0 (TID 223). 1120 bytes result sent to driver
18/03/19 07:48:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:20 INFO TaskSetManager: Starting task 13.0 in stage 8.0 (TID 225, localhost, executor driver, partition 13, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:20 INFO Executor: Running task 13.0 in stage 8.0 (TID 225)
18/03/19 07:48:20 INFO TaskSetManager: Finished task 11.0 in stage 8.0 (TID 223) in 3309 ms on localhost (executor driver) (12/96)
18/03/19 07:48:20 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:20 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:436207616+33554432
18/03/19 07:48:20 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:24 INFO Executor: Finished task 12.0 in stage 8.0 (TID 224). 1120 bytes result sent to driver
18/03/19 07:48:24 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:24 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:24 INFO TaskSetManager: Starting task 14.0 in stage 8.0 (TID 226, localhost, executor driver, partition 14, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:24 INFO Executor: Running task 14.0 in stage 8.0 (TID 226)
18/03/19 07:48:24 INFO TaskSetManager: Finished task 12.0 in stage 8.0 (TID 224) in 3994 ms on localhost (executor driver) (13/96)
18/03/19 07:48:24 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:24 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:469762048+33554432
18/03/19 07:48:24 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:24 INFO Executor: Finished task 13.0 in stage 8.0 (TID 225). 1120 bytes result sent to driver
18/03/19 07:48:24 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:24 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:24 INFO TaskSetManager: Starting task 15.0 in stage 8.0 (TID 227, localhost, executor driver, partition 15, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:24 INFO TaskSetManager: Finished task 13.0 in stage 8.0 (TID 225) in 3908 ms on localhost (executor driver) (14/96)
18/03/19 07:48:24 INFO Executor: Running task 15.0 in stage 8.0 (TID 227)
18/03/19 07:48:24 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:24 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:503316480+33554432
18/03/19 07:48:24 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:28 INFO Executor: Finished task 14.0 in stage 8.0 (TID 226). 1120 bytes result sent to driver
18/03/19 07:48:28 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:28 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:28 INFO TaskSetManager: Starting task 16.0 in stage 8.0 (TID 228, localhost, executor driver, partition 16, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:28 INFO TaskSetManager: Finished task 14.0 in stage 8.0 (TID 226) in 3384 ms on localhost (executor driver) (15/96)
18/03/19 07:48:28 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:28 INFO Executor: Running task 16.0 in stage 8.0 (TID 228)
18/03/19 07:48:28 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:536870912+33554432
18/03/19 07:48:28 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:28 INFO Executor: Finished task 15.0 in stage 8.0 (TID 227). 1120 bytes result sent to driver
18/03/19 07:48:28 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:28 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:28 INFO TaskSetManager: Starting task 17.0 in stage 8.0 (TID 229, localhost, executor driver, partition 17, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:28 INFO Executor: Running task 17.0 in stage 8.0 (TID 229)
18/03/19 07:48:28 INFO TaskSetManager: Finished task 15.0 in stage 8.0 (TID 227) in 3603 ms on localhost (executor driver) (16/96)
18/03/19 07:48:28 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:28 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:570425344+33554432
18/03/19 07:48:28 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:31 INFO Executor: Finished task 17.0 in stage 8.0 (TID 229). 1120 bytes result sent to driver
18/03/19 07:48:31 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:31 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:31 INFO TaskSetManager: Starting task 18.0 in stage 8.0 (TID 230, localhost, executor driver, partition 18, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:31 INFO TaskSetManager: Finished task 17.0 in stage 8.0 (TID 229) in 3095 ms on localhost (executor driver) (17/96)
18/03/19 07:48:31 INFO Executor: Running task 18.0 in stage 8.0 (TID 230)
18/03/19 07:48:31 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:31 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:603979776+33554432
18/03/19 07:48:31 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:31 INFO Executor: Finished task 16.0 in stage 8.0 (TID 228). 1163 bytes result sent to driver
18/03/19 07:48:31 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:31 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:31 INFO TaskSetManager: Starting task 19.0 in stage 8.0 (TID 231, localhost, executor driver, partition 19, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:31 INFO TaskSetManager: Finished task 16.0 in stage 8.0 (TID 228) in 3377 ms on localhost (executor driver) (18/96)
18/03/19 07:48:31 INFO Executor: Running task 19.0 in stage 8.0 (TID 231)
18/03/19 07:48:31 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:31 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:637534208+33554432
18/03/19 07:48:31 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:34 INFO Executor: Finished task 18.0 in stage 8.0 (TID 230). 1120 bytes result sent to driver
18/03/19 07:48:34 INFO Executor: Finished task 19.0 in stage 8.0 (TID 231). 1120 bytes result sent to driver
18/03/19 07:48:34 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:34 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:34 INFO TaskSetManager: Starting task 20.0 in stage 8.0 (TID 232, localhost, executor driver, partition 20, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:34 INFO Executor: Running task 20.0 in stage 8.0 (TID 232)
18/03/19 07:48:34 INFO TaskSetManager: Finished task 18.0 in stage 8.0 (TID 230) in 3487 ms on localhost (executor driver) (19/96)
18/03/19 07:48:34 INFO TaskSetManager: Finished task 19.0 in stage 8.0 (TID 231) in 3477 ms on localhost (executor driver) (20/96)
18/03/19 07:48:34 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:34 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:34 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:34 INFO TaskSetManager: Starting task 21.0 in stage 8.0 (TID 233, localhost, executor driver, partition 21, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:34 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:34 INFO Executor: Running task 21.0 in stage 8.0 (TID 233)
18/03/19 07:48:34 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:671088640+33554432
18/03/19 07:48:34 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:34 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:704643072+33554432
18/03/19 07:48:34 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:38 INFO Executor: Finished task 20.0 in stage 8.0 (TID 232). 1120 bytes result sent to driver
18/03/19 07:48:38 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:38 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:38 INFO TaskSetManager: Starting task 22.0 in stage 8.0 (TID 234, localhost, executor driver, partition 22, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:38 INFO Executor: Running task 22.0 in stage 8.0 (TID 234)
18/03/19 07:48:38 INFO TaskSetManager: Finished task 20.0 in stage 8.0 (TID 232) in 3689 ms on localhost (executor driver) (21/96)
18/03/19 07:48:38 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:38 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:738197504+33554432
18/03/19 07:48:38 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:38 INFO Executor: Finished task 21.0 in stage 8.0 (TID 233). 1120 bytes result sent to driver
18/03/19 07:48:38 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:38 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:38 INFO TaskSetManager: Starting task 23.0 in stage 8.0 (TID 235, localhost, executor driver, partition 23, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:38 INFO TaskSetManager: Finished task 21.0 in stage 8.0 (TID 233) in 3765 ms on localhost (executor driver) (22/96)
18/03/19 07:48:38 INFO Executor: Running task 23.0 in stage 8.0 (TID 235)
18/03/19 07:48:38 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:38 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:771751936+33554432
18/03/19 07:48:38 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:41 INFO Executor: Finished task 22.0 in stage 8.0 (TID 234). 1120 bytes result sent to driver
18/03/19 07:48:41 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:41 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:41 INFO TaskSetManager: Starting task 24.0 in stage 8.0 (TID 236, localhost, executor driver, partition 24, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:41 INFO TaskSetManager: Finished task 22.0 in stage 8.0 (TID 234) in 2987 ms on localhost (executor driver) (23/96)
18/03/19 07:48:41 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:41 INFO Executor: Running task 24.0 in stage 8.0 (TID 236)
18/03/19 07:48:41 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:805306368+33554432
18/03/19 07:48:41 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:41 INFO Executor: Finished task 23.0 in stage 8.0 (TID 235). 1120 bytes result sent to driver
18/03/19 07:48:41 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:41 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:41 INFO TaskSetManager: Starting task 25.0 in stage 8.0 (TID 237, localhost, executor driver, partition 25, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:41 INFO TaskSetManager: Finished task 23.0 in stage 8.0 (TID 235) in 3030 ms on localhost (executor driver) (24/96)
18/03/19 07:48:41 INFO Executor: Running task 25.0 in stage 8.0 (TID 237)
18/03/19 07:48:41 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:41 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:838860800+33554432
18/03/19 07:48:41 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:45 INFO Executor: Finished task 24.0 in stage 8.0 (TID 236). 1120 bytes result sent to driver
18/03/19 07:48:45 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:45 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:45 INFO TaskSetManager: Starting task 26.0 in stage 8.0 (TID 238, localhost, executor driver, partition 26, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:45 INFO TaskSetManager: Finished task 24.0 in stage 8.0 (TID 236) in 3730 ms on localhost (executor driver) (25/96)
18/03/19 07:48:45 INFO Executor: Running task 26.0 in stage 8.0 (TID 238)
18/03/19 07:48:45 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:45 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:872415232+33554432
18/03/19 07:48:45 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:45 INFO Executor: Finished task 25.0 in stage 8.0 (TID 237). 1077 bytes result sent to driver
18/03/19 07:48:45 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:45 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:45 INFO TaskSetManager: Starting task 27.0 in stage 8.0 (TID 239, localhost, executor driver, partition 27, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:45 INFO Executor: Running task 27.0 in stage 8.0 (TID 239)
18/03/19 07:48:45 INFO TaskSetManager: Finished task 25.0 in stage 8.0 (TID 237) in 3618 ms on localhost (executor driver) (26/96)
18/03/19 07:48:45 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:45 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:905969664+33554432
18/03/19 07:48:45 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:48 INFO Executor: Finished task 26.0 in stage 8.0 (TID 238). 1120 bytes result sent to driver
18/03/19 07:48:48 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:48 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:48 INFO TaskSetManager: Starting task 28.0 in stage 8.0 (TID 240, localhost, executor driver, partition 28, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:48 INFO TaskSetManager: Finished task 26.0 in stage 8.0 (TID 238) in 3288 ms on localhost (executor driver) (27/96)
18/03/19 07:48:48 INFO Executor: Running task 28.0 in stage 8.0 (TID 240)
18/03/19 07:48:48 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:48 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:939524096+33554432
18/03/19 07:48:48 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:48 INFO Executor: Finished task 27.0 in stage 8.0 (TID 239). 1120 bytes result sent to driver
18/03/19 07:48:48 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:48 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:48 INFO TaskSetManager: Starting task 29.0 in stage 8.0 (TID 241, localhost, executor driver, partition 29, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:48 INFO TaskSetManager: Finished task 27.0 in stage 8.0 (TID 239) in 3421 ms on localhost (executor driver) (28/96)
18/03/19 07:48:48 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:48 INFO Executor: Running task 29.0 in stage 8.0 (TID 241)
18/03/19 07:48:48 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:973078528+33554432
18/03/19 07:48:48 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:51 INFO Executor: Finished task 28.0 in stage 8.0 (TID 240). 1120 bytes result sent to driver
18/03/19 07:48:51 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:51 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:51 INFO TaskSetManager: Starting task 30.0 in stage 8.0 (TID 242, localhost, executor driver, partition 30, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:51 INFO Executor: Running task 30.0 in stage 8.0 (TID 242)
18/03/19 07:48:51 INFO TaskSetManager: Finished task 28.0 in stage 8.0 (TID 240) in 3091 ms on localhost (executor driver) (29/96)
18/03/19 07:48:51 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:51 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1006632960+33554432
18/03/19 07:48:51 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:51 INFO Executor: Finished task 29.0 in stage 8.0 (TID 241). 1120 bytes result sent to driver
18/03/19 07:48:51 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:51 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:51 INFO TaskSetManager: Starting task 31.0 in stage 8.0 (TID 243, localhost, executor driver, partition 31, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:51 INFO Executor: Running task 31.0 in stage 8.0 (TID 243)
18/03/19 07:48:51 INFO TaskSetManager: Finished task 29.0 in stage 8.0 (TID 241) in 3053 ms on localhost (executor driver) (30/96)
18/03/19 07:48:51 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:51 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1040187392+33554432
18/03/19 07:48:51 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:55 INFO Executor: Finished task 30.0 in stage 8.0 (TID 242). 1077 bytes result sent to driver
18/03/19 07:48:55 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:55 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:55 INFO TaskSetManager: Starting task 32.0 in stage 8.0 (TID 244, localhost, executor driver, partition 32, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:55 INFO TaskSetManager: Finished task 30.0 in stage 8.0 (TID 242) in 3480 ms on localhost (executor driver) (31/96)
18/03/19 07:48:55 INFO Executor: Running task 32.0 in stage 8.0 (TID 244)
18/03/19 07:48:55 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:55 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1073741824+33554432
18/03/19 07:48:55 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:55 INFO Executor: Finished task 31.0 in stage 8.0 (TID 243). 1077 bytes result sent to driver
18/03/19 07:48:55 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:55 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:55 INFO TaskSetManager: Starting task 33.0 in stage 8.0 (TID 245, localhost, executor driver, partition 33, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:55 INFO TaskSetManager: Finished task 31.0 in stage 8.0 (TID 243) in 3601 ms on localhost (executor driver) (32/96)
18/03/19 07:48:55 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:55 INFO Executor: Running task 33.0 in stage 8.0 (TID 245)
18/03/19 07:48:55 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1107296256+33554432
18/03/19 07:48:55 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:58 INFO Executor: Finished task 32.0 in stage 8.0 (TID 244). 1120 bytes result sent to driver
18/03/19 07:48:58 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:58 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:58 INFO TaskSetManager: Starting task 34.0 in stage 8.0 (TID 246, localhost, executor driver, partition 34, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:58 INFO Executor: Running task 34.0 in stage 8.0 (TID 246)
18/03/19 07:48:58 INFO TaskSetManager: Finished task 32.0 in stage 8.0 (TID 244) in 3234 ms on localhost (executor driver) (33/96)
18/03/19 07:48:58 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:58 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1140850688+33554432
18/03/19 07:48:58 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:48:58 INFO Executor: Finished task 33.0 in stage 8.0 (TID 245). 1120 bytes result sent to driver
18/03/19 07:48:58 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:48:58 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:48:58 INFO TaskSetManager: Starting task 35.0 in stage 8.0 (TID 247, localhost, executor driver, partition 35, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:48:58 INFO Executor: Running task 35.0 in stage 8.0 (TID 247)
18/03/19 07:48:58 INFO TaskSetManager: Finished task 33.0 in stage 8.0 (TID 245) in 3176 ms on localhost (executor driver) (34/96)
18/03/19 07:48:58 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:48:58 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1174405120+33554432
18/03/19 07:48:58 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:01 INFO Executor: Finished task 34.0 in stage 8.0 (TID 246). 1120 bytes result sent to driver
18/03/19 07:49:01 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:01 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:01 INFO TaskSetManager: Starting task 36.0 in stage 8.0 (TID 248, localhost, executor driver, partition 36, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:01 INFO TaskSetManager: Finished task 34.0 in stage 8.0 (TID 246) in 3230 ms on localhost (executor driver) (35/96)
18/03/19 07:49:01 INFO Executor: Running task 36.0 in stage 8.0 (TID 248)
18/03/19 07:49:01 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:01 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1207959552+33554432
18/03/19 07:49:01 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:01 INFO Executor: Finished task 35.0 in stage 8.0 (TID 247). 1120 bytes result sent to driver
18/03/19 07:49:01 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:01 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:01 INFO TaskSetManager: Starting task 37.0 in stage 8.0 (TID 249, localhost, executor driver, partition 37, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:01 INFO Executor: Running task 37.0 in stage 8.0 (TID 249)
18/03/19 07:49:01 INFO TaskSetManager: Finished task 35.0 in stage 8.0 (TID 247) in 3343 ms on localhost (executor driver) (36/96)
18/03/19 07:49:01 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:01 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1241513984+33554432
18/03/19 07:49:01 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:05 INFO Executor: Finished task 36.0 in stage 8.0 (TID 248). 1120 bytes result sent to driver
18/03/19 07:49:05 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:05 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:05 INFO TaskSetManager: Starting task 38.0 in stage 8.0 (TID 250, localhost, executor driver, partition 38, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:05 INFO Executor: Running task 38.0 in stage 8.0 (TID 250)
18/03/19 07:49:05 INFO TaskSetManager: Finished task 36.0 in stage 8.0 (TID 248) in 3831 ms on localhost (executor driver) (37/96)
18/03/19 07:49:05 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:05 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1275068416+33554432
18/03/19 07:49:05 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:05 INFO Executor: Finished task 37.0 in stage 8.0 (TID 249). 1120 bytes result sent to driver
18/03/19 07:49:05 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:05 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:05 INFO TaskSetManager: Starting task 39.0 in stage 8.0 (TID 251, localhost, executor driver, partition 39, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:05 INFO Executor: Running task 39.0 in stage 8.0 (TID 251)
18/03/19 07:49:05 INFO TaskSetManager: Finished task 37.0 in stage 8.0 (TID 249) in 3782 ms on localhost (executor driver) (38/96)
18/03/19 07:49:05 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:05 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1308622848+33554432
18/03/19 07:49:05 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:08 INFO Executor: Finished task 38.0 in stage 8.0 (TID 250). 1120 bytes result sent to driver
18/03/19 07:49:08 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:08 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:08 INFO TaskSetManager: Starting task 40.0 in stage 8.0 (TID 252, localhost, executor driver, partition 40, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:08 INFO Executor: Running task 40.0 in stage 8.0 (TID 252)
18/03/19 07:49:08 INFO TaskSetManager: Finished task 38.0 in stage 8.0 (TID 250) in 3020 ms on localhost (executor driver) (39/96)
18/03/19 07:49:08 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:08 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1342177280+33554432
18/03/19 07:49:08 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:08 INFO Executor: Finished task 39.0 in stage 8.0 (TID 251). 1120 bytes result sent to driver
18/03/19 07:49:08 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:08 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:08 INFO TaskSetManager: Starting task 41.0 in stage 8.0 (TID 253, localhost, executor driver, partition 41, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:08 INFO Executor: Running task 41.0 in stage 8.0 (TID 253)
18/03/19 07:49:08 INFO TaskSetManager: Finished task 39.0 in stage 8.0 (TID 251) in 3104 ms on localhost (executor driver) (40/96)
18/03/19 07:49:08 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:08 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1375731712+33554432
18/03/19 07:49:08 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:11 INFO Executor: Finished task 40.0 in stage 8.0 (TID 252). 1120 bytes result sent to driver
18/03/19 07:49:11 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:11 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:11 INFO TaskSetManager: Starting task 42.0 in stage 8.0 (TID 254, localhost, executor driver, partition 42, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:11 INFO TaskSetManager: Finished task 40.0 in stage 8.0 (TID 252) in 3026 ms on localhost (executor driver) (41/96)
18/03/19 07:49:11 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:11 INFO Executor: Running task 42.0 in stage 8.0 (TID 254)
18/03/19 07:49:11 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1409286144+33554432
18/03/19 07:49:11 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:11 INFO Executor: Finished task 41.0 in stage 8.0 (TID 253). 1120 bytes result sent to driver
18/03/19 07:49:11 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:11 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:11 INFO TaskSetManager: Starting task 43.0 in stage 8.0 (TID 255, localhost, executor driver, partition 43, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:11 INFO TaskSetManager: Finished task 41.0 in stage 8.0 (TID 253) in 3023 ms on localhost (executor driver) (42/96)
18/03/19 07:49:11 INFO Executor: Running task 43.0 in stage 8.0 (TID 255)
18/03/19 07:49:11 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:11 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1442840576+33554432
18/03/19 07:49:11 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:15 INFO Executor: Finished task 43.0 in stage 8.0 (TID 255). 1120 bytes result sent to driver
18/03/19 07:49:15 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:15 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:15 INFO TaskSetManager: Starting task 44.0 in stage 8.0 (TID 256, localhost, executor driver, partition 44, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:15 INFO Executor: Running task 44.0 in stage 8.0 (TID 256)
18/03/19 07:49:15 INFO TaskSetManager: Finished task 43.0 in stage 8.0 (TID 255) in 3472 ms on localhost (executor driver) (43/96)
18/03/19 07:49:15 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:15 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1476395008+33554432
18/03/19 07:49:15 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:15 INFO Executor: Finished task 42.0 in stage 8.0 (TID 254). 1120 bytes result sent to driver
18/03/19 07:49:15 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:15 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:15 INFO TaskSetManager: Starting task 45.0 in stage 8.0 (TID 257, localhost, executor driver, partition 45, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:15 INFO Executor: Running task 45.0 in stage 8.0 (TID 257)
18/03/19 07:49:15 INFO TaskSetManager: Finished task 42.0 in stage 8.0 (TID 254) in 3796 ms on localhost (executor driver) (44/96)
18/03/19 07:49:15 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:15 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1509949440+33554432
18/03/19 07:49:15 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:18 INFO Executor: Finished task 44.0 in stage 8.0 (TID 256). 1120 bytes result sent to driver
18/03/19 07:49:18 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:18 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:18 INFO TaskSetManager: Starting task 46.0 in stage 8.0 (TID 258, localhost, executor driver, partition 46, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:18 INFO TaskSetManager: Finished task 44.0 in stage 8.0 (TID 256) in 2935 ms on localhost (executor driver) (45/96)
18/03/19 07:49:18 INFO Executor: Running task 46.0 in stage 8.0 (TID 258)
18/03/19 07:49:18 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:18 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1543503872+33554432
18/03/19 07:49:18 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:18 INFO Executor: Finished task 45.0 in stage 8.0 (TID 257). 1120 bytes result sent to driver
18/03/19 07:49:18 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:18 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:18 INFO TaskSetManager: Starting task 47.0 in stage 8.0 (TID 259, localhost, executor driver, partition 47, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:18 INFO Executor: Running task 47.0 in stage 8.0 (TID 259)
18/03/19 07:49:18 INFO TaskSetManager: Finished task 45.0 in stage 8.0 (TID 257) in 2969 ms on localhost (executor driver) (46/96)
18/03/19 07:49:18 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:18 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1577058304+33554432
18/03/19 07:49:18 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:18 TRACE HeartbeatReceiver: Checking for hosts with no recent heartbeats in HeartbeatReceiver.
18/03/19 07:49:21 INFO Executor: Finished task 46.0 in stage 8.0 (TID 258). 1120 bytes result sent to driver
18/03/19 07:49:21 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:21 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:21 INFO TaskSetManager: Starting task 48.0 in stage 8.0 (TID 260, localhost, executor driver, partition 48, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:21 INFO Executor: Running task 48.0 in stage 8.0 (TID 260)
18/03/19 07:49:21 INFO TaskSetManager: Finished task 46.0 in stage 8.0 (TID 258) in 3023 ms on localhost (executor driver) (47/96)
18/03/19 07:49:21 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:21 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1610612736+33554432
18/03/19 07:49:21 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:21 INFO Executor: Finished task 47.0 in stage 8.0 (TID 259). 1120 bytes result sent to driver
18/03/19 07:49:21 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:21 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:21 INFO TaskSetManager: Starting task 49.0 in stage 8.0 (TID 261, localhost, executor driver, partition 49, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:21 INFO Executor: Running task 49.0 in stage 8.0 (TID 261)
18/03/19 07:49:21 INFO TaskSetManager: Finished task 47.0 in stage 8.0 (TID 259) in 3099 ms on localhost (executor driver) (48/96)
18/03/19 07:49:21 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:21 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1644167168+33554432
18/03/19 07:49:21 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:24 INFO Executor: Finished task 48.0 in stage 8.0 (TID 260). 1120 bytes result sent to driver
18/03/19 07:49:24 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:24 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:24 INFO TaskSetManager: Starting task 50.0 in stage 8.0 (TID 262, localhost, executor driver, partition 50, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:24 INFO Executor: Running task 50.0 in stage 8.0 (TID 262)
18/03/19 07:49:24 INFO TaskSetManager: Finished task 48.0 in stage 8.0 (TID 260) in 3704 ms on localhost (executor driver) (49/96)
18/03/19 07:49:24 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:24 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1677721600+33554432
18/03/19 07:49:24 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:25 INFO Executor: Finished task 49.0 in stage 8.0 (TID 261). 1120 bytes result sent to driver
18/03/19 07:49:25 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:25 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:25 INFO TaskSetManager: Starting task 51.0 in stage 8.0 (TID 263, localhost, executor driver, partition 51, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:25 INFO Executor: Running task 51.0 in stage 8.0 (TID 263)
18/03/19 07:49:25 INFO TaskSetManager: Finished task 49.0 in stage 8.0 (TID 261) in 4259 ms on localhost (executor driver) (50/96)
18/03/19 07:49:25 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:25 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1711276032+33554432
18/03/19 07:49:25 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:28 INFO Executor: Finished task 50.0 in stage 8.0 (TID 262). 1120 bytes result sent to driver
18/03/19 07:49:28 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:28 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:28 INFO TaskSetManager: Starting task 52.0 in stage 8.0 (TID 264, localhost, executor driver, partition 52, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:28 INFO Executor: Running task 52.0 in stage 8.0 (TID 264)
18/03/19 07:49:28 INFO TaskSetManager: Finished task 50.0 in stage 8.0 (TID 262) in 3426 ms on localhost (executor driver) (51/96)
18/03/19 07:49:28 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:28 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1744830464+33554432
18/03/19 07:49:28 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:28 INFO Executor: Finished task 51.0 in stage 8.0 (TID 263). 1120 bytes result sent to driver
18/03/19 07:49:28 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:28 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:28 INFO TaskSetManager: Starting task 53.0 in stage 8.0 (TID 265, localhost, executor driver, partition 53, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:28 INFO TaskSetManager: Finished task 51.0 in stage 8.0 (TID 263) in 3280 ms on localhost (executor driver) (52/96)
18/03/19 07:49:28 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:28 INFO Executor: Running task 53.0 in stage 8.0 (TID 265)
18/03/19 07:49:28 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1778384896+33554432
18/03/19 07:49:28 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:31 INFO Executor: Finished task 52.0 in stage 8.0 (TID 264). 1120 bytes result sent to driver
18/03/19 07:49:31 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:31 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:31 INFO TaskSetManager: Starting task 54.0 in stage 8.0 (TID 266, localhost, executor driver, partition 54, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:31 INFO Executor: Running task 54.0 in stage 8.0 (TID 266)
18/03/19 07:49:31 INFO TaskSetManager: Finished task 52.0 in stage 8.0 (TID 264) in 3451 ms on localhost (executor driver) (53/96)
18/03/19 07:49:31 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:31 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1811939328+33554432
18/03/19 07:49:31 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:32 INFO Executor: Finished task 53.0 in stage 8.0 (TID 265). 1120 bytes result sent to driver
18/03/19 07:49:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:32 INFO TaskSetManager: Starting task 55.0 in stage 8.0 (TID 267, localhost, executor driver, partition 55, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:32 INFO Executor: Running task 55.0 in stage 8.0 (TID 267)
18/03/19 07:49:32 INFO TaskSetManager: Finished task 53.0 in stage 8.0 (TID 265) in 3279 ms on localhost (executor driver) (54/96)
18/03/19 07:49:32 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:32 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1845493760+33554432
18/03/19 07:49:32 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:35 INFO Executor: Finished task 54.0 in stage 8.0 (TID 266). 1120 bytes result sent to driver
18/03/19 07:49:35 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:35 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:35 INFO TaskSetManager: Starting task 56.0 in stage 8.0 (TID 268, localhost, executor driver, partition 56, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:35 INFO TaskSetManager: Finished task 54.0 in stage 8.0 (TID 266) in 3932 ms on localhost (executor driver) (55/96)
18/03/19 07:49:35 INFO Executor: Running task 56.0 in stage 8.0 (TID 268)
18/03/19 07:49:35 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:35 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1879048192+33554432
18/03/19 07:49:35 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:36 INFO Executor: Finished task 55.0 in stage 8.0 (TID 267). 1120 bytes result sent to driver
18/03/19 07:49:36 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:36 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:36 INFO TaskSetManager: Starting task 57.0 in stage 8.0 (TID 269, localhost, executor driver, partition 57, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:36 INFO TaskSetManager: Finished task 55.0 in stage 8.0 (TID 267) in 4073 ms on localhost (executor driver) (56/96)
18/03/19 07:49:36 INFO Executor: Running task 57.0 in stage 8.0 (TID 269)
18/03/19 07:49:36 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:36 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1912602624+33554432
18/03/19 07:49:36 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:38 INFO Executor: Finished task 56.0 in stage 8.0 (TID 268). 1077 bytes result sent to driver
18/03/19 07:49:38 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:38 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:38 INFO TaskSetManager: Starting task 58.0 in stage 8.0 (TID 270, localhost, executor driver, partition 58, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:38 INFO TaskSetManager: Finished task 56.0 in stage 8.0 (TID 268) in 3209 ms on localhost (executor driver) (57/96)
18/03/19 07:49:38 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:38 INFO Executor: Running task 58.0 in stage 8.0 (TID 270)
18/03/19 07:49:38 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1946157056+33554432
18/03/19 07:49:38 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:39 INFO Executor: Finished task 57.0 in stage 8.0 (TID 269). 1163 bytes result sent to driver
18/03/19 07:49:39 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:39 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:39 INFO TaskSetManager: Starting task 59.0 in stage 8.0 (TID 271, localhost, executor driver, partition 59, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:39 INFO TaskSetManager: Finished task 57.0 in stage 8.0 (TID 269) in 3060 ms on localhost (executor driver) (58/96)
18/03/19 07:49:39 INFO Executor: Running task 59.0 in stage 8.0 (TID 271)
18/03/19 07:49:39 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:39 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:1979711488+33554432
18/03/19 07:49:39 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:42 INFO Executor: Finished task 58.0 in stage 8.0 (TID 270). 1120 bytes result sent to driver
18/03/19 07:49:42 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:42 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:42 INFO TaskSetManager: Starting task 60.0 in stage 8.0 (TID 272, localhost, executor driver, partition 60, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:42 INFO Executor: Running task 60.0 in stage 8.0 (TID 272)
18/03/19 07:49:42 INFO TaskSetManager: Finished task 58.0 in stage 8.0 (TID 270) in 3144 ms on localhost (executor driver) (59/96)
18/03/19 07:49:42 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:42 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2013265920+33554432
18/03/19 07:49:42 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:42 INFO Executor: Finished task 59.0 in stage 8.0 (TID 271). 1120 bytes result sent to driver
18/03/19 07:49:42 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:42 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:42 INFO TaskSetManager: Starting task 61.0 in stage 8.0 (TID 273, localhost, executor driver, partition 61, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:42 INFO TaskSetManager: Finished task 59.0 in stage 8.0 (TID 271) in 3120 ms on localhost (executor driver) (60/96)
18/03/19 07:49:42 INFO Executor: Running task 61.0 in stage 8.0 (TID 273)
18/03/19 07:49:42 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:42 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2046820352+33554432
18/03/19 07:49:42 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:45 INFO Executor: Finished task 60.0 in stage 8.0 (TID 272). 1120 bytes result sent to driver
18/03/19 07:49:45 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:45 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:45 INFO TaskSetManager: Starting task 62.0 in stage 8.0 (TID 274, localhost, executor driver, partition 62, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:45 INFO Executor: Running task 62.0 in stage 8.0 (TID 274)
18/03/19 07:49:45 INFO TaskSetManager: Finished task 60.0 in stage 8.0 (TID 272) in 3496 ms on localhost (executor driver) (61/96)
18/03/19 07:49:45 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:45 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2080374784+33554432
18/03/19 07:49:45 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:46 INFO Executor: Finished task 61.0 in stage 8.0 (TID 273). 1120 bytes result sent to driver
18/03/19 07:49:46 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:46 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:46 INFO TaskSetManager: Starting task 63.0 in stage 8.0 (TID 275, localhost, executor driver, partition 63, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:46 INFO Executor: Running task 63.0 in stage 8.0 (TID 275)
18/03/19 07:49:46 INFO TaskSetManager: Finished task 61.0 in stage 8.0 (TID 273) in 3623 ms on localhost (executor driver) (62/96)
18/03/19 07:49:46 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:46 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2113929216+33554432
18/03/19 07:49:46 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:48 INFO Executor: Finished task 62.0 in stage 8.0 (TID 274). 1077 bytes result sent to driver
18/03/19 07:49:48 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:48 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:48 INFO TaskSetManager: Starting task 64.0 in stage 8.0 (TID 276, localhost, executor driver, partition 64, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:48 INFO Executor: Running task 64.0 in stage 8.0 (TID 276)
18/03/19 07:49:48 INFO TaskSetManager: Finished task 62.0 in stage 8.0 (TID 274) in 3005 ms on localhost (executor driver) (63/96)
18/03/19 07:49:48 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:48 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2147483648+33554432
18/03/19 07:49:48 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:48 INFO Executor: Finished task 63.0 in stage 8.0 (TID 275). 1120 bytes result sent to driver
18/03/19 07:49:48 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:48 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:48 INFO TaskSetManager: Starting task 65.0 in stage 8.0 (TID 277, localhost, executor driver, partition 65, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:48 INFO TaskSetManager: Finished task 63.0 in stage 8.0 (TID 275) in 2788 ms on localhost (executor driver) (64/96)
18/03/19 07:49:48 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:48 INFO Executor: Running task 65.0 in stage 8.0 (TID 277)
18/03/19 07:49:48 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2181038080+33554432
18/03/19 07:49:48 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:52 INFO Executor: Finished task 64.0 in stage 8.0 (TID 276). 1120 bytes result sent to driver
18/03/19 07:49:52 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:52 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:52 INFO TaskSetManager: Starting task 66.0 in stage 8.0 (TID 278, localhost, executor driver, partition 66, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:52 INFO TaskSetManager: Finished task 64.0 in stage 8.0 (TID 276) in 3556 ms on localhost (executor driver) (65/96)
18/03/19 07:49:52 INFO Executor: Running task 66.0 in stage 8.0 (TID 278)
18/03/19 07:49:52 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:52 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2214592512+33554432
18/03/19 07:49:52 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:52 INFO Executor: Finished task 65.0 in stage 8.0 (TID 277). 1120 bytes result sent to driver
18/03/19 07:49:52 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:52 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:52 INFO TaskSetManager: Starting task 67.0 in stage 8.0 (TID 279, localhost, executor driver, partition 67, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:52 INFO Executor: Running task 67.0 in stage 8.0 (TID 279)
18/03/19 07:49:52 INFO TaskSetManager: Finished task 65.0 in stage 8.0 (TID 277) in 3670 ms on localhost (executor driver) (66/96)
18/03/19 07:49:52 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:52 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2248146944+33554432
18/03/19 07:49:52 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:56 INFO Executor: Finished task 66.0 in stage 8.0 (TID 278). 1077 bytes result sent to driver
18/03/19 07:49:56 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:56 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:56 INFO TaskSetManager: Starting task 68.0 in stage 8.0 (TID 280, localhost, executor driver, partition 68, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:56 INFO Executor: Running task 68.0 in stage 8.0 (TID 280)
18/03/19 07:49:56 INFO TaskSetManager: Finished task 66.0 in stage 8.0 (TID 278) in 3865 ms on localhost (executor driver) (67/96)
18/03/19 07:49:56 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:56 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2281701376+33554432
18/03/19 07:49:56 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:56 INFO Executor: Finished task 67.0 in stage 8.0 (TID 279). 1120 bytes result sent to driver
18/03/19 07:49:56 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:56 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:56 INFO TaskSetManager: Starting task 69.0 in stage 8.0 (TID 281, localhost, executor driver, partition 69, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:56 INFO Executor: Running task 69.0 in stage 8.0 (TID 281)
18/03/19 07:49:56 INFO TaskSetManager: Finished task 67.0 in stage 8.0 (TID 279) in 3784 ms on localhost (executor driver) (68/96)
18/03/19 07:49:56 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:56 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2315255808+33554432
18/03/19 07:49:56 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:59 INFO Executor: Finished task 69.0 in stage 8.0 (TID 281). 1120 bytes result sent to driver
18/03/19 07:49:59 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:59 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:59 INFO TaskSetManager: Starting task 70.0 in stage 8.0 (TID 282, localhost, executor driver, partition 70, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:59 INFO Executor: Running task 70.0 in stage 8.0 (TID 282)
18/03/19 07:49:59 INFO TaskSetManager: Finished task 69.0 in stage 8.0 (TID 281) in 3102 ms on localhost (executor driver) (69/96)
18/03/19 07:49:59 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:59 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2348810240+33554432
18/03/19 07:49:59 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:49:59 INFO Executor: Finished task 68.0 in stage 8.0 (TID 280). 1120 bytes result sent to driver
18/03/19 07:49:59 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:49:59 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:49:59 INFO TaskSetManager: Starting task 71.0 in stage 8.0 (TID 283, localhost, executor driver, partition 71, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:49:59 INFO Executor: Running task 71.0 in stage 8.0 (TID 283)
18/03/19 07:49:59 INFO TaskSetManager: Finished task 68.0 in stage 8.0 (TID 280) in 3488 ms on localhost (executor driver) (70/96)
18/03/19 07:49:59 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:49:59 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2382364672+33554432
18/03/19 07:49:59 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:02 INFO Executor: Finished task 70.0 in stage 8.0 (TID 282). 1120 bytes result sent to driver
18/03/19 07:50:02 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:02 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:02 INFO TaskSetManager: Starting task 72.0 in stage 8.0 (TID 284, localhost, executor driver, partition 72, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:50:02 INFO Executor: Running task 72.0 in stage 8.0 (TID 284)
18/03/19 07:50:02 INFO TaskSetManager: Finished task 70.0 in stage 8.0 (TID 282) in 3601 ms on localhost (executor driver) (71/96)
18/03/19 07:50:02 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:02 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2415919104+33554432
18/03/19 07:50:02 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:03 INFO Executor: Finished task 71.0 in stage 8.0 (TID 283). 1120 bytes result sent to driver
18/03/19 07:50:03 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:03 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:03 INFO TaskSetManager: Starting task 73.0 in stage 8.0 (TID 285, localhost, executor driver, partition 73, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:50:03 INFO Executor: Running task 73.0 in stage 8.0 (TID 285)
18/03/19 07:50:03 INFO TaskSetManager: Finished task 71.0 in stage 8.0 (TID 283) in 3708 ms on localhost (executor driver) (72/96)
18/03/19 07:50:03 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:03 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2449473536+33554432
18/03/19 07:50:03 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:07 INFO Executor: Finished task 72.0 in stage 8.0 (TID 284). 1120 bytes result sent to driver
18/03/19 07:50:07 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:07 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:07 INFO TaskSetManager: Starting task 74.0 in stage 8.0 (TID 286, localhost, executor driver, partition 74, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:50:07 INFO Executor: Running task 74.0 in stage 8.0 (TID 286)
18/03/19 07:50:07 INFO TaskSetManager: Finished task 72.0 in stage 8.0 (TID 284) in 4455 ms on localhost (executor driver) (73/96)
18/03/19 07:50:07 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:07 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2483027968+33554432
18/03/19 07:50:07 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:07 INFO Executor: Finished task 73.0 in stage 8.0 (TID 285). 1120 bytes result sent to driver
18/03/19 07:50:07 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:07 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:07 INFO TaskSetManager: Starting task 75.0 in stage 8.0 (TID 287, localhost, executor driver, partition 75, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:50:07 INFO Executor: Running task 75.0 in stage 8.0 (TID 287)
18/03/19 07:50:07 INFO TaskSetManager: Finished task 73.0 in stage 8.0 (TID 285) in 4361 ms on localhost (executor driver) (74/96)
18/03/19 07:50:07 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:07 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2516582400+33554432
18/03/19 07:50:07 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:10 INFO Executor: Finished task 74.0 in stage 8.0 (TID 286). 1120 bytes result sent to driver
18/03/19 07:50:10 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:10 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:10 INFO TaskSetManager: Starting task 76.0 in stage 8.0 (TID 288, localhost, executor driver, partition 76, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:50:10 INFO Executor: Running task 76.0 in stage 8.0 (TID 288)
18/03/19 07:50:10 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2550136832+33554432
18/03/19 07:50:10 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:10 INFO TaskSetManager: Finished task 74.0 in stage 8.0 (TID 286) in 2823 ms on localhost (executor driver) (75/96)
18/03/19 07:50:10 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:10 INFO Executor: Finished task 75.0 in stage 8.0 (TID 287). 1120 bytes result sent to driver
18/03/19 07:50:10 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:10 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:10 INFO TaskSetManager: Starting task 77.0 in stage 8.0 (TID 289, localhost, executor driver, partition 77, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:50:10 INFO Executor: Running task 77.0 in stage 8.0 (TID 289)
18/03/19 07:50:10 INFO TaskSetManager: Finished task 75.0 in stage 8.0 (TID 287) in 2827 ms on localhost (executor driver) (76/96)
18/03/19 07:50:10 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:10 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2583691264+33554432
18/03/19 07:50:10 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:13 INFO Executor: Finished task 76.0 in stage 8.0 (TID 288). 1120 bytes result sent to driver
18/03/19 07:50:13 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:13 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:13 INFO TaskSetManager: Starting task 78.0 in stage 8.0 (TID 290, localhost, executor driver, partition 78, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:50:13 INFO Executor: Running task 78.0 in stage 8.0 (TID 290)
18/03/19 07:50:13 INFO TaskSetManager: Finished task 76.0 in stage 8.0 (TID 288) in 3098 ms on localhost (executor driver) (77/96)
18/03/19 07:50:13 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2617245696+33554432
18/03/19 07:50:13 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:13 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:13 INFO Executor: Finished task 77.0 in stage 8.0 (TID 289). 1120 bytes result sent to driver
18/03/19 07:50:13 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:13 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:13 INFO TaskSetManager: Starting task 79.0 in stage 8.0 (TID 291, localhost, executor driver, partition 79, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:50:13 INFO Executor: Running task 79.0 in stage 8.0 (TID 291)
18/03/19 07:50:13 INFO TaskSetManager: Finished task 77.0 in stage 8.0 (TID 289) in 3139 ms on localhost (executor driver) (78/96)
18/03/19 07:50:13 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:13 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2650800128+33554432
18/03/19 07:50:13 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:17 INFO Executor: Finished task 78.0 in stage 8.0 (TID 290). 1120 bytes result sent to driver
18/03/19 07:50:17 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:17 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:17 INFO TaskSetManager: Starting task 80.0 in stage 8.0 (TID 292, localhost, executor driver, partition 80, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:50:17 INFO Executor: Running task 80.0 in stage 8.0 (TID 292)
18/03/19 07:50:17 INFO TaskSetManager: Finished task 78.0 in stage 8.0 (TID 290) in 4180 ms on localhost (executor driver) (79/96)
18/03/19 07:50:17 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:17 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2684354560+33554432
18/03/19 07:50:17 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:17 INFO Executor: Finished task 79.0 in stage 8.0 (TID 291). 1120 bytes result sent to driver
18/03/19 07:50:17 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:17 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:17 INFO TaskSetManager: Starting task 81.0 in stage 8.0 (TID 293, localhost, executor driver, partition 81, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:50:17 INFO TaskSetManager: Finished task 79.0 in stage 8.0 (TID 291) in 4235 ms on localhost (executor driver) (80/96)
18/03/19 07:50:17 INFO Executor: Running task 81.0 in stage 8.0 (TID 293)
18/03/19 07:50:17 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:17 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2717908992+33554432
18/03/19 07:50:17 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:18 TRACE HeartbeatReceiver: Checking for hosts with no recent heartbeats in HeartbeatReceiver.
18/03/19 07:50:20 INFO Executor: Finished task 80.0 in stage 8.0 (TID 292). 1120 bytes result sent to driver
18/03/19 07:50:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:20 INFO TaskSetManager: Starting task 82.0 in stage 8.0 (TID 294, localhost, executor driver, partition 82, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:50:20 INFO Executor: Running task 82.0 in stage 8.0 (TID 294)
18/03/19 07:50:20 INFO TaskSetManager: Finished task 80.0 in stage 8.0 (TID 292) in 2873 ms on localhost (executor driver) (81/96)
18/03/19 07:50:20 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:20 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2751463424+33554432
18/03/19 07:50:20 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:20 INFO Executor: Finished task 81.0 in stage 8.0 (TID 293). 1120 bytes result sent to driver
18/03/19 07:50:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:20 INFO TaskSetManager: Starting task 83.0 in stage 8.0 (TID 295, localhost, executor driver, partition 83, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:50:20 INFO Executor: Running task 83.0 in stage 8.0 (TID 295)
18/03/19 07:50:20 INFO TaskSetManager: Finished task 81.0 in stage 8.0 (TID 293) in 2891 ms on localhost (executor driver) (82/96)
18/03/19 07:50:20 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:20 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2785017856+33554432
18/03/19 07:50:20 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:23 INFO Executor: Finished task 82.0 in stage 8.0 (TID 294). 1120 bytes result sent to driver
18/03/19 07:50:23 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:23 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:23 INFO TaskSetManager: Starting task 84.0 in stage 8.0 (TID 296, localhost, executor driver, partition 84, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:50:23 INFO Executor: Running task 84.0 in stage 8.0 (TID 296)
18/03/19 07:50:23 INFO TaskSetManager: Finished task 82.0 in stage 8.0 (TID 294) in 3114 ms on localhost (executor driver) (83/96)
18/03/19 07:50:23 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:23 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2818572288+33554432
18/03/19 07:50:23 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:23 INFO Executor: Finished task 83.0 in stage 8.0 (TID 295). 1120 bytes result sent to driver
18/03/19 07:50:23 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:23 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:23 INFO TaskSetManager: Starting task 85.0 in stage 8.0 (TID 297, localhost, executor driver, partition 85, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:50:23 INFO Executor: Running task 85.0 in stage 8.0 (TID 297)
18/03/19 07:50:23 INFO TaskSetManager: Finished task 83.0 in stage 8.0 (TID 295) in 3165 ms on localhost (executor driver) (84/96)
18/03/19 07:50:23 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:23 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2852126720+33554432
18/03/19 07:50:23 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:27 INFO Executor: Finished task 84.0 in stage 8.0 (TID 296). 1120 bytes result sent to driver
18/03/19 07:50:27 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:27 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:27 INFO TaskSetManager: Starting task 86.0 in stage 8.0 (TID 298, localhost, executor driver, partition 86, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:50:27 INFO Executor: Running task 86.0 in stage 8.0 (TID 298)
18/03/19 07:50:27 INFO TaskSetManager: Finished task 84.0 in stage 8.0 (TID 296) in 4118 ms on localhost (executor driver) (85/96)
18/03/19 07:50:27 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:27 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2885681152+33554432
18/03/19 07:50:27 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:27 INFO Executor: Finished task 85.0 in stage 8.0 (TID 297). 1120 bytes result sent to driver
18/03/19 07:50:27 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:27 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:27 INFO TaskSetManager: Starting task 87.0 in stage 8.0 (TID 299, localhost, executor driver, partition 87, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:50:27 INFO Executor: Running task 87.0 in stage 8.0 (TID 299)
18/03/19 07:50:27 INFO TaskSetManager: Finished task 85.0 in stage 8.0 (TID 297) in 4056 ms on localhost (executor driver) (86/96)
18/03/19 07:50:27 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:27 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2919235584+33554432
18/03/19 07:50:27 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:32 INFO Executor: Finished task 86.0 in stage 8.0 (TID 298). 1120 bytes result sent to driver
18/03/19 07:50:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:32 INFO TaskSetManager: Starting task 88.0 in stage 8.0 (TID 300, localhost, executor driver, partition 88, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:50:32 INFO Executor: Running task 88.0 in stage 8.0 (TID 300)
18/03/19 07:50:32 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2952790016+33554432
18/03/19 07:50:32 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:32 INFO TaskSetManager: Finished task 86.0 in stage 8.0 (TID 298) in 4624 ms on localhost (executor driver) (87/96)
18/03/19 07:50:32 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:32 INFO Executor: Finished task 87.0 in stage 8.0 (TID 299). 1120 bytes result sent to driver
18/03/19 07:50:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:32 INFO TaskSetManager: Starting task 89.0 in stage 8.0 (TID 301, localhost, executor driver, partition 89, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:50:32 INFO TaskSetManager: Finished task 87.0 in stage 8.0 (TID 299) in 4542 ms on localhost (executor driver) (88/96)
18/03/19 07:50:32 INFO Executor: Running task 89.0 in stage 8.0 (TID 301)
18/03/19 07:50:32 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:32 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:2986344448+33554432
18/03/19 07:50:32 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:35 INFO Executor: Finished task 88.0 in stage 8.0 (TID 300). 1120 bytes result sent to driver
18/03/19 07:50:35 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:35 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:35 INFO TaskSetManager: Starting task 90.0 in stage 8.0 (TID 302, localhost, executor driver, partition 90, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:50:35 INFO Executor: Running task 90.0 in stage 8.0 (TID 302)
18/03/19 07:50:35 INFO TaskSetManager: Finished task 88.0 in stage 8.0 (TID 300) in 2887 ms on localhost (executor driver) (89/96)
18/03/19 07:50:35 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:35 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:3019898880+33554432
18/03/19 07:50:35 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:35 INFO Executor: Finished task 89.0 in stage 8.0 (TID 301). 1120 bytes result sent to driver
18/03/19 07:50:35 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:35 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:35 INFO TaskSetManager: Starting task 91.0 in stage 8.0 (TID 303, localhost, executor driver, partition 91, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:50:35 INFO Executor: Running task 91.0 in stage 8.0 (TID 303)
18/03/19 07:50:35 INFO TaskSetManager: Finished task 89.0 in stage 8.0 (TID 301) in 2852 ms on localhost (executor driver) (90/96)
18/03/19 07:50:35 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:35 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:3053453312+33554432
18/03/19 07:50:35 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:38 INFO Executor: Finished task 91.0 in stage 8.0 (TID 303). 1120 bytes result sent to driver
18/03/19 07:50:38 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:38 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:38 INFO TaskSetManager: Starting task 92.0 in stage 8.0 (TID 304, localhost, executor driver, partition 92, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:50:38 INFO Executor: Running task 92.0 in stage 8.0 (TID 304)
18/03/19 07:50:38 INFO TaskSetManager: Finished task 91.0 in stage 8.0 (TID 303) in 3463 ms on localhost (executor driver) (91/96)
18/03/19 07:50:38 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:38 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:3087007744+33554432
18/03/19 07:50:38 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:38 INFO Executor: Finished task 90.0 in stage 8.0 (TID 302). 1120 bytes result sent to driver
18/03/19 07:50:38 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:38 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:38 INFO TaskSetManager: Starting task 93.0 in stage 8.0 (TID 305, localhost, executor driver, partition 93, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:50:38 INFO TaskSetManager: Finished task 90.0 in stage 8.0 (TID 302) in 3801 ms on localhost (executor driver) (92/96)
18/03/19 07:50:38 INFO Executor: Running task 93.0 in stage 8.0 (TID 305)
18/03/19 07:50:38 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:38 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:3120562176+33554432
18/03/19 07:50:38 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:41 INFO Executor: Finished task 92.0 in stage 8.0 (TID 304). 1120 bytes result sent to driver
18/03/19 07:50:41 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:41 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:41 INFO TaskSetManager: Starting task 94.0 in stage 8.0 (TID 306, localhost, executor driver, partition 94, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:50:41 INFO TaskSetManager: Finished task 92.0 in stage 8.0 (TID 304) in 3111 ms on localhost (executor driver) (93/96)
18/03/19 07:50:41 INFO Executor: Running task 94.0 in stage 8.0 (TID 306)
18/03/19 07:50:41 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:41 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:3154116608+33554432
18/03/19 07:50:41 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:41 INFO Executor: Finished task 93.0 in stage 8.0 (TID 305). 1077 bytes result sent to driver
18/03/19 07:50:41 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:41 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:41 INFO TaskSetManager: Starting task 95.0 in stage 8.0 (TID 307, localhost, executor driver, partition 95, PROCESS_LOCAL, 7863 bytes)
18/03/19 07:50:41 INFO TaskSetManager: Finished task 93.0 in stage 8.0 (TID 305) in 3036 ms on localhost (executor driver) (94/96)
18/03/19 07:50:41 INFO Executor: Running task 95.0 in stage 8.0 (TID 307)
18/03/19 07:50:41 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:41 INFO HadoopRDD: Input split: file:/Data/purchace100m.csv:3187671040+19265026
18/03/19 07:50:41 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:43 INFO Executor: Finished task 95.0 in stage 8.0 (TID 307). 1077 bytes result sent to driver
18/03/19 07:50:43 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:43 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:43 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
18/03/19 07:50:43 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 308, localhost, executor driver, partition 0, PROCESS_LOCAL, 7855 bytes)
18/03/19 07:50:43 INFO Executor: Running task 0.0 in stage 9.0 (TID 308)
18/03/19 07:50:43 INFO TaskSetManager: Finished task 95.0 in stage 8.0 (TID 307) in 1889 ms on localhost (executor driver) (95/96)
18/03/19 07:50:43 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:43 DEBUG BlockManager: Getting local block broadcast_11
18/03/19 07:50:43 TRACE BlockInfoManager: Task 308 trying to acquire read lock for broadcast_11
18/03/19 07:50:43 TRACE BlockInfoManager: Task 308 acquired read lock for broadcast_11
18/03/19 07:50:43 DEBUG BlockManager: Level for block broadcast_11 is StorageLevel(disk, memory, deserialized, 1 replicas)
18/03/19 07:50:43 INFO HadoopRDD: Input split: file:/Data/user.csv:0+33554432
18/03/19 07:50:43 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:44 TRACE BlockInfoManager: Task 308 releasing lock for broadcast_11
18/03/19 07:50:44 INFO Executor: Finished task 0.0 in stage 9.0 (TID 308). 1120 bytes result sent to driver
18/03/19 07:50:44 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:44 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:44 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 309, localhost, executor driver, partition 1, PROCESS_LOCAL, 7855 bytes)
18/03/19 07:50:44 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 308) in 1060 ms on localhost (executor driver) (1/8)
18/03/19 07:50:44 INFO Executor: Running task 1.0 in stage 9.0 (TID 309)
18/03/19 07:50:44 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:44 INFO HadoopRDD: Input split: file:/Data/user.csv:33554432+33554432
18/03/19 07:50:44 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:45 INFO Executor: Finished task 1.0 in stage 9.0 (TID 309). 1120 bytes result sent to driver
18/03/19 07:50:45 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 1
18/03/19 07:50:45 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:45 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 310, localhost, executor driver, partition 2, PROCESS_LOCAL, 7855 bytes)
18/03/19 07:50:45 INFO Executor: Running task 2.0 in stage 9.0 (TID 310)
18/03/19 07:50:45 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 309) in 965 ms on localhost (executor driver) (2/8)
18/03/19 07:50:45 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:45 INFO HadoopRDD: Input split: file:/Data/user.csv:67108864+33554432
18/03/19 07:50:45 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:45 INFO Executor: Finished task 94.0 in stage 8.0 (TID 306). 1120 bytes result sent to driver
18/03/19 07:50:45 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8.0, runningTasks: 0
18/03/19 07:50:45 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 1
18/03/19 07:50:45 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 311, localhost, executor driver, partition 3, PROCESS_LOCAL, 7855 bytes)
18/03/19 07:50:45 INFO TaskSetManager: Finished task 94.0 in stage 8.0 (TID 306) in 4091 ms on localhost (executor driver) (96/96)
18/03/19 07:50:45 INFO Executor: Running task 3.0 in stage 9.0 (TID 311)
18/03/19 07:50:45 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
18/03/19 07:50:45 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:45 INFO DAGScheduler: ShuffleMapStage 8 (map at SBMJ_GB.scala:52) finished in 169.386 s
18/03/19 07:50:45 INFO DAGScheduler: looking for newly runnable stages
18/03/19 07:50:45 INFO HadoopRDD: Input split: file:/Data/user.csv:100663296+33554432
18/03/19 07:50:45 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:46 INFO DAGScheduler: running: Set(ShuffleMapStage 9)
18/03/19 07:50:46 INFO DAGScheduler: waiting: Set(ResultStage 10)
18/03/19 07:50:46 INFO DAGScheduler: failed: Set()
18/03/19 07:50:46 DEBUG MapOutputTrackerMaster: Increasing epoch to 1
18/03/19 07:50:46 TRACE DAGScheduler: Checking if any dependencies of ShuffleMapStage 8 are now runnable
18/03/19 07:50:46 TRACE DAGScheduler: running: Set(ShuffleMapStage 9)
18/03/19 07:50:46 TRACE DAGScheduler: waiting: Set(ResultStage 10)
18/03/19 07:50:46 TRACE DAGScheduler: failed: Set()
18/03/19 07:50:46 DEBUG DAGScheduler: submitStage(ResultStage 10)
18/03/19 07:50:46 DEBUG DAGScheduler: missing: List(ShuffleMapStage 9)
18/03/19 07:50:46 DEBUG DAGScheduler: submitStage(ShuffleMapStage 9)
18/03/19 07:50:46 INFO Executor: Finished task 2.0 in stage 9.0 (TID 310). 1120 bytes result sent to driver
18/03/19 07:50:46 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 1
18/03/19 07:50:46 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 312, localhost, executor driver, partition 4, PROCESS_LOCAL, 7855 bytes)
18/03/19 07:50:46 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 310) in 833 ms on localhost (executor driver) (3/8)
18/03/19 07:50:46 INFO Executor: Running task 4.0 in stage 9.0 (TID 312)
18/03/19 07:50:46 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:46 INFO HadoopRDD: Input split: file:/Data/user.csv:134217728+33554432
18/03/19 07:50:46 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:47 INFO Executor: Finished task 3.0 in stage 9.0 (TID 311). 1120 bytes result sent to driver
18/03/19 07:50:47 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 1
18/03/19 07:50:47 INFO TaskSetManager: Starting task 5.0 in stage 9.0 (TID 313, localhost, executor driver, partition 5, PROCESS_LOCAL, 7855 bytes)
18/03/19 07:50:47 INFO Executor: Running task 5.0 in stage 9.0 (TID 313)
18/03/19 07:50:47 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 311) in 1264 ms on localhost (executor driver) (4/8)
18/03/19 07:50:47 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:47 INFO HadoopRDD: Input split: file:/Data/user.csv:167772160+33554432
18/03/19 07:50:47 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:49 INFO Executor: Finished task 4.0 in stage 9.0 (TID 312). 1077 bytes result sent to driver
18/03/19 07:50:49 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 1
18/03/19 07:50:49 INFO TaskSetManager: Starting task 6.0 in stage 9.0 (TID 314, localhost, executor driver, partition 6, PROCESS_LOCAL, 7855 bytes)
18/03/19 07:50:49 INFO Executor: Running task 6.0 in stage 9.0 (TID 314)
18/03/19 07:50:49 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 312) in 2539 ms on localhost (executor driver) (5/8)
18/03/19 07:50:49 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:49 INFO HadoopRDD: Input split: file:/Data/user.csv:201326592+33554432
18/03/19 07:50:49 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:49 INFO Executor: Finished task 5.0 in stage 9.0 (TID 313). 1120 bytes result sent to driver
18/03/19 07:50:49 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 1
18/03/19 07:50:49 INFO TaskSetManager: Starting task 7.0 in stage 9.0 (TID 315, localhost, executor driver, partition 7, PROCESS_LOCAL, 7855 bytes)
18/03/19 07:50:49 INFO Executor: Running task 7.0 in stage 9.0 (TID 315)
18/03/19 07:50:49 INFO TaskSetManager: Finished task 5.0 in stage 9.0 (TID 313) in 2412 ms on localhost (executor driver) (6/8)
18/03/19 07:50:49 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:49 INFO HadoopRDD: Input split: file:/Data/user.csv:234881024+21712488
18/03/19 07:50:49 DEBUG HadoopRDD: Re-using cached JobConf
18/03/19 07:50:50 INFO Executor: Finished task 7.0 in stage 9.0 (TID 315). 1120 bytes result sent to driver
18/03/19 07:50:50 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 1
18/03/19 07:50:50 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
18/03/19 07:50:50 INFO TaskSetManager: Finished task 7.0 in stage 9.0 (TID 315) in 877 ms on localhost (executor driver) (7/8)
18/03/19 07:50:50 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:50 INFO Executor: Finished task 6.0 in stage 9.0 (TID 314). 1120 bytes result sent to driver
18/03/19 07:50:50 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9.0, runningTasks: 0
18/03/19 07:50:50 INFO TaskSetManager: Finished task 6.0 in stage 9.0 (TID 314) in 1715 ms on localhost (executor driver) (8/8)
18/03/19 07:50:50 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
18/03/19 07:50:50 DEBUG DAGScheduler: ShuffleMapTask finished on driver
18/03/19 07:50:50 INFO DAGScheduler: ShuffleMapStage 9 (map at SBMJ_GB.scala:33) finished in 174.418 s
18/03/19 07:50:50 INFO DAGScheduler: looking for newly runnable stages
18/03/19 07:50:50 INFO DAGScheduler: running: Set()
18/03/19 07:50:50 INFO DAGScheduler: waiting: Set(ResultStage 10)
18/03/19 07:50:50 INFO DAGScheduler: failed: Set()
18/03/19 07:50:50 DEBUG MapOutputTrackerMaster: Increasing epoch to 2
18/03/19 07:50:50 TRACE DAGScheduler: Checking if any dependencies of ShuffleMapStage 9 are now runnable
18/03/19 07:50:50 TRACE DAGScheduler: running: Set()
18/03/19 07:50:50 TRACE DAGScheduler: waiting: Set(ResultStage 10)
18/03/19 07:50:50 TRACE DAGScheduler: failed: Set()
18/03/19 07:50:50 DEBUG DAGScheduler: submitStage(ResultStage 10)
18/03/19 07:50:50 DEBUG DAGScheduler: missing: List()
18/03/19 07:50:50 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[16] at mapValues at SBMJ_GB.scala:57), which has no missing parents
18/03/19 07:50:50 DEBUG DAGScheduler: submitMissingTasks(ResultStage 10)
18/03/19 07:50:50 TRACE BlockInfoManager: Task -1024 trying to put broadcast_12
18/03/19 07:50:50 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_12
18/03/19 07:50:50 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_12
18/03/19 07:50:50 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_12
18/03/19 07:50:50 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 4.6 KB, free 852.1 MB)
18/03/19 07:50:50 DEBUG BlockManager: Put block broadcast_12 locally took  1 ms
18/03/19 07:50:50 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_12
18/03/19 07:50:50 DEBUG BlockManager: Putting block broadcast_12 without replication took  1 ms
18/03/19 07:50:50 TRACE BlockInfoManager: Task -1024 trying to put broadcast_12_piece0
18/03/19 07:50:50 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_12_piece0
18/03/19 07:50:50 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_12_piece0
18/03/19 07:50:50 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_12_piece0
18/03/19 07:50:50 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.3 KB, free 852.1 MB)
18/03/19 07:50:50 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 192.168.8.100:40919 (size: 2.3 KB, free: 852.6 MB)
18/03/19 07:50:50 DEBUG BlockManagerMaster: Updated info of block broadcast_12_piece0
18/03/19 07:50:50 DEBUG BlockManager: Told master about block broadcast_12_piece0
18/03/19 07:50:50 DEBUG BlockManager: Put block broadcast_12_piece0 locally took  1 ms
18/03/19 07:50:50 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_12_piece0
18/03/19 07:50:50 DEBUG BlockManager: Putting block broadcast_12_piece0 without replication took  1 ms
18/03/19 07:50:50 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1039
18/03/19 07:50:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[16] at mapValues at SBMJ_GB.scala:57) (first 15 tasks are for partitions Vector(0))
18/03/19 07:50:50 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
18/03/19 07:50:50 DEBUG TaskSetManager: Epoch for TaskSet 10.0: 2
18/03/19 07:50:50 DEBUG TaskSetManager: Valid locality levels for TaskSet 10.0: NO_PREF, ANY
18/03/19 07:50:50 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_10.0, runningTasks: 0
18/03/19 07:50:50 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 316, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:50:50 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
18/03/19 07:50:50 INFO Executor: Running task 0.0 in stage 10.0 (TID 316)
18/03/19 07:50:50 DEBUG BlockManager: Getting local block broadcast_12
18/03/19 07:50:50 TRACE BlockInfoManager: Task 316 trying to acquire read lock for broadcast_12
18/03/19 07:50:50 TRACE BlockInfoManager: Task 316 acquired read lock for broadcast_12
18/03/19 07:50:50 DEBUG BlockManager: Level for block broadcast_12 is StorageLevel(disk, memory, deserialized, 1 replicas)
18/03/19 07:50:51 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 0-1
18/03/19 07:50:51 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:50:51 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:50:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
18/03/19 07:50:51 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  669 ms
18/03/19 07:50:51 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 0-1
18/03/19 07:50:51 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:50:51 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:50:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:50:51 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:50:52 DEBUG TaskMemoryManager: Task 316 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2f725ed5
18/03/19 07:50:53 DEBUG TaskMemoryManager: Task 316 acquired 10.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2f725ed5
18/03/19 07:50:54 DEBUG TaskMemoryManager: Task 316 acquired 20.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2f725ed5
18/03/19 07:50:56 DEBUG TaskMemoryManager: Task 316 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3e96cf23
18/03/19 07:50:56 DEBUG TaskMemoryManager: Task 316 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3e96cf23
18/03/19 07:50:56 DEBUG TaskMemoryManager: Task 316 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3e96cf23
18/03/19 07:50:57 DEBUG TaskMemoryManager: Task 316 acquired 44.8 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3e96cf23
18/03/19 07:50:57 DEBUG TaskMemoryManager: Task 316 release 35.7 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2f725ed5
18/03/19 07:50:57 TRACE BlockInfoManager: Task 316 releasing lock for broadcast_12
18/03/19 07:50:57 DEBUG TaskMemoryManager: unreleased 79.9 MB memory from org.apache.spark.util.collection.ExternalAppendOnlyMap@3e96cf23
18/03/19 07:50:57 WARN Executor: Managed memory leak detected; size = 83757810 bytes, TID = 316
18/03/19 07:50:57 INFO Executor: Finished task 0.0 in stage 10.0 (TID 316). 1778 bytes result sent to driver
18/03/19 07:50:57 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_10.0, runningTasks: 0
18/03/19 07:50:57 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 316) in 6363 ms on localhost (executor driver) (1/1)
18/03/19 07:50:57 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
18/03/19 07:50:57 INFO DAGScheduler: ResultStage 10 (take at SBMJ_GB.scala:66) finished in 6.369 s
18/03/19 07:50:57 DEBUG DAGScheduler: After removal of stage 8, remaining stages = 2
18/03/19 07:50:57 DEBUG DAGScheduler: After removal of stage 10, remaining stages = 1
18/03/19 07:50:57 DEBUG DAGScheduler: After removal of stage 9, remaining stages = 0
18/03/19 07:50:57 INFO DAGScheduler: Job 8 finished: take at SBMJ_GB.scala:66, took 180.885810 s
18/03/19 07:50:57 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
(81801,(814353,Noble Beer))
(641553,(989148,Zella Lueilwitz))
(705936,(789129,Loraine Rice))
(901428,(777181,Guillermo Zieme))
(254463,(785378,Xander McGlynn))
(828828,(604897,Ashley Terry))
(912318,(705226,Marcellus Nader))
(730620,(903717,Amy Mayert))
(833811,(925684,Katarina Thompson))
(617529,(914910,Easter Jacobs))
18/03/19 07:50:57 DEBUG ClosureCleaner:  + declared fields: 1
18/03/19 07:50:57 DEBUG ClosureCleaner:      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
18/03/19 07:50:57 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:50:57 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
18/03/19 07:50:57 DEBUG ClosureCleaner:      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
18/03/19 07:50:57 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:50:57 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:50:57 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:50:57 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:50:57 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:50:57 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:50:57 DEBUG ClosureCleaner:  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
18/03/19 07:50:57 DEBUG ClosureCleaner: +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
18/03/19 07:50:57 DEBUG ClosureCleaner:  + declared fields: 2
18/03/19 07:50:57 DEBUG ClosureCleaner:      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
18/03/19 07:50:57 DEBUG ClosureCleaner:      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
18/03/19 07:50:57 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:50:57 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
18/03/19 07:50:57 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
18/03/19 07:50:57 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:50:57 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:50:57 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:50:57 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:50:57 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:50:57 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:50:57 DEBUG ClosureCleaner:  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
18/03/19 07:50:57 INFO SparkContext: Starting job: count at SBMJ_GB.scala:67
18/03/19 07:50:57 INFO DAGScheduler: Got job 9 (count at SBMJ_GB.scala:67) with 96 output partitions
18/03/19 07:50:57 INFO DAGScheduler: Final stage: ResultStage 13 (count at SBMJ_GB.scala:67)
18/03/19 07:50:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12, ShuffleMapStage 11)
18/03/19 07:50:57 INFO DAGScheduler: Missing parents: List()
18/03/19 07:50:57 DEBUG DAGScheduler: submitStage(ResultStage 13)
18/03/19 07:50:57 DEBUG DAGScheduler: missing: List()
18/03/19 07:50:57 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[16] at mapValues at SBMJ_GB.scala:57), which has no missing parents
18/03/19 07:50:57 DEBUG DAGScheduler: submitMissingTasks(ResultStage 13)
18/03/19 07:50:57 TRACE BlockInfoManager: Task -1024 trying to put broadcast_13
18/03/19 07:50:57 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_13
18/03/19 07:50:57 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_13
18/03/19 07:50:57 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_13
18/03/19 07:50:57 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 4.4 KB, free 852.1 MB)
18/03/19 07:50:57 DEBUG BlockManager: Put block broadcast_13 locally took  1 ms
18/03/19 07:50:57 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_13
18/03/19 07:50:57 DEBUG BlockManager: Putting block broadcast_13 without replication took  1 ms
18/03/19 07:50:57 TRACE BlockInfoManager: Task -1024 trying to put broadcast_13_piece0
18/03/19 07:50:57 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_13_piece0
18/03/19 07:50:57 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_13_piece0
18/03/19 07:50:57 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_13_piece0
18/03/19 07:50:57 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.2 KB, free 852.1 MB)
18/03/19 07:50:57 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 192.168.8.100:40919 (size: 2.2 KB, free: 852.6 MB)
18/03/19 07:50:57 DEBUG BlockManagerMaster: Updated info of block broadcast_13_piece0
18/03/19 07:50:57 DEBUG BlockManager: Told master about block broadcast_13_piece0
18/03/19 07:50:57 DEBUG BlockManager: Put block broadcast_13_piece0 locally took  2 ms
18/03/19 07:50:57 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_13_piece0
18/03/19 07:50:57 DEBUG BlockManager: Putting block broadcast_13_piece0 without replication took  2 ms
18/03/19 07:50:57 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1039
18/03/19 07:50:57 INFO DAGScheduler: Submitting 96 missing tasks from ResultStage 13 (MapPartitionsRDD[16] at mapValues at SBMJ_GB.scala:57) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
18/03/19 07:50:57 INFO TaskSchedulerImpl: Adding task set 13.0 with 96 tasks
18/03/19 07:50:57 DEBUG TaskSetManager: Epoch for TaskSet 13.0: 2
18/03/19 07:50:57 DEBUG TaskSetManager: Valid locality levels for TaskSet 13.0: NO_PREF, ANY
18/03/19 07:50:57 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 0
18/03/19 07:50:57 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 317, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:50:57 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 318, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:50:57 INFO Executor: Running task 0.0 in stage 13.0 (TID 317)
18/03/19 07:50:57 INFO Executor: Running task 1.0 in stage 13.0 (TID 318)
18/03/19 07:50:57 DEBUG BlockManager: Getting local block broadcast_13
18/03/19 07:50:57 TRACE BlockInfoManager: Task 317 trying to acquire read lock for broadcast_13
18/03/19 07:50:57 TRACE BlockInfoManager: Task 317 acquired read lock for broadcast_13
18/03/19 07:50:57 DEBUG BlockManager: Level for block broadcast_13 is StorageLevel(disk, memory, deserialized, 1 replicas)
18/03/19 07:50:57 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 1-2
18/03/19 07:50:57 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 0-1
18/03/19 07:50:57 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:50:57 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:50:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:50:57 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:50:57 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:50:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:50:57 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  11 ms
18/03/19 07:50:57 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 0-1
18/03/19 07:50:57 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:50:57 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:50:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:50:57 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:50:57 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  17 ms
18/03/19 07:50:57 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 1-2
18/03/19 07:50:57 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:50:57 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:50:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
18/03/19 07:50:57 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  12 ms
18/03/19 07:50:57 DEBUG TaskMemoryManager: Task 317 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@51b2f634
18/03/19 07:50:57 DEBUG TaskMemoryManager: Task 318 acquired 5.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7ea92fda
18/03/19 07:50:58 DEBUG TaskMemoryManager: Task 317 acquired 10.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@51b2f634
18/03/19 07:50:58 DEBUG TaskMemoryManager: Task 318 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7ea92fda
18/03/19 07:50:58 DEBUG TaskMemoryManager: Task 317 acquired 20.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@51b2f634
18/03/19 07:50:59 DEBUG TaskMemoryManager: Task 318 acquired 20.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7ea92fda
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(12)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning broadcast 12
18/03/19 07:50:59 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 12
18/03/19 07:50:59 DEBUG BlockManagerSlaveEndpoint: removing broadcast 12
18/03/19 07:50:59 DEBUG BlockManager: Removing broadcast 12
18/03/19 07:50:59 DEBUG BlockManager: Removing block broadcast_12_piece0
18/03/19 07:50:59 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_12_piece0
18/03/19 07:50:59 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_12_piece0
18/03/19 07:50:59 DEBUG MemoryStore: Block broadcast_12_piece0 of size 2353 dropped from memory (free 818969685)
18/03/19 07:50:59 TRACE BlockInfoManager: Task -1024 trying to remove block broadcast_12_piece0
18/03/19 07:50:59 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 192.168.8.100:40919 in memory (size: 2.3 KB, free: 852.6 MB)
18/03/19 07:50:59 DEBUG BlockManagerMaster: Updated info of block broadcast_12_piece0
18/03/19 07:50:59 DEBUG BlockManager: Told master about block broadcast_12_piece0
18/03/19 07:50:59 DEBUG BlockManager: Removing block broadcast_12
18/03/19 07:50:59 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_12
18/03/19 07:50:59 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_12
18/03/19 07:50:59 DEBUG MemoryStore: Block broadcast_12 of size 4680 dropped from memory (free 818974365)
18/03/19 07:50:59 TRACE BlockInfoManager: Task -1024 trying to remove block broadcast_12
18/03/19 07:50:59 DEBUG BlockManagerSlaveEndpoint: Done removing broadcast 12, response is 0
18/03/19 07:50:59 DEBUG BlockManagerSlaveEndpoint: Sent response: 0 to 192.168.8.100:45639
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaned broadcast 12
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(226)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 226
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 226
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(260)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 260
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 260
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(221)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 221
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 221
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(252)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 252
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 252
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(222)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 222
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 222
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(264)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 264
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 264
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(210)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 210
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 210
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(213)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 213
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 213
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(273)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 273
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 273
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(236)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 236
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 236
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(274)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 274
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 274
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(244)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 244
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 244
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(217)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 217
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 217
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(254)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 254
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 254
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(209)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 209
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 209
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(268)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 268
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 268
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(250)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 250
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 250
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(231)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 231
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 231
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(230)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 230
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 230
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(219)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 219
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 219
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(245)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 245
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 245
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(206)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 206
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 206
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(243)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 243
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 243
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(240)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 240
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 240
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(234)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 234
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 234
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(215)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 215
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 215
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(249)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 249
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 249
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(228)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 228
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 228
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(253)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 253
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 253
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(211)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 211
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 211
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(224)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 224
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 224
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(256)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 256
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 256
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(246)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 246
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 246
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(266)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 266
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 266
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(237)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 237
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 237
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(227)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 227
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 227
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(235)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 235
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 235
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(232)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 232
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 232
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(220)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 220
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 220
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(255)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 255
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 255
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(267)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 267
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 267
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(261)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 261
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 261
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(258)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 258
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 258
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(263)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 263
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 263
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(208)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 208
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 208
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(216)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 216
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 216
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(271)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 271
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 271
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(202)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 202
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 202
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(218)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 218
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 218
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(272)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 272
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 272
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(242)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 242
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 242
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(270)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 270
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 270
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(238)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 238
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 238
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(201)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 201
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 201
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(269)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 269
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 269
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(248)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 248
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 248
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(233)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 233
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 233
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(229)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 229
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 229
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(259)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 259
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 259
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(241)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 241
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 241
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(225)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 225
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 225
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(214)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 214
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 214
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanAccum(204)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning accumulator 204
18/03/19 07:50:59 INFO ContextCleaner: Cleaned accumulator 204
18/03/19 07:50:59 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(11)
18/03/19 07:50:59 DEBUG ContextCleaner: Cleaning broadcast 11
18/03/19 07:50:59 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 11
18/03/19 07:50:59 DEBUG BlockManagerSlaveEndpoint: removing broadcast 11
18/03/19 07:50:59 DEBUG BlockManager: Removing broadcast 11
18/03/19 07:50:59 DEBUG BlockManager: Removing block broadcast_11
18/03/19 07:50:59 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_11
18/03/19 07:50:59 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_11
18/03/19 07:50:59 DEBUG MemoryStore: Block broadcast_11 of size 4608 dropped from memory (free 818978973)
18/03/19 07:50:59 TRACE BlockInfoManager: Task -1024 trying to remove block broadcast_11
18/03/19 07:50:59 DEBUG BlockManager: Removing block broadcast_11_piece0
18/03/19 07:50:59 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_11_piece0
18/03/19 07:50:59 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_11_piece0
18/03/19 07:50:59 DEBUG MemoryStore: Block broadcast_11_piece0 of size 2579 dropped from memory (free 818981552)
18/03/19 07:50:59 TRACE BlockInfoManager: Task -1024 trying to remove block broadcast_11_piece0
18/03/19 07:50:59 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 192.168.8.100:40919 in memory (size: 2.5 KB, free: 852.6 MB)
18/03/19 07:50:59 DEBUG BlockManagerMaster: Updated info of block broadcast_11_piece0
18/03/19 07:50:59 DEBUG BlockManager: Told master about block broadcast_11_piece0
18/03/19 07:50:59 DEBUG BlockManagerSlaveEndpoint: Done removing broadcast 11, response is 0
18/03/19 07:50:59 DEBUG BlockManagerSlaveEndpoint: Sent response: 0 to 192.168.8.100:45639
18/03/19 07:51:00 DEBUG ContextCleaner: Cleaned broadcast 11
18/03/19 07:51:00 DEBUG ContextCleaner: Got cleaning task CleanAccum(203)
18/03/19 07:51:00 DEBUG ContextCleaner: Cleaning accumulator 203
18/03/19 07:51:00 INFO ContextCleaner: Cleaned accumulator 203
18/03/19 07:51:00 DEBUG ContextCleaner: Got cleaning task CleanAccum(262)
18/03/19 07:51:00 DEBUG ContextCleaner: Cleaning accumulator 262
18/03/19 07:51:00 INFO ContextCleaner: Cleaned accumulator 262
18/03/19 07:51:00 DEBUG ContextCleaner: Got cleaning task CleanAccum(257)
18/03/19 07:51:00 DEBUG ContextCleaner: Cleaning accumulator 257
18/03/19 07:51:00 INFO ContextCleaner: Cleaned accumulator 257
18/03/19 07:51:00 DEBUG ContextCleaner: Got cleaning task CleanAccum(265)
18/03/19 07:51:00 DEBUG ContextCleaner: Cleaning accumulator 265
18/03/19 07:51:00 INFO ContextCleaner: Cleaned accumulator 265
18/03/19 07:51:00 DEBUG ContextCleaner: Got cleaning task CleanAccum(200)
18/03/19 07:51:00 DEBUG ContextCleaner: Cleaning accumulator 200
18/03/19 07:51:00 INFO ContextCleaner: Cleaned accumulator 200
18/03/19 07:51:00 DEBUG ContextCleaner: Got cleaning task CleanAccum(239)
18/03/19 07:51:00 DEBUG ContextCleaner: Cleaning accumulator 239
18/03/19 07:51:00 INFO ContextCleaner: Cleaned accumulator 239
18/03/19 07:51:00 DEBUG ContextCleaner: Got cleaning task CleanAccum(212)
18/03/19 07:51:00 DEBUG ContextCleaner: Cleaning accumulator 212
18/03/19 07:51:00 INFO ContextCleaner: Cleaned accumulator 212
18/03/19 07:51:00 DEBUG ContextCleaner: Got cleaning task CleanAccum(207)
18/03/19 07:51:00 DEBUG ContextCleaner: Cleaning accumulator 207
18/03/19 07:51:00 INFO ContextCleaner: Cleaned accumulator 207
18/03/19 07:51:00 DEBUG ContextCleaner: Got cleaning task CleanAccum(251)
18/03/19 07:51:00 DEBUG ContextCleaner: Cleaning accumulator 251
18/03/19 07:51:00 INFO ContextCleaner: Cleaned accumulator 251
18/03/19 07:51:00 DEBUG ContextCleaner: Got cleaning task CleanAccum(223)
18/03/19 07:51:00 DEBUG ContextCleaner: Cleaning accumulator 223
18/03/19 07:51:00 INFO ContextCleaner: Cleaned accumulator 223
18/03/19 07:51:00 DEBUG ContextCleaner: Got cleaning task CleanAccum(247)
18/03/19 07:51:00 DEBUG ContextCleaner: Cleaning accumulator 247
18/03/19 07:51:00 INFO ContextCleaner: Cleaned accumulator 247
18/03/19 07:51:00 DEBUG ContextCleaner: Got cleaning task CleanAccum(205)
18/03/19 07:51:00 DEBUG ContextCleaner: Cleaning accumulator 205
18/03/19 07:51:00 INFO ContextCleaner: Cleaned accumulator 205
18/03/19 07:51:00 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(10)
18/03/19 07:51:00 DEBUG ContextCleaner: Cleaning broadcast 10
18/03/19 07:51:00 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 10
18/03/19 07:51:00 DEBUG BlockManagerSlaveEndpoint: removing broadcast 10
18/03/19 07:51:00 DEBUG BlockManager: Removing broadcast 10
18/03/19 07:51:00 DEBUG BlockManager: Removing block broadcast_10
18/03/19 07:51:00 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_10
18/03/19 07:51:00 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_10
18/03/19 07:51:00 DEBUG MemoryStore: Block broadcast_10 of size 4616 dropped from memory (free 818986168)
18/03/19 07:51:00 TRACE BlockInfoManager: Task -1024 trying to remove block broadcast_10
18/03/19 07:51:00 DEBUG BlockManager: Removing block broadcast_10_piece0
18/03/19 07:51:00 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_10_piece0
18/03/19 07:51:00 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_10_piece0
18/03/19 07:51:00 DEBUG MemoryStore: Block broadcast_10_piece0 of size 2556 dropped from memory (free 818988724)
18/03/19 07:51:00 TRACE BlockInfoManager: Task -1024 trying to remove block broadcast_10_piece0
18/03/19 07:51:00 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 192.168.8.100:40919 in memory (size: 2.5 KB, free: 852.6 MB)
18/03/19 07:51:00 DEBUG BlockManagerMaster: Updated info of block broadcast_10_piece0
18/03/19 07:51:00 DEBUG BlockManager: Told master about block broadcast_10_piece0
18/03/19 07:51:00 DEBUG BlockManagerSlaveEndpoint: Done removing broadcast 10, response is 0
18/03/19 07:51:00 DEBUG BlockManagerSlaveEndpoint: Sent response: 0 to 192.168.8.100:45639
18/03/19 07:51:00 DEBUG ContextCleaner: Cleaned broadcast 10
18/03/19 07:51:01 DEBUG TaskMemoryManager: Task 317 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@68f322c3
18/03/19 07:51:01 DEBUG TaskMemoryManager: Task 317 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@68f322c3
18/03/19 07:51:01 DEBUG TaskMemoryManager: Task 318 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@14fea7ff
18/03/19 07:51:01 DEBUG TaskMemoryManager: Task 317 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@68f322c3
18/03/19 07:51:01 DEBUG TaskMemoryManager: Task 318 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@14fea7ff
18/03/19 07:51:02 DEBUG TaskMemoryManager: Task 318 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@14fea7ff
18/03/19 07:51:02 DEBUG TaskMemoryManager: Task 317 acquired 44.8 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@68f322c3
18/03/19 07:51:02 DEBUG TaskMemoryManager: Task 317 release 35.7 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@51b2f634
18/03/19 07:51:02 DEBUG TaskMemoryManager: Task 317 release 79.9 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@68f322c3
18/03/19 07:51:02 TRACE BlockInfoManager: Task 317 releasing lock for broadcast_13
18/03/19 07:51:02 INFO Executor: Finished task 0.0 in stage 13.0 (TID 317). 1219 bytes result sent to driver
18/03/19 07:51:02 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:02 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 319, localhost, executor driver, partition 2, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:02 INFO Executor: Running task 2.0 in stage 13.0 (TID 319)
18/03/19 07:51:02 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 317) in 5252 ms on localhost (executor driver) (1/96)
18/03/19 07:51:02 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 2-3
18/03/19 07:51:02 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:02 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:02 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  7 ms
18/03/19 07:51:02 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 2-3
18/03/19 07:51:02 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:02 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:02 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:51:02 DEBUG TaskMemoryManager: Task 318 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@14fea7ff
18/03/19 07:51:02 DEBUG TaskMemoryManager: Task 318 release 35.4 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@7ea92fda
18/03/19 07:51:02 DEBUG TaskMemoryManager: Task 318 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@14fea7ff
18/03/19 07:51:02 INFO Executor: Finished task 1.0 in stage 13.0 (TID 318). 1219 bytes result sent to driver
18/03/19 07:51:02 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:02 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 320, localhost, executor driver, partition 3, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:02 INFO Executor: Running task 3.0 in stage 13.0 (TID 320)
18/03/19 07:51:02 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 318) in 5493 ms on localhost (executor driver) (2/96)
18/03/19 07:51:02 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 3-4
18/03/19 07:51:02 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:02 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:51:02 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  8 ms
18/03/19 07:51:02 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 3-4
18/03/19 07:51:02 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:02 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:02 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:51:02 DEBUG TaskMemoryManager: Task 319 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2deb3440
18/03/19 07:51:03 DEBUG TaskMemoryManager: Task 320 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3b41bbf6
18/03/19 07:51:03 DEBUG TaskMemoryManager: Task 319 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2deb3440
18/03/19 07:51:03 DEBUG TaskMemoryManager: Task 319 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2deb3440
18/03/19 07:51:04 DEBUG TaskMemoryManager: Task 320 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3b41bbf6
18/03/19 07:51:05 DEBUG TaskMemoryManager: Task 320 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3b41bbf6
18/03/19 07:51:05 DEBUG TaskMemoryManager: Task 319 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5fd9e0
18/03/19 07:51:05 DEBUG TaskMemoryManager: Task 319 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5fd9e0
18/03/19 07:51:06 DEBUG TaskMemoryManager: Task 319 acquired 25.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5fd9e0
18/03/19 07:51:06 DEBUG TaskMemoryManager: Task 320 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2781647c
18/03/19 07:51:06 DEBUG TaskMemoryManager: Task 319 acquired 45.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5fd9e0
18/03/19 07:51:06 DEBUG TaskMemoryManager: Task 320 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2781647c
18/03/19 07:51:06 DEBUG TaskMemoryManager: Task 319 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2deb3440
18/03/19 07:51:06 DEBUG TaskMemoryManager: Task 319 release 85.8 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5fd9e0
18/03/19 07:51:06 INFO Executor: Finished task 2.0 in stage 13.0 (TID 319). 1219 bytes result sent to driver
18/03/19 07:51:06 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:06 INFO TaskSetManager: Starting task 4.0 in stage 13.0 (TID 321, localhost, executor driver, partition 4, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:06 INFO Executor: Running task 4.0 in stage 13.0 (TID 321)
18/03/19 07:51:06 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 319) in 4089 ms on localhost (executor driver) (3/96)
18/03/19 07:51:06 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 4-5
18/03/19 07:51:06 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:06 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:06 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  5 ms
18/03/19 07:51:06 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 4-5
18/03/19 07:51:06 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:06 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:06 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:51:06 DEBUG TaskMemoryManager: Task 320 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2781647c
18/03/19 07:51:07 DEBUG TaskMemoryManager: Task 321 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@680bf59d
18/03/19 07:51:07 DEBUG TaskMemoryManager: Task 320 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2781647c
18/03/19 07:51:07 DEBUG TaskMemoryManager: Task 320 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3b41bbf6
18/03/19 07:51:07 DEBUG TaskMemoryManager: Task 320 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2781647c
18/03/19 07:51:07 INFO Executor: Finished task 3.0 in stage 13.0 (TID 320). 1219 bytes result sent to driver
18/03/19 07:51:07 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:07 INFO TaskSetManager: Starting task 5.0 in stage 13.0 (TID 322, localhost, executor driver, partition 5, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:07 INFO Executor: Running task 5.0 in stage 13.0 (TID 322)
18/03/19 07:51:07 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 320) in 4542 ms on localhost (executor driver) (4/96)
18/03/19 07:51:07 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 5-6
18/03/19 07:51:07 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:07 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:07 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  5 ms
18/03/19 07:51:07 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 5-6
18/03/19 07:51:07 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:07 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:07 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:51:07 DEBUG TaskMemoryManager: Task 321 acquired 10.9 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@680bf59d
18/03/19 07:51:07 DEBUG TaskMemoryManager: Task 322 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@49fd24c2
18/03/19 07:51:08 DEBUG TaskMemoryManager: Task 322 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@49fd24c2
18/03/19 07:51:09 DEBUG TaskMemoryManager: Task 321 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@357fbee4
18/03/19 07:51:09 DEBUG TaskMemoryManager: Task 321 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@357fbee4
18/03/19 07:51:09 DEBUG TaskMemoryManager: Task 321 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@357fbee4
18/03/19 07:51:09 DEBUG TaskMemoryManager: Task 321 release 15.9 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@680bf59d
18/03/19 07:51:09 DEBUG TaskMemoryManager: Task 321 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@357fbee4
18/03/19 07:51:09 INFO Executor: Finished task 4.0 in stage 13.0 (TID 321). 1176 bytes result sent to driver
18/03/19 07:51:09 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:09 INFO TaskSetManager: Starting task 6.0 in stage 13.0 (TID 323, localhost, executor driver, partition 6, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:09 INFO Executor: Running task 6.0 in stage 13.0 (TID 323)
18/03/19 07:51:09 INFO TaskSetManager: Finished task 4.0 in stage 13.0 (TID 321) in 3113 ms on localhost (executor driver) (5/96)
18/03/19 07:51:09 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 6-7
18/03/19 07:51:09 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:09 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:51:09 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  5 ms
18/03/19 07:51:09 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 6-7
18/03/19 07:51:09 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:09 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:51:09 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:51:09 DEBUG TaskMemoryManager: Task 322 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@648d3092
18/03/19 07:51:10 DEBUG TaskMemoryManager: Task 322 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@648d3092
18/03/19 07:51:10 DEBUG TaskMemoryManager: Task 323 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7b73625a
18/03/19 07:51:10 DEBUG TaskMemoryManager: Task 322 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@648d3092
18/03/19 07:51:10 DEBUG TaskMemoryManager: Task 323 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7b73625a
18/03/19 07:51:10 DEBUG TaskMemoryManager: Task 322 release 15.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@49fd24c2
18/03/19 07:51:10 DEBUG TaskMemoryManager: Task 322 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@648d3092
18/03/19 07:51:10 INFO Executor: Finished task 5.0 in stage 13.0 (TID 322). 1219 bytes result sent to driver
18/03/19 07:51:10 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:10 INFO TaskSetManager: Starting task 7.0 in stage 13.0 (TID 324, localhost, executor driver, partition 7, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:10 INFO Executor: Running task 7.0 in stage 13.0 (TID 324)
18/03/19 07:51:10 INFO TaskSetManager: Finished task 5.0 in stage 13.0 (TID 322) in 3168 ms on localhost (executor driver) (6/96)
18/03/19 07:51:10 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 7-8
18/03/19 07:51:10 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:10 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:10 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  9 ms
18/03/19 07:51:10 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 7-8
18/03/19 07:51:10 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:10 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:51:10 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:51:11 DEBUG TaskMemoryManager: Task 324 acquired 5.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@399b6488
18/03/19 07:51:11 DEBUG TaskMemoryManager: Task 323 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7b73625a
18/03/19 07:51:11 DEBUG TaskMemoryManager: Task 324 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@399b6488
18/03/19 07:51:12 DEBUG TaskMemoryManager: Task 323 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@593c9a47
18/03/19 07:51:12 DEBUG TaskMemoryManager: Task 323 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@593c9a47
18/03/19 07:51:13 DEBUG TaskMemoryManager: Task 323 acquired 21.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@593c9a47
18/03/19 07:51:13 DEBUG TaskMemoryManager: Task 324 acquired 5.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@53ed7336
18/03/19 07:51:13 DEBUG TaskMemoryManager: Task 323 acquired 41.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@593c9a47
18/03/19 07:51:13 DEBUG TaskMemoryManager: Task 323 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@7b73625a
18/03/19 07:51:13 DEBUG TaskMemoryManager: Task 324 acquired 10.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@53ed7336
18/03/19 07:51:13 DEBUG TaskMemoryManager: Task 323 release 77.8 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@593c9a47
18/03/19 07:51:13 INFO Executor: Finished task 6.0 in stage 13.0 (TID 323). 1176 bytes result sent to driver
18/03/19 07:51:13 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:13 INFO TaskSetManager: Starting task 8.0 in stage 13.0 (TID 325, localhost, executor driver, partition 8, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:13 INFO Executor: Running task 8.0 in stage 13.0 (TID 325)
18/03/19 07:51:13 INFO TaskSetManager: Finished task 6.0 in stage 13.0 (TID 323) in 3611 ms on localhost (executor driver) (7/96)
18/03/19 07:51:13 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 8-9
18/03/19 07:51:13 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:13 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:51:13 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  3 ms
18/03/19 07:51:13 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 8-9
18/03/19 07:51:13 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:13 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:13 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:51:13 DEBUG TaskMemoryManager: Task 324 acquired 20.9 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@53ed7336
18/03/19 07:51:13 DEBUG TaskMemoryManager: Task 325 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@61eb1cd5
18/03/19 07:51:13 DEBUG TaskMemoryManager: Task 324 release 15.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@399b6488
18/03/19 07:51:13 DEBUG TaskMemoryManager: Task 324 release 36.8 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@53ed7336
18/03/19 07:51:13 INFO Executor: Finished task 7.0 in stage 13.0 (TID 324). 1219 bytes result sent to driver
18/03/19 07:51:13 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:13 INFO TaskSetManager: Starting task 9.0 in stage 13.0 (TID 326, localhost, executor driver, partition 9, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:13 INFO Executor: Running task 9.0 in stage 13.0 (TID 326)
18/03/19 07:51:13 INFO TaskSetManager: Finished task 7.0 in stage 13.0 (TID 324) in 3378 ms on localhost (executor driver) (8/96)
18/03/19 07:51:13 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 9-10
18/03/19 07:51:13 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:13 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:51:13 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:51:13 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 9-10
18/03/19 07:51:13 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:13 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:13 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:51:14 DEBUG TaskMemoryManager: Task 326 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2f233e3b
18/03/19 07:51:14 DEBUG TaskMemoryManager: Task 325 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@61eb1cd5
18/03/19 07:51:14 DEBUG TaskMemoryManager: Task 326 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2f233e3b
18/03/19 07:51:15 DEBUG TaskMemoryManager: Task 325 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@94f1c33
18/03/19 07:51:15 DEBUG TaskMemoryManager: Task 325 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@94f1c33
18/03/19 07:51:15 DEBUG TaskMemoryManager: Task 326 acquired 5.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@45e0fc3d
18/03/19 07:51:15 DEBUG TaskMemoryManager: Task 325 acquired 21.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@94f1c33
18/03/19 07:51:15 DEBUG TaskMemoryManager: Task 326 acquired 10.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@45e0fc3d
18/03/19 07:51:16 DEBUG TaskMemoryManager: Task 325 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@61eb1cd5
18/03/19 07:51:16 DEBUG TaskMemoryManager: Task 325 release 36.5 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@94f1c33
18/03/19 07:51:16 INFO Executor: Finished task 8.0 in stage 13.0 (TID 325). 1176 bytes result sent to driver
18/03/19 07:51:16 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:16 INFO TaskSetManager: Starting task 10.0 in stage 13.0 (TID 327, localhost, executor driver, partition 10, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:16 INFO TaskSetManager: Finished task 8.0 in stage 13.0 (TID 325) in 2606 ms on localhost (executor driver) (9/96)
18/03/19 07:51:16 INFO Executor: Running task 10.0 in stage 13.0 (TID 327)
18/03/19 07:51:16 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 10-11
18/03/19 07:51:16 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:16 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:16 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  3 ms
18/03/19 07:51:16 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 10-11
18/03/19 07:51:16 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:16 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:16 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:51:16 DEBUG TaskMemoryManager: Task 326 acquired 21.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@45e0fc3d
18/03/19 07:51:16 DEBUG TaskMemoryManager: Task 326 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2f233e3b
18/03/19 07:51:16 DEBUG TaskMemoryManager: Task 326 release 36.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@45e0fc3d
18/03/19 07:51:16 INFO Executor: Finished task 9.0 in stage 13.0 (TID 326). 1176 bytes result sent to driver
18/03/19 07:51:16 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:16 INFO TaskSetManager: Starting task 11.0 in stage 13.0 (TID 328, localhost, executor driver, partition 11, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:16 INFO Executor: Running task 11.0 in stage 13.0 (TID 328)
18/03/19 07:51:16 INFO TaskSetManager: Finished task 9.0 in stage 13.0 (TID 326) in 2478 ms on localhost (executor driver) (10/96)
18/03/19 07:51:16 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 11-12
18/03/19 07:51:16 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:16 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:16 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  3 ms
18/03/19 07:51:16 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 11-12
18/03/19 07:51:16 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:16 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:16 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:51:16 DEBUG TaskMemoryManager: Task 327 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@582b4c6d
18/03/19 07:51:16 DEBUG TaskMemoryManager: Task 327 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@582b4c6d
18/03/19 07:51:17 DEBUG TaskMemoryManager: Task 328 acquired 5.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7ace5ee1
18/03/19 07:51:17 DEBUG TaskMemoryManager: Task 328 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7ace5ee1
18/03/19 07:51:17 DEBUG TaskMemoryManager: Task 327 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6b3f3efa
18/03/19 07:51:18 DEBUG TaskMemoryManager: Task 327 acquired 10.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6b3f3efa
18/03/19 07:51:18 DEBUG TaskMemoryManager: Task 327 acquired 20.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6b3f3efa
18/03/19 07:51:18 DEBUG TaskMemoryManager: Task 327 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@582b4c6d
18/03/19 07:51:18 DEBUG TaskMemoryManager: Task 327 release 36.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@6b3f3efa
18/03/19 07:51:18 INFO Executor: Finished task 10.0 in stage 13.0 (TID 327). 1219 bytes result sent to driver
18/03/19 07:51:18 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:18 INFO TaskSetManager: Starting task 12.0 in stage 13.0 (TID 329, localhost, executor driver, partition 12, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:18 INFO Executor: Running task 12.0 in stage 13.0 (TID 329)
18/03/19 07:51:18 INFO TaskSetManager: Finished task 10.0 in stage 13.0 (TID 327) in 2405 ms on localhost (executor driver) (11/96)
18/03/19 07:51:18 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 12-13
18/03/19 07:51:18 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:18 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:18 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  3 ms
18/03/19 07:51:18 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 12-13
18/03/19 07:51:18 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:18 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:18 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:51:18 TRACE HeartbeatReceiver: Checking for hosts with no recent heartbeats in HeartbeatReceiver.
18/03/19 07:51:18 DEBUG TaskMemoryManager: Task 329 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@219ab2b8
18/03/19 07:51:18 DEBUG TaskMemoryManager: Task 328 acquired 5.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@73638555
18/03/19 07:51:18 DEBUG TaskMemoryManager: Task 328 acquired 10.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@73638555
18/03/19 07:51:19 DEBUG TaskMemoryManager: Task 329 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@219ab2b8
18/03/19 07:51:19 DEBUG TaskMemoryManager: Task 328 acquired 21.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@73638555
18/03/19 07:51:19 DEBUG TaskMemoryManager: Task 328 release 15.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@7ace5ee1
18/03/19 07:51:19 DEBUG TaskMemoryManager: Task 328 release 37.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@73638555
18/03/19 07:51:19 INFO Executor: Finished task 11.0 in stage 13.0 (TID 328). 1219 bytes result sent to driver
18/03/19 07:51:19 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:19 INFO TaskSetManager: Starting task 13.0 in stage 13.0 (TID 330, localhost, executor driver, partition 13, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:19 INFO Executor: Running task 13.0 in stage 13.0 (TID 330)
18/03/19 07:51:19 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 13-14
18/03/19 07:51:19 INFO TaskSetManager: Finished task 11.0 in stage 13.0 (TID 328) in 2881 ms on localhost (executor driver) (12/96)
18/03/19 07:51:19 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:19 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:19 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:51:19 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 13-14
18/03/19 07:51:19 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:19 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:51:19 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:51:19 DEBUG TaskMemoryManager: Task 330 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6105638
18/03/19 07:51:19 DEBUG TaskMemoryManager: Task 330 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6105638
18/03/19 07:51:20 DEBUG TaskMemoryManager: Task 329 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5727e305
18/03/19 07:51:20 DEBUG TaskMemoryManager: Task 329 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5727e305
18/03/19 07:51:20 DEBUG TaskMemoryManager: Task 329 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5727e305
18/03/19 07:51:20 DEBUG TaskMemoryManager: Task 329 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@219ab2b8
18/03/19 07:51:20 DEBUG TaskMemoryManager: Task 329 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5727e305
18/03/19 07:51:20 INFO Executor: Finished task 12.0 in stage 13.0 (TID 329). 1219 bytes result sent to driver
18/03/19 07:51:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:20 INFO TaskSetManager: Starting task 14.0 in stage 13.0 (TID 331, localhost, executor driver, partition 14, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:20 INFO Executor: Running task 14.0 in stage 13.0 (TID 331)
18/03/19 07:51:20 INFO TaskSetManager: Finished task 12.0 in stage 13.0 (TID 329) in 2469 ms on localhost (executor driver) (13/96)
18/03/19 07:51:20 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 14-15
18/03/19 07:51:20 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:20 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:20 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:51:20 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 14-15
18/03/19 07:51:20 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:20 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:20 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:51:21 DEBUG TaskMemoryManager: Task 330 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@b8b6cda
18/03/19 07:51:21 DEBUG TaskMemoryManager: Task 330 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@b8b6cda
18/03/19 07:51:21 DEBUG TaskMemoryManager: Task 331 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@43343aef
18/03/19 07:51:21 DEBUG TaskMemoryManager: Task 330 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@b8b6cda
18/03/19 07:51:22 DEBUG TaskMemoryManager: Task 330 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@6105638
18/03/19 07:51:22 DEBUG TaskMemoryManager: Task 330 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@b8b6cda
18/03/19 07:51:22 INFO Executor: Finished task 13.0 in stage 13.0 (TID 330). 1176 bytes result sent to driver
18/03/19 07:51:22 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:22 INFO TaskSetManager: Starting task 15.0 in stage 13.0 (TID 332, localhost, executor driver, partition 15, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:22 INFO Executor: Running task 15.0 in stage 13.0 (TID 332)
18/03/19 07:51:22 INFO TaskSetManager: Finished task 13.0 in stage 13.0 (TID 330) in 2801 ms on localhost (executor driver) (14/96)
18/03/19 07:51:22 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 15-16
18/03/19 07:51:22 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:22 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:22 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:51:22 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 15-16
18/03/19 07:51:22 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:22 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:22 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:51:22 DEBUG TaskMemoryManager: Task 331 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@43343aef
18/03/19 07:51:22 DEBUG TaskMemoryManager: Task 332 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@40aca3df
18/03/19 07:51:22 DEBUG TaskMemoryManager: Task 332 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@40aca3df
18/03/19 07:51:23 DEBUG TaskMemoryManager: Task 331 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@f10f5a4
18/03/19 07:51:23 DEBUG TaskMemoryManager: Task 331 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@f10f5a4
18/03/19 07:51:23 DEBUG TaskMemoryManager: Task 331 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@f10f5a4
18/03/19 07:51:23 DEBUG TaskMemoryManager: Task 331 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@43343aef
18/03/19 07:51:23 DEBUG TaskMemoryManager: Task 331 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@f10f5a4
18/03/19 07:51:23 INFO Executor: Finished task 14.0 in stage 13.0 (TID 331). 1219 bytes result sent to driver
18/03/19 07:51:23 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:23 INFO TaskSetManager: Starting task 16.0 in stage 13.0 (TID 333, localhost, executor driver, partition 16, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:23 INFO Executor: Running task 16.0 in stage 13.0 (TID 333)
18/03/19 07:51:23 INFO TaskSetManager: Finished task 14.0 in stage 13.0 (TID 331) in 2807 ms on localhost (executor driver) (15/96)
18/03/19 07:51:23 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 16-17
18/03/19 07:51:23 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:23 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:23 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:51:23 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 16-17
18/03/19 07:51:23 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:23 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:23 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:51:24 DEBUG TaskMemoryManager: Task 332 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2794619f
18/03/19 07:51:24 DEBUG TaskMemoryManager: Task 333 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6dcc10e6
18/03/19 07:51:24 DEBUG TaskMemoryManager: Task 332 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2794619f
18/03/19 07:51:24 DEBUG TaskMemoryManager: Task 332 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2794619f
18/03/19 07:51:24 DEBUG TaskMemoryManager: Task 332 release 15.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@40aca3df
18/03/19 07:51:24 DEBUG TaskMemoryManager: Task 333 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6dcc10e6
18/03/19 07:51:24 DEBUG TaskMemoryManager: Task 332 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2794619f
18/03/19 07:51:24 INFO Executor: Finished task 15.0 in stage 13.0 (TID 332). 1176 bytes result sent to driver
18/03/19 07:51:24 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:24 INFO TaskSetManager: Starting task 17.0 in stage 13.0 (TID 334, localhost, executor driver, partition 17, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:24 INFO TaskSetManager: Finished task 15.0 in stage 13.0 (TID 332) in 2608 ms on localhost (executor driver) (16/96)
18/03/19 07:51:24 INFO Executor: Running task 17.0 in stage 13.0 (TID 334)
18/03/19 07:51:24 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 17-18
18/03/19 07:51:24 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:24 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:24 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:51:24 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 17-18
18/03/19 07:51:24 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:24 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:24 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:51:25 DEBUG TaskMemoryManager: Task 334 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@32ed4f76
18/03/19 07:51:25 DEBUG TaskMemoryManager: Task 334 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@32ed4f76
18/03/19 07:51:26 DEBUG TaskMemoryManager: Task 333 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@72c4cbce
18/03/19 07:51:26 DEBUG TaskMemoryManager: Task 333 acquired 10.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@72c4cbce
18/03/19 07:51:26 DEBUG TaskMemoryManager: Task 334 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4eecf468
18/03/19 07:51:26 DEBUG TaskMemoryManager: Task 333 acquired 20.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@72c4cbce
18/03/19 07:51:26 DEBUG TaskMemoryManager: Task 334 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4eecf468
18/03/19 07:51:26 DEBUG TaskMemoryManager: Task 333 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@6dcc10e6
18/03/19 07:51:26 DEBUG TaskMemoryManager: Task 333 release 35.4 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@72c4cbce
18/03/19 07:51:26 INFO Executor: Finished task 16.0 in stage 13.0 (TID 333). 1219 bytes result sent to driver
18/03/19 07:51:26 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:27 INFO TaskSetManager: Starting task 18.0 in stage 13.0 (TID 335, localhost, executor driver, partition 18, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:27 INFO Executor: Running task 18.0 in stage 13.0 (TID 335)
18/03/19 07:51:27 INFO TaskSetManager: Finished task 16.0 in stage 13.0 (TID 333) in 3282 ms on localhost (executor driver) (17/96)
18/03/19 07:51:27 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 18-19
18/03/19 07:51:27 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:27 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:27 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:51:27 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 18-19
18/03/19 07:51:27 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:27 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:27 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:51:27 DEBUG TaskMemoryManager: Task 334 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4eecf468
18/03/19 07:51:27 DEBUG TaskMemoryManager: Task 335 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2529b9cf
18/03/19 07:51:27 DEBUG TaskMemoryManager: Task 334 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@32ed4f76
18/03/19 07:51:27 DEBUG TaskMemoryManager: Task 334 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@4eecf468
18/03/19 07:51:27 INFO Executor: Finished task 17.0 in stage 13.0 (TID 334). 1219 bytes result sent to driver
18/03/19 07:51:27 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:27 INFO TaskSetManager: Starting task 19.0 in stage 13.0 (TID 336, localhost, executor driver, partition 19, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:27 INFO Executor: Running task 19.0 in stage 13.0 (TID 336)
18/03/19 07:51:27 INFO TaskSetManager: Finished task 17.0 in stage 13.0 (TID 334) in 2805 ms on localhost (executor driver) (18/96)
18/03/19 07:51:27 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 19-20
18/03/19 07:51:27 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:27 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:27 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  3 ms
18/03/19 07:51:27 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 19-20
18/03/19 07:51:27 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:27 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:27 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:51:27 DEBUG TaskMemoryManager: Task 336 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@24e4ef98
18/03/19 07:51:27 DEBUG TaskMemoryManager: Task 335 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2529b9cf
18/03/19 07:51:28 DEBUG TaskMemoryManager: Task 336 acquired 10.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@24e4ef98
18/03/19 07:51:29 DEBUG TaskMemoryManager: Task 335 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1d1c7e98
18/03/19 07:51:29 DEBUG TaskMemoryManager: Task 335 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1d1c7e98
18/03/19 07:51:29 DEBUG TaskMemoryManager: Task 335 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1d1c7e98
18/03/19 07:51:29 DEBUG TaskMemoryManager: Task 336 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@68feb379
18/03/19 07:51:30 DEBUG TaskMemoryManager: Task 336 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@68feb379
18/03/19 07:51:30 DEBUG TaskMemoryManager: Task 335 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2529b9cf
18/03/19 07:51:30 DEBUG TaskMemoryManager: Task 335 release 35.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@1d1c7e98
18/03/19 07:51:30 INFO Executor: Finished task 18.0 in stage 13.0 (TID 335). 1219 bytes result sent to driver
18/03/19 07:51:30 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:30 INFO TaskSetManager: Starting task 20.0 in stage 13.0 (TID 337, localhost, executor driver, partition 20, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:30 INFO Executor: Running task 20.0 in stage 13.0 (TID 337)
18/03/19 07:51:30 INFO TaskSetManager: Finished task 18.0 in stage 13.0 (TID 335) in 3105 ms on localhost (executor driver) (19/96)
18/03/19 07:51:30 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 20-21
18/03/19 07:51:30 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:30 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:30 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:51:30 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 20-21
18/03/19 07:51:30 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:30 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:30 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:51:30 DEBUG TaskMemoryManager: Task 337 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3cbe1dfc
18/03/19 07:51:30 DEBUG TaskMemoryManager: Task 336 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@68feb379
18/03/19 07:51:30 DEBUG TaskMemoryManager: Task 336 acquired 40.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@68feb379
18/03/19 07:51:30 DEBUG TaskMemoryManager: Task 336 release 15.3 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@24e4ef98
18/03/19 07:51:30 DEBUG TaskMemoryManager: Task 336 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@68feb379
18/03/19 07:51:30 INFO Executor: Finished task 19.0 in stage 13.0 (TID 336). 1219 bytes result sent to driver
18/03/19 07:51:30 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:30 INFO TaskSetManager: Starting task 21.0 in stage 13.0 (TID 338, localhost, executor driver, partition 21, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:30 INFO Executor: Running task 21.0 in stage 13.0 (TID 338)
18/03/19 07:51:30 INFO TaskSetManager: Finished task 19.0 in stage 13.0 (TID 336) in 3107 ms on localhost (executor driver) (20/96)
18/03/19 07:51:30 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 21-22
18/03/19 07:51:30 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:30 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:30 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:51:30 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 21-22
18/03/19 07:51:30 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:30 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:30 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:51:30 DEBUG TaskMemoryManager: Task 337 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3cbe1dfc
18/03/19 07:51:30 DEBUG TaskMemoryManager: Task 338 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1eab538
18/03/19 07:51:31 DEBUG TaskMemoryManager: Task 338 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1eab538
18/03/19 07:51:31 DEBUG TaskMemoryManager: Task 337 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3cbe1dfc
18/03/19 07:51:32 DEBUG TaskMemoryManager: Task 338 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1eab538
18/03/19 07:51:33 DEBUG TaskMemoryManager: Task 337 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7415b9e7
18/03/19 07:51:33 DEBUG TaskMemoryManager: Task 337 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7415b9e7
18/03/19 07:51:33 DEBUG TaskMemoryManager: Task 338 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5f7f3227
18/03/19 07:51:33 DEBUG TaskMemoryManager: Task 337 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7415b9e7
18/03/19 07:51:33 DEBUG TaskMemoryManager: Task 338 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5f7f3227
18/03/19 07:51:33 DEBUG TaskMemoryManager: Task 337 acquired 40.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7415b9e7
18/03/19 07:51:33 DEBUG TaskMemoryManager: Task 338 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5f7f3227
18/03/19 07:51:34 DEBUG TaskMemoryManager: Task 337 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3cbe1dfc
18/03/19 07:51:34 DEBUG TaskMemoryManager: Task 337 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@7415b9e7
18/03/19 07:51:34 INFO Executor: Finished task 20.0 in stage 13.0 (TID 337). 1219 bytes result sent to driver
18/03/19 07:51:34 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:34 INFO TaskSetManager: Starting task 22.0 in stage 13.0 (TID 339, localhost, executor driver, partition 22, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:34 INFO TaskSetManager: Finished task 20.0 in stage 13.0 (TID 337) in 4686 ms on localhost (executor driver) (21/96)
18/03/19 07:51:34 INFO Executor: Running task 22.0 in stage 13.0 (TID 339)
18/03/19 07:51:34 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 22-23
18/03/19 07:51:34 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:34 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:51:34 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  3 ms
18/03/19 07:51:34 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 22-23
18/03/19 07:51:34 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:34 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:51:34 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:51:34 DEBUG TaskMemoryManager: Task 338 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5f7f3227
18/03/19 07:51:35 DEBUG TaskMemoryManager: Task 338 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@1eab538
18/03/19 07:51:35 DEBUG TaskMemoryManager: Task 338 release 75.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5f7f3227
18/03/19 07:51:35 INFO Executor: Finished task 21.0 in stage 13.0 (TID 338). 1176 bytes result sent to driver
18/03/19 07:51:35 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:35 INFO TaskSetManager: Starting task 23.0 in stage 13.0 (TID 340, localhost, executor driver, partition 23, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:35 INFO TaskSetManager: Finished task 21.0 in stage 13.0 (TID 338) in 4426 ms on localhost (executor driver) (22/96)
18/03/19 07:51:35 INFO Executor: Running task 23.0 in stage 13.0 (TID 340)
18/03/19 07:51:35 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 23-24
18/03/19 07:51:35 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:35 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:35 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:51:35 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 23-24
18/03/19 07:51:35 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:35 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:51:35 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:51:35 DEBUG TaskMemoryManager: Task 339 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4bb8ed0d
18/03/19 07:51:35 DEBUG TaskMemoryManager: Task 340 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@25a4dbc1
18/03/19 07:51:35 DEBUG TaskMemoryManager: Task 339 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4bb8ed0d
18/03/19 07:51:35 DEBUG TaskMemoryManager: Task 340 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@25a4dbc1
18/03/19 07:51:36 DEBUG TaskMemoryManager: Task 340 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@25a4dbc1
18/03/19 07:51:37 DEBUG TaskMemoryManager: Task 339 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@55a81eee
18/03/19 07:51:37 DEBUG TaskMemoryManager: Task 339 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@55a81eee
18/03/19 07:51:38 DEBUG TaskMemoryManager: Task 339 acquired 20.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@55a81eee
18/03/19 07:51:38 DEBUG TaskMemoryManager: Task 340 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@11a10b82
18/03/19 07:51:38 DEBUG TaskMemoryManager: Task 340 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@11a10b82
18/03/19 07:51:38 DEBUG TaskMemoryManager: Task 339 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@4bb8ed0d
18/03/19 07:51:38 DEBUG TaskMemoryManager: Task 339 release 35.4 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@55a81eee
18/03/19 07:51:38 INFO Executor: Finished task 22.0 in stage 13.0 (TID 339). 1219 bytes result sent to driver
18/03/19 07:51:38 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:38 INFO TaskSetManager: Starting task 24.0 in stage 13.0 (TID 341, localhost, executor driver, partition 24, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:38 INFO TaskSetManager: Finished task 22.0 in stage 13.0 (TID 339) in 3735 ms on localhost (executor driver) (23/96)
18/03/19 07:51:38 INFO Executor: Running task 24.0 in stage 13.0 (TID 341)
18/03/19 07:51:38 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 24-25
18/03/19 07:51:38 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:38 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:38 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:51:38 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 24-25
18/03/19 07:51:38 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:38 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:38 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:51:38 DEBUG TaskMemoryManager: Task 340 acquired 20.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@11a10b82
18/03/19 07:51:38 DEBUG TaskMemoryManager: Task 341 acquired 5.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@51ba204b
18/03/19 07:51:38 DEBUG TaskMemoryManager: Task 340 acquired 40.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@11a10b82
18/03/19 07:51:39 DEBUG TaskMemoryManager: Task 340 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@25a4dbc1
18/03/19 07:51:39 DEBUG TaskMemoryManager: Task 340 release 75.3 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@11a10b82
18/03/19 07:51:39 INFO Executor: Finished task 23.0 in stage 13.0 (TID 340). 1219 bytes result sent to driver
18/03/19 07:51:39 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:39 INFO TaskSetManager: Starting task 25.0 in stage 13.0 (TID 342, localhost, executor driver, partition 25, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:39 INFO TaskSetManager: Finished task 23.0 in stage 13.0 (TID 340) in 4035 ms on localhost (executor driver) (24/96)
18/03/19 07:51:39 INFO Executor: Running task 25.0 in stage 13.0 (TID 342)
18/03/19 07:51:39 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 25-26
18/03/19 07:51:39 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:39 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:39 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:51:39 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 25-26
18/03/19 07:51:39 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:39 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:39 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:51:39 DEBUG TaskMemoryManager: Task 341 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@51ba204b
18/03/19 07:51:39 DEBUG TaskMemoryManager: Task 342 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1bda0b86
18/03/19 07:51:39 DEBUG TaskMemoryManager: Task 342 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1bda0b86
18/03/19 07:51:40 DEBUG TaskMemoryManager: Task 341 acquired 20.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@51ba204b
18/03/19 07:51:40 DEBUG TaskMemoryManager: Task 342 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1bda0b86
18/03/19 07:51:41 DEBUG TaskMemoryManager: Task 341 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@e36abf9
18/03/19 07:51:41 DEBUG TaskMemoryManager: Task 341 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@e36abf9
18/03/19 07:51:41 DEBUG TaskMemoryManager: Task 341 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@e36abf9
18/03/19 07:51:41 DEBUG TaskMemoryManager: Task 341 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@e36abf9
18/03/19 07:51:41 DEBUG TaskMemoryManager: Task 342 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@20edb1b
18/03/19 07:51:43 DEBUG TaskMemoryManager: Task 341 release 35.4 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@51ba204b
18/03/19 07:51:43 DEBUG TaskMemoryManager: Task 341 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@e36abf9
18/03/19 07:51:43 INFO Executor: Finished task 24.0 in stage 13.0 (TID 341). 1219 bytes result sent to driver
18/03/19 07:51:43 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:43 INFO TaskSetManager: Starting task 26.0 in stage 13.0 (TID 343, localhost, executor driver, partition 26, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:43 INFO Executor: Running task 26.0 in stage 13.0 (TID 343)
18/03/19 07:51:43 INFO TaskSetManager: Finished task 24.0 in stage 13.0 (TID 341) in 4631 ms on localhost (executor driver) (25/96)
18/03/19 07:51:43 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 26-27
18/03/19 07:51:43 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:43 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:43 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  5 ms
18/03/19 07:51:43 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 26-27
18/03/19 07:51:43 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:43 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
18/03/19 07:51:43 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:51:43 DEBUG TaskMemoryManager: Task 342 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@20edb1b
18/03/19 07:51:43 DEBUG TaskMemoryManager: Task 343 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@393ded41
18/03/19 07:51:43 DEBUG TaskMemoryManager: Task 342 acquired 20.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@20edb1b
18/03/19 07:51:43 DEBUG TaskMemoryManager: Task 343 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@393ded41
18/03/19 07:51:43 DEBUG TaskMemoryManager: Task 342 acquired 44.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@20edb1b
18/03/19 07:51:43 DEBUG TaskMemoryManager: Task 342 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@1bda0b86
18/03/19 07:51:43 DEBUG TaskMemoryManager: Task 342 release 79.7 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@20edb1b
18/03/19 07:51:43 INFO Executor: Finished task 25.0 in stage 13.0 (TID 342). 1176 bytes result sent to driver
18/03/19 07:51:43 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:43 INFO TaskSetManager: Starting task 27.0 in stage 13.0 (TID 344, localhost, executor driver, partition 27, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:43 INFO TaskSetManager: Finished task 25.0 in stage 13.0 (TID 342) in 4858 ms on localhost (executor driver) (26/96)
18/03/19 07:51:43 INFO Executor: Running task 27.0 in stage 13.0 (TID 344)
18/03/19 07:51:43 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 27-28
18/03/19 07:51:43 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:43 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:51:43 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  3 ms
18/03/19 07:51:43 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 27-28
18/03/19 07:51:43 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:43 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:43 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:51:44 DEBUG TaskMemoryManager: Task 344 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1bdd3616
18/03/19 07:51:44 DEBUG TaskMemoryManager: Task 343 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@393ded41
18/03/19 07:51:44 DEBUG TaskMemoryManager: Task 344 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1bdd3616
18/03/19 07:51:46 DEBUG TaskMemoryManager: Task 344 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1bdd3616
18/03/19 07:51:46 DEBUG TaskMemoryManager: Task 343 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2c5c23a4
18/03/19 07:51:46 DEBUG TaskMemoryManager: Task 343 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2c5c23a4
18/03/19 07:51:46 DEBUG TaskMemoryManager: Task 343 acquired 20.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2c5c23a4
18/03/19 07:51:47 DEBUG TaskMemoryManager: Task 343 acquired 40.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2c5c23a4
18/03/19 07:51:47 DEBUG TaskMemoryManager: Task 343 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@393ded41
18/03/19 07:51:47 DEBUG TaskMemoryManager: Task 343 release 75.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2c5c23a4
18/03/19 07:51:47 INFO Executor: Finished task 26.0 in stage 13.0 (TID 343). 1176 bytes result sent to driver
18/03/19 07:51:47 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:47 INFO TaskSetManager: Starting task 28.0 in stage 13.0 (TID 345, localhost, executor driver, partition 28, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:47 INFO TaskSetManager: Finished task 26.0 in stage 13.0 (TID 343) in 4178 ms on localhost (executor driver) (27/96)
18/03/19 07:51:47 INFO Executor: Running task 28.0 in stage 13.0 (TID 345)
18/03/19 07:51:47 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 28-29
18/03/19 07:51:47 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:47 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:47 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:51:47 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 28-29
18/03/19 07:51:47 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:47 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:47 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:51:47 DEBUG TaskMemoryManager: Task 344 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@70eed872
18/03/19 07:51:47 DEBUG TaskMemoryManager: Task 345 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3fa18d16
18/03/19 07:51:47 DEBUG TaskMemoryManager: Task 344 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@70eed872
18/03/19 07:51:47 DEBUG TaskMemoryManager: Task 344 acquired 22.8 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@70eed872
18/03/19 07:51:48 DEBUG TaskMemoryManager: Task 345 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3fa18d16
18/03/19 07:51:48 DEBUG TaskMemoryManager: Task 344 acquired 42.9 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@70eed872
18/03/19 07:51:48 DEBUG TaskMemoryManager: Task 344 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@1bdd3616
18/03/19 07:51:48 DEBUG TaskMemoryManager: Task 344 release 80.8 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@70eed872
18/03/19 07:51:48 INFO Executor: Finished task 27.0 in stage 13.0 (TID 344). 1219 bytes result sent to driver
18/03/19 07:51:48 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:48 INFO TaskSetManager: Starting task 29.0 in stage 13.0 (TID 346, localhost, executor driver, partition 29, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:48 INFO TaskSetManager: Finished task 27.0 in stage 13.0 (TID 344) in 4574 ms on localhost (executor driver) (28/96)
18/03/19 07:51:48 INFO Executor: Running task 29.0 in stage 13.0 (TID 346)
18/03/19 07:51:48 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 29-30
18/03/19 07:51:48 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:48 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:48 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:51:48 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 29-30
18/03/19 07:51:48 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:48 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:48 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:51:48 DEBUG TaskMemoryManager: Task 346 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1ec352fd
18/03/19 07:51:49 DEBUG TaskMemoryManager: Task 346 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1ec352fd
18/03/19 07:51:49 DEBUG TaskMemoryManager: Task 345 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3fa18d16
18/03/19 07:51:50 DEBUG TaskMemoryManager: Task 346 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1ec352fd
18/03/19 07:51:52 DEBUG TaskMemoryManager: Task 345 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6d310e35
18/03/19 07:51:52 DEBUG TaskMemoryManager: Task 346 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@18e31d53
18/03/19 07:51:52 DEBUG TaskMemoryManager: Task 345 acquired 10.8 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6d310e35
18/03/19 07:51:52 DEBUG TaskMemoryManager: Task 346 acquired 11.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@18e31d53
18/03/19 07:51:52 DEBUG TaskMemoryManager: Task 345 acquired 20.8 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6d310e35
18/03/19 07:51:52 DEBUG TaskMemoryManager: Task 346 acquired 21.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@18e31d53
18/03/19 07:51:52 DEBUG TaskMemoryManager: Task 345 acquired 41.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6d310e35
18/03/19 07:51:52 DEBUG TaskMemoryManager: Task 346 acquired 42.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@18e31d53
18/03/19 07:51:53 DEBUG TaskMemoryManager: Task 345 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3fa18d16
18/03/19 07:51:53 DEBUG TaskMemoryManager: Task 345 release 78.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@6d310e35
18/03/19 07:51:53 INFO Executor: Finished task 28.0 in stage 13.0 (TID 345). 1219 bytes result sent to driver
18/03/19 07:51:53 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:53 INFO TaskSetManager: Starting task 30.0 in stage 13.0 (TID 347, localhost, executor driver, partition 30, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:53 INFO Executor: Running task 30.0 in stage 13.0 (TID 347)
18/03/19 07:51:53 INFO TaskSetManager: Finished task 28.0 in stage 13.0 (TID 345) in 5855 ms on localhost (executor driver) (29/96)
18/03/19 07:51:53 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 30-31
18/03/19 07:51:53 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:53 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:53 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:51:53 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 30-31
18/03/19 07:51:53 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:53 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:53 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:51:53 DEBUG TaskMemoryManager: Task 346 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@1ec352fd
18/03/19 07:51:53 DEBUG TaskMemoryManager: Task 346 release 79.7 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@18e31d53
18/03/19 07:51:53 INFO Executor: Finished task 29.0 in stage 13.0 (TID 346). 1219 bytes result sent to driver
18/03/19 07:51:53 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:53 INFO TaskSetManager: Starting task 31.0 in stage 13.0 (TID 348, localhost, executor driver, partition 31, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:53 INFO Executor: Running task 31.0 in stage 13.0 (TID 348)
18/03/19 07:51:53 INFO TaskSetManager: Finished task 29.0 in stage 13.0 (TID 346) in 4734 ms on localhost (executor driver) (30/96)
18/03/19 07:51:53 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 31-32
18/03/19 07:51:53 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:53 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:53 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:51:53 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 31-32
18/03/19 07:51:53 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:53 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:53 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:51:53 DEBUG TaskMemoryManager: Task 347 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7b8ae141
18/03/19 07:51:53 DEBUG TaskMemoryManager: Task 348 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3c4a9ad3
18/03/19 07:51:53 DEBUG TaskMemoryManager: Task 347 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7b8ae141
18/03/19 07:51:54 DEBUG TaskMemoryManager: Task 348 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3c4a9ad3
18/03/19 07:51:54 DEBUG TaskMemoryManager: Task 347 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7b8ae141
18/03/19 07:51:54 DEBUG TaskMemoryManager: Task 348 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3c4a9ad3
18/03/19 07:51:56 DEBUG TaskMemoryManager: Task 347 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@79a02a78
18/03/19 07:51:56 DEBUG TaskMemoryManager: Task 347 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@79a02a78
18/03/19 07:51:56 DEBUG TaskMemoryManager: Task 348 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@697e2bfb
18/03/19 07:51:56 DEBUG TaskMemoryManager: Task 347 acquired 20.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@79a02a78
18/03/19 07:51:56 DEBUG TaskMemoryManager: Task 348 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@697e2bfb
18/03/19 07:51:56 DEBUG TaskMemoryManager: Task 348 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@697e2bfb
18/03/19 07:51:56 DEBUG TaskMemoryManager: Task 347 acquired 40.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@79a02a78
18/03/19 07:51:56 DEBUG TaskMemoryManager: Task 348 acquired 41.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@697e2bfb
18/03/19 07:51:56 DEBUG TaskMemoryManager: Task 347 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@7b8ae141
18/03/19 07:51:57 DEBUG TaskMemoryManager: Task 347 release 76.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@79a02a78
18/03/19 07:51:57 INFO Executor: Finished task 30.0 in stage 13.0 (TID 347). 1176 bytes result sent to driver
18/03/19 07:51:57 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:57 INFO TaskSetManager: Starting task 32.0 in stage 13.0 (TID 349, localhost, executor driver, partition 32, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:57 INFO TaskSetManager: Finished task 30.0 in stage 13.0 (TID 347) in 3832 ms on localhost (executor driver) (31/96)
18/03/19 07:51:57 INFO Executor: Running task 32.0 in stage 13.0 (TID 349)
18/03/19 07:51:57 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 32-33
18/03/19 07:51:57 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:57 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:51:57 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:51:57 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 32-33
18/03/19 07:51:57 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:57 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:57 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:51:57 DEBUG TaskMemoryManager: Task 348 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3c4a9ad3
18/03/19 07:51:57 DEBUG TaskMemoryManager: Task 349 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@15ef9bcf
18/03/19 07:51:57 DEBUG TaskMemoryManager: Task 348 release 76.3 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@697e2bfb
18/03/19 07:51:57 INFO Executor: Finished task 31.0 in stage 13.0 (TID 348). 1219 bytes result sent to driver
18/03/19 07:51:57 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:51:57 INFO TaskSetManager: Starting task 33.0 in stage 13.0 (TID 350, localhost, executor driver, partition 33, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:51:57 INFO TaskSetManager: Finished task 31.0 in stage 13.0 (TID 348) in 3967 ms on localhost (executor driver) (32/96)
18/03/19 07:51:57 INFO Executor: Running task 33.0 in stage 13.0 (TID 350)
18/03/19 07:51:57 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 33-34
18/03/19 07:51:57 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:57 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:51:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:57 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:51:57 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 33-34
18/03/19 07:51:57 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:51:57 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:51:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:51:57 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:51:57 DEBUG TaskMemoryManager: Task 350 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@37157861
18/03/19 07:51:57 DEBUG TaskMemoryManager: Task 349 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@15ef9bcf
18/03/19 07:51:57 DEBUG TaskMemoryManager: Task 350 acquired 10.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@37157861
18/03/19 07:51:58 DEBUG TaskMemoryManager: Task 349 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@15ef9bcf
18/03/19 07:51:59 DEBUG TaskMemoryManager: Task 350 acquired 20.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@37157861
18/03/19 07:51:59 DEBUG TaskMemoryManager: Task 349 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3acabc74
18/03/19 07:52:00 DEBUG TaskMemoryManager: Task 349 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3acabc74
18/03/19 07:52:01 DEBUG TaskMemoryManager: Task 349 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3acabc74
18/03/19 07:52:01 DEBUG TaskMemoryManager: Task 350 acquired 5.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7dabc276
18/03/19 07:52:01 DEBUG TaskMemoryManager: Task 349 acquired 40.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3acabc74
18/03/19 07:52:01 DEBUG TaskMemoryManager: Task 350 acquired 10.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7dabc276
18/03/19 07:52:01 DEBUG TaskMemoryManager: Task 350 acquired 21.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7dabc276
18/03/19 07:52:01 DEBUG TaskMemoryManager: Task 349 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@15ef9bcf
18/03/19 07:52:01 DEBUG TaskMemoryManager: Task 349 release 75.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3acabc74
18/03/19 07:52:01 INFO Executor: Finished task 32.0 in stage 13.0 (TID 349). 1176 bytes result sent to driver
18/03/19 07:52:01 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:01 INFO TaskSetManager: Starting task 34.0 in stage 13.0 (TID 351, localhost, executor driver, partition 34, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:01 INFO TaskSetManager: Finished task 32.0 in stage 13.0 (TID 349) in 4556 ms on localhost (executor driver) (33/96)
18/03/19 07:52:01 INFO Executor: Running task 34.0 in stage 13.0 (TID 351)
18/03/19 07:52:01 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 34-35
18/03/19 07:52:01 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:01 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:01 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:52:01 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 34-35
18/03/19 07:52:01 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:01 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:01 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:52:01 DEBUG TaskMemoryManager: Task 350 acquired 42.7 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7dabc276
18/03/19 07:52:02 DEBUG TaskMemoryManager: Task 351 acquired 5.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@12b752fb
18/03/19 07:52:02 DEBUG TaskMemoryManager: Task 350 release 35.9 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@37157861
18/03/19 07:52:02 DEBUG TaskMemoryManager: Task 350 release 79.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@7dabc276
18/03/19 07:52:02 INFO Executor: Finished task 33.0 in stage 13.0 (TID 350). 1219 bytes result sent to driver
18/03/19 07:52:02 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:02 INFO TaskSetManager: Starting task 35.0 in stage 13.0 (TID 352, localhost, executor driver, partition 35, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:02 INFO Executor: Running task 35.0 in stage 13.0 (TID 352)
18/03/19 07:52:02 INFO TaskSetManager: Finished task 33.0 in stage 13.0 (TID 350) in 4933 ms on localhost (executor driver) (34/96)
18/03/19 07:52:02 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 35-36
18/03/19 07:52:02 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:02 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:02 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:52:02 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 35-36
18/03/19 07:52:02 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:02 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:02 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:02 DEBUG TaskMemoryManager: Task 352 acquired 5.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1ab9f770
18/03/19 07:52:02 DEBUG TaskMemoryManager: Task 351 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@12b752fb
18/03/19 07:52:02 DEBUG TaskMemoryManager: Task 352 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1ab9f770
18/03/19 07:52:03 DEBUG TaskMemoryManager: Task 352 acquired 20.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1ab9f770
18/03/19 07:52:04 DEBUG TaskMemoryManager: Task 351 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6ee1e553
18/03/19 07:52:04 DEBUG TaskMemoryManager: Task 352 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@14762e4d
18/03/19 07:52:04 DEBUG TaskMemoryManager: Task 351 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6ee1e553
18/03/19 07:52:04 DEBUG TaskMemoryManager: Task 352 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@14762e4d
18/03/19 07:52:05 DEBUG TaskMemoryManager: Task 351 acquired 21.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6ee1e553
18/03/19 07:52:05 DEBUG TaskMemoryManager: Task 352 acquired 22.8 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@14762e4d
18/03/19 07:52:05 DEBUG TaskMemoryManager: Task 352 acquired 42.9 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@14762e4d
18/03/19 07:52:05 DEBUG TaskMemoryManager: Task 351 release 15.3 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@12b752fb
18/03/19 07:52:05 DEBUG TaskMemoryManager: Task 352 release 35.4 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@1ab9f770
18/03/19 07:52:05 DEBUG TaskMemoryManager: Task 351 release 36.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@6ee1e553
18/03/19 07:52:05 INFO Executor: Finished task 34.0 in stage 13.0 (TID 351). 1176 bytes result sent to driver
18/03/19 07:52:05 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:05 INFO TaskSetManager: Starting task 36.0 in stage 13.0 (TID 353, localhost, executor driver, partition 36, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:05 INFO Executor: Running task 36.0 in stage 13.0 (TID 353)
18/03/19 07:52:05 INFO TaskSetManager: Finished task 34.0 in stage 13.0 (TID 351) in 3875 ms on localhost (executor driver) (35/96)
18/03/19 07:52:05 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 36-37
18/03/19 07:52:05 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:05 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:05 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  3 ms
18/03/19 07:52:05 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 36-37
18/03/19 07:52:05 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:05 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:05 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:05 DEBUG TaskMemoryManager: Task 352 release 80.7 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@14762e4d
18/03/19 07:52:05 INFO Executor: Finished task 35.0 in stage 13.0 (TID 352). 1219 bytes result sent to driver
18/03/19 07:52:05 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:05 INFO TaskSetManager: Starting task 37.0 in stage 13.0 (TID 354, localhost, executor driver, partition 37, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:05 INFO TaskSetManager: Finished task 35.0 in stage 13.0 (TID 352) in 3333 ms on localhost (executor driver) (36/96)
18/03/19 07:52:05 INFO Executor: Running task 37.0 in stage 13.0 (TID 354)
18/03/19 07:52:05 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 37-38
18/03/19 07:52:05 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:05 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:05 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  3 ms
18/03/19 07:52:05 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 37-38
18/03/19 07:52:05 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:05 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:05 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:05 DEBUG TaskMemoryManager: Task 353 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3616f3c4
18/03/19 07:52:05 DEBUG TaskMemoryManager: Task 354 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@32edb53a
18/03/19 07:52:06 DEBUG TaskMemoryManager: Task 353 acquired 10.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3616f3c4
18/03/19 07:52:06 DEBUG TaskMemoryManager: Task 354 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@32edb53a
18/03/19 07:52:07 DEBUG TaskMemoryManager: Task 353 acquired 20.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3616f3c4
18/03/19 07:52:07 DEBUG TaskMemoryManager: Task 353 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7f86ccaa
18/03/19 07:52:07 DEBUG TaskMemoryManager: Task 353 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7f86ccaa
18/03/19 07:52:08 DEBUG TaskMemoryManager: Task 354 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@59a02e5e
18/03/19 07:52:08 DEBUG TaskMemoryManager: Task 353 acquired 21.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7f86ccaa
18/03/19 07:52:08 DEBUG TaskMemoryManager: Task 354 acquired 10.8 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@59a02e5e
18/03/19 07:52:08 DEBUG TaskMemoryManager: Task 354 acquired 20.8 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@59a02e5e
18/03/19 07:52:08 DEBUG TaskMemoryManager: Task 353 acquired 41.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7f86ccaa
18/03/19 07:52:08 DEBUG TaskMemoryManager: Task 353 release 36.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3616f3c4
18/03/19 07:52:08 DEBUG TaskMemoryManager: Task 353 release 77.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@7f86ccaa
18/03/19 07:52:08 INFO Executor: Finished task 36.0 in stage 13.0 (TID 353). 1219 bytes result sent to driver
18/03/19 07:52:08 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:08 INFO TaskSetManager: Starting task 38.0 in stage 13.0 (TID 355, localhost, executor driver, partition 38, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:08 INFO TaskSetManager: Finished task 36.0 in stage 13.0 (TID 353) in 3148 ms on localhost (executor driver) (37/96)
18/03/19 07:52:08 INFO Executor: Running task 38.0 in stage 13.0 (TID 355)
18/03/19 07:52:08 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 38-39
18/03/19 07:52:08 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:08 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:08 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:52:08 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 38-39
18/03/19 07:52:08 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:08 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:08 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:08 DEBUG TaskMemoryManager: Task 355 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3b25f16e
18/03/19 07:52:08 DEBUG TaskMemoryManager: Task 354 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@32edb53a
18/03/19 07:52:08 DEBUG TaskMemoryManager: Task 354 release 36.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@59a02e5e
18/03/19 07:52:08 INFO Executor: Finished task 37.0 in stage 13.0 (TID 354). 1219 bytes result sent to driver
18/03/19 07:52:08 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:08 INFO TaskSetManager: Starting task 39.0 in stage 13.0 (TID 356, localhost, executor driver, partition 39, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:08 INFO Executor: Running task 39.0 in stage 13.0 (TID 356)
18/03/19 07:52:08 INFO TaskSetManager: Finished task 37.0 in stage 13.0 (TID 354) in 3375 ms on localhost (executor driver) (38/96)
18/03/19 07:52:08 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 39-40
18/03/19 07:52:08 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:08 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:08 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  3 ms
18/03/19 07:52:08 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 39-40
18/03/19 07:52:08 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:08 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:08 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:09 DEBUG TaskMemoryManager: Task 356 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@692c4f6d
18/03/19 07:52:09 DEBUG TaskMemoryManager: Task 355 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3b25f16e
18/03/19 07:52:09 DEBUG TaskMemoryManager: Task 356 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@692c4f6d
18/03/19 07:52:09 DEBUG TaskMemoryManager: Task 355 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3b25f16e
18/03/19 07:52:10 DEBUG TaskMemoryManager: Task 355 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3e88e02d
18/03/19 07:52:10 DEBUG TaskMemoryManager: Task 355 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3e88e02d
18/03/19 07:52:10 DEBUG TaskMemoryManager: Task 356 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7c5b9c55
18/03/19 07:52:10 DEBUG TaskMemoryManager: Task 355 acquired 20.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3e88e02d
18/03/19 07:52:11 DEBUG TaskMemoryManager: Task 356 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7c5b9c55
18/03/19 07:52:11 DEBUG TaskMemoryManager: Task 356 acquired 21.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7c5b9c55
18/03/19 07:52:11 DEBUG TaskMemoryManager: Task 355 acquired 41.9 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3e88e02d
18/03/19 07:52:11 DEBUG TaskMemoryManager: Task 355 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3b25f16e
18/03/19 07:52:11 DEBUG TaskMemoryManager: Task 355 release 77.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3e88e02d
18/03/19 07:52:11 INFO Executor: Finished task 38.0 in stage 13.0 (TID 355). 1219 bytes result sent to driver
18/03/19 07:52:11 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:11 INFO TaskSetManager: Starting task 40.0 in stage 13.0 (TID 357, localhost, executor driver, partition 40, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:11 INFO Executor: Running task 40.0 in stage 13.0 (TID 357)
18/03/19 07:52:11 INFO TaskSetManager: Finished task 38.0 in stage 13.0 (TID 355) in 2772 ms on localhost (executor driver) (39/96)
18/03/19 07:52:11 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 40-41
18/03/19 07:52:11 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:11 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:11 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:52:11 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 40-41
18/03/19 07:52:11 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:11 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:11 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:11 DEBUG TaskMemoryManager: Task 356 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@692c4f6d
18/03/19 07:52:11 DEBUG TaskMemoryManager: Task 356 release 36.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@7c5b9c55
18/03/19 07:52:11 INFO Executor: Finished task 39.0 in stage 13.0 (TID 356). 1219 bytes result sent to driver
18/03/19 07:52:11 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:11 INFO TaskSetManager: Starting task 41.0 in stage 13.0 (TID 358, localhost, executor driver, partition 41, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:11 INFO Executor: Running task 41.0 in stage 13.0 (TID 358)
18/03/19 07:52:11 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 41-42
18/03/19 07:52:11 INFO TaskSetManager: Finished task 39.0 in stage 13.0 (TID 356) in 2710 ms on localhost (executor driver) (40/96)
18/03/19 07:52:11 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:11 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:11 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:52:11 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 41-42
18/03/19 07:52:11 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:11 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:11 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:11 DEBUG TaskMemoryManager: Task 357 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1745972f
18/03/19 07:52:11 DEBUG TaskMemoryManager: Task 358 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@15b3e79e
18/03/19 07:52:11 DEBUG TaskMemoryManager: Task 357 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1745972f
18/03/19 07:52:12 DEBUG TaskMemoryManager: Task 358 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@15b3e79e
18/03/19 07:52:13 DEBUG TaskMemoryManager: Task 358 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7a3ac009
18/03/19 07:52:13 DEBUG TaskMemoryManager: Task 357 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@59e55fa1
18/03/19 07:52:13 DEBUG TaskMemoryManager: Task 357 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@59e55fa1
18/03/19 07:52:13 DEBUG TaskMemoryManager: Task 358 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7a3ac009
18/03/19 07:52:13 DEBUG TaskMemoryManager: Task 358 acquired 21.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7a3ac009
18/03/19 07:52:13 DEBUG TaskMemoryManager: Task 357 acquired 21.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@59e55fa1
18/03/19 07:52:13 DEBUG TaskMemoryManager: Task 358 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@15b3e79e
18/03/19 07:52:13 DEBUG TaskMemoryManager: Task 358 release 36.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@7a3ac009
18/03/19 07:52:13 INFO Executor: Finished task 41.0 in stage 13.0 (TID 358). 1219 bytes result sent to driver
18/03/19 07:52:13 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:13 INFO TaskSetManager: Starting task 42.0 in stage 13.0 (TID 359, localhost, executor driver, partition 42, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:13 INFO TaskSetManager: Finished task 41.0 in stage 13.0 (TID 358) in 2271 ms on localhost (executor driver) (41/96)
18/03/19 07:52:13 INFO Executor: Running task 42.0 in stage 13.0 (TID 359)
18/03/19 07:52:13 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 42-43
18/03/19 07:52:13 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:13 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:13 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  3 ms
18/03/19 07:52:13 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 42-43
18/03/19 07:52:13 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:13 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:13 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:14 DEBUG TaskMemoryManager: Task 357 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@1745972f
18/03/19 07:52:14 DEBUG TaskMemoryManager: Task 357 release 36.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@59e55fa1
18/03/19 07:52:14 INFO Executor: Finished task 40.0 in stage 13.0 (TID 357). 1176 bytes result sent to driver
18/03/19 07:52:14 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:14 INFO TaskSetManager: Starting task 43.0 in stage 13.0 (TID 360, localhost, executor driver, partition 43, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:14 INFO Executor: Running task 43.0 in stage 13.0 (TID 360)
18/03/19 07:52:14 INFO TaskSetManager: Finished task 40.0 in stage 13.0 (TID 357) in 3057 ms on localhost (executor driver) (42/96)
18/03/19 07:52:14 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 43-44
18/03/19 07:52:14 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:14 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:14 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:52:14 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 43-44
18/03/19 07:52:14 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:14 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:14 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:14 DEBUG TaskMemoryManager: Task 359 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@a569a7b
18/03/19 07:52:14 DEBUG TaskMemoryManager: Task 360 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@638e106
18/03/19 07:52:15 DEBUG TaskMemoryManager: Task 359 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@a569a7b
18/03/19 07:52:15 DEBUG TaskMemoryManager: Task 360 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@638e106
18/03/19 07:52:16 DEBUG TaskMemoryManager: Task 359 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1bece74e
18/03/19 07:52:16 DEBUG TaskMemoryManager: Task 360 acquired 5.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@73a6ca4
18/03/19 07:52:16 DEBUG TaskMemoryManager: Task 359 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1bece74e
18/03/19 07:52:16 DEBUG TaskMemoryManager: Task 360 acquired 10.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@73a6ca4
18/03/19 07:52:16 DEBUG TaskMemoryManager: Task 359 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1bece74e
18/03/19 07:52:16 DEBUG TaskMemoryManager: Task 360 acquired 20.8 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@73a6ca4
18/03/19 07:52:16 DEBUG TaskMemoryManager: Task 359 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@a569a7b
18/03/19 07:52:16 DEBUG TaskMemoryManager: Task 360 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@638e106
18/03/19 07:52:16 DEBUG TaskMemoryManager: Task 359 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@1bece74e
18/03/19 07:52:16 INFO Executor: Finished task 42.0 in stage 13.0 (TID 359). 1219 bytes result sent to driver
18/03/19 07:52:16 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:16 INFO TaskSetManager: Starting task 44.0 in stage 13.0 (TID 361, localhost, executor driver, partition 44, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:16 INFO TaskSetManager: Finished task 42.0 in stage 13.0 (TID 359) in 2973 ms on localhost (executor driver) (43/96)
18/03/19 07:52:16 INFO Executor: Running task 44.0 in stage 13.0 (TID 361)
18/03/19 07:52:16 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 44-45
18/03/19 07:52:16 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:16 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:16 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:52:16 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 44-45
18/03/19 07:52:16 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:16 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:16 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:16 DEBUG TaskMemoryManager: Task 360 release 36.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@73a6ca4
18/03/19 07:52:16 INFO Executor: Finished task 43.0 in stage 13.0 (TID 360). 1219 bytes result sent to driver
18/03/19 07:52:16 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:16 INFO TaskSetManager: Starting task 45.0 in stage 13.0 (TID 362, localhost, executor driver, partition 45, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:16 INFO TaskSetManager: Finished task 43.0 in stage 13.0 (TID 360) in 2400 ms on localhost (executor driver) (44/96)
18/03/19 07:52:16 INFO Executor: Running task 45.0 in stage 13.0 (TID 362)
18/03/19 07:52:16 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 45-46
18/03/19 07:52:16 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:16 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:16 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:52:16 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 45-46
18/03/19 07:52:16 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:16 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:16 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:17 DEBUG TaskMemoryManager: Task 361 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@62205864
18/03/19 07:52:17 DEBUG TaskMemoryManager: Task 362 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@253d58e7
18/03/19 07:52:17 DEBUG TaskMemoryManager: Task 361 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@62205864
18/03/19 07:52:17 DEBUG TaskMemoryManager: Task 362 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@253d58e7
18/03/19 07:52:18 TRACE HeartbeatReceiver: Checking for hosts with no recent heartbeats in HeartbeatReceiver.
18/03/19 07:52:19 DEBUG TaskMemoryManager: Task 362 acquired 5.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6a2daeca
18/03/19 07:52:19 DEBUG TaskMemoryManager: Task 361 acquired 5.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@d7bd845
18/03/19 07:52:19 DEBUG TaskMemoryManager: Task 361 acquired 10.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@d7bd845
18/03/19 07:52:19 DEBUG TaskMemoryManager: Task 362 acquired 11.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6a2daeca
18/03/19 07:52:19 DEBUG TaskMemoryManager: Task 361 acquired 20.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@d7bd845
18/03/19 07:52:19 DEBUG TaskMemoryManager: Task 362 acquired 21.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6a2daeca
18/03/19 07:52:19 DEBUG TaskMemoryManager: Task 361 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@62205864
18/03/19 07:52:19 DEBUG TaskMemoryManager: Task 361 release 35.8 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@d7bd845
18/03/19 07:52:19 INFO Executor: Finished task 44.0 in stage 13.0 (TID 361). 1219 bytes result sent to driver
18/03/19 07:52:19 DEBUG TaskMemoryManager: Task 362 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@253d58e7
18/03/19 07:52:19 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:19 INFO TaskSetManager: Starting task 46.0 in stage 13.0 (TID 363, localhost, executor driver, partition 46, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:19 INFO TaskSetManager: Finished task 44.0 in stage 13.0 (TID 361) in 2728 ms on localhost (executor driver) (45/96)
18/03/19 07:52:19 INFO Executor: Running task 46.0 in stage 13.0 (TID 363)
18/03/19 07:52:19 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 46-47
18/03/19 07:52:19 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:19 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:19 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:52:19 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 46-47
18/03/19 07:52:19 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:19 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:19 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:19 DEBUG TaskMemoryManager: Task 362 release 37.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@6a2daeca
18/03/19 07:52:19 INFO Executor: Finished task 45.0 in stage 13.0 (TID 362). 1219 bytes result sent to driver
18/03/19 07:52:19 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:19 INFO TaskSetManager: Starting task 47.0 in stage 13.0 (TID 364, localhost, executor driver, partition 47, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:19 INFO TaskSetManager: Finished task 45.0 in stage 13.0 (TID 362) in 2731 ms on localhost (executor driver) (46/96)
18/03/19 07:52:19 INFO Executor: Running task 47.0 in stage 13.0 (TID 364)
18/03/19 07:52:19 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 47-48
18/03/19 07:52:19 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:19 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:19 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:52:19 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 47-48
18/03/19 07:52:19 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:19 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:19 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:52:19 DEBUG TaskMemoryManager: Task 363 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@119736cb
18/03/19 07:52:20 DEBUG TaskMemoryManager: Task 364 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@26297197
18/03/19 07:52:20 DEBUG TaskMemoryManager: Task 363 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@119736cb
18/03/19 07:52:20 DEBUG TaskMemoryManager: Task 364 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@26297197
18/03/19 07:52:21 DEBUG TaskMemoryManager: Task 363 acquired 5.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@45a6d944
18/03/19 07:52:21 DEBUG TaskMemoryManager: Task 363 acquired 10.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@45a6d944
18/03/19 07:52:21 DEBUG TaskMemoryManager: Task 364 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2c3d1687
18/03/19 07:52:21 DEBUG TaskMemoryManager: Task 363 acquired 20.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@45a6d944
18/03/19 07:52:21 DEBUG TaskMemoryManager: Task 364 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2c3d1687
18/03/19 07:52:22 DEBUG TaskMemoryManager: Task 363 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@119736cb
18/03/19 07:52:22 DEBUG TaskMemoryManager: Task 363 release 36.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@45a6d944
18/03/19 07:52:22 INFO Executor: Finished task 46.0 in stage 13.0 (TID 363). 1219 bytes result sent to driver
18/03/19 07:52:22 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:22 INFO TaskSetManager: Starting task 48.0 in stage 13.0 (TID 365, localhost, executor driver, partition 48, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:22 INFO Executor: Running task 48.0 in stage 13.0 (TID 365)
18/03/19 07:52:22 INFO TaskSetManager: Finished task 46.0 in stage 13.0 (TID 363) in 2573 ms on localhost (executor driver) (47/96)
18/03/19 07:52:22 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 48-49
18/03/19 07:52:22 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:22 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:22 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:52:22 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 48-49
18/03/19 07:52:22 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:22 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:22 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:22 DEBUG TaskMemoryManager: Task 364 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2c3d1687
18/03/19 07:52:22 DEBUG TaskMemoryManager: Task 364 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@26297197
18/03/19 07:52:22 DEBUG TaskMemoryManager: Task 364 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2c3d1687
18/03/19 07:52:22 INFO Executor: Finished task 47.0 in stage 13.0 (TID 364). 1219 bytes result sent to driver
18/03/19 07:52:22 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:22 INFO TaskSetManager: Starting task 49.0 in stage 13.0 (TID 366, localhost, executor driver, partition 49, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:22 INFO Executor: Running task 49.0 in stage 13.0 (TID 366)
18/03/19 07:52:22 INFO TaskSetManager: Finished task 47.0 in stage 13.0 (TID 364) in 2954 ms on localhost (executor driver) (48/96)
18/03/19 07:52:22 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 49-50
18/03/19 07:52:22 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:22 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:22 DEBUG TaskMemoryManager: Task 365 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3f807a8c
18/03/19 07:52:22 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  53 ms
18/03/19 07:52:22 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 49-50
18/03/19 07:52:22 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:22 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:22 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:22 DEBUG TaskMemoryManager: Task 366 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@56a41e73
18/03/19 07:52:23 DEBUG TaskMemoryManager: Task 365 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3f807a8c
18/03/19 07:52:23 DEBUG TaskMemoryManager: Task 366 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@56a41e73
18/03/19 07:52:23 DEBUG TaskMemoryManager: Task 366 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@56a41e73
18/03/19 07:52:24 DEBUG TaskMemoryManager: Task 365 acquired 5.8 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@154328ed
18/03/19 07:52:24 DEBUG TaskMemoryManager: Task 365 acquired 11.8 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@154328ed
18/03/19 07:52:24 DEBUG TaskMemoryManager: Task 366 acquired 5.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@430bf61b
18/03/19 07:52:24 DEBUG TaskMemoryManager: Task 365 acquired 22.7 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@154328ed
18/03/19 07:52:24 DEBUG TaskMemoryManager: Task 366 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@430bf61b
18/03/19 07:52:24 DEBUG TaskMemoryManager: Task 366 acquired 20.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@430bf61b
18/03/19 07:52:25 DEBUG TaskMemoryManager: Task 365 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3f807a8c
18/03/19 07:52:25 DEBUG TaskMemoryManager: Task 365 release 40.3 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@154328ed
18/03/19 07:52:25 INFO Executor: Finished task 48.0 in stage 13.0 (TID 365). 1219 bytes result sent to driver
18/03/19 07:52:25 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:25 INFO TaskSetManager: Starting task 50.0 in stage 13.0 (TID 367, localhost, executor driver, partition 50, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:25 INFO TaskSetManager: Finished task 48.0 in stage 13.0 (TID 365) in 3060 ms on localhost (executor driver) (49/96)
18/03/19 07:52:25 INFO Executor: Running task 50.0 in stage 13.0 (TID 367)
18/03/19 07:52:25 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 50-51
18/03/19 07:52:25 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:25 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:25 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:52:25 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 50-51
18/03/19 07:52:25 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:25 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:25 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:25 DEBUG TaskMemoryManager: Task 366 acquired 41.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@430bf61b
18/03/19 07:52:25 DEBUG TaskMemoryManager: Task 367 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2f16a6da
18/03/19 07:52:25 DEBUG TaskMemoryManager: Task 366 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@56a41e73
18/03/19 07:52:25 DEBUG TaskMemoryManager: Task 366 release 76.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@430bf61b
18/03/19 07:52:25 INFO Executor: Finished task 49.0 in stage 13.0 (TID 366). 1219 bytes result sent to driver
18/03/19 07:52:25 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:25 INFO TaskSetManager: Starting task 51.0 in stage 13.0 (TID 368, localhost, executor driver, partition 51, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:25 INFO TaskSetManager: Finished task 49.0 in stage 13.0 (TID 366) in 3026 ms on localhost (executor driver) (50/96)
18/03/19 07:52:25 INFO Executor: Running task 51.0 in stage 13.0 (TID 368)
18/03/19 07:52:25 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 51-52
18/03/19 07:52:25 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:25 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:25 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  3 ms
18/03/19 07:52:25 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 51-52
18/03/19 07:52:25 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:25 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:25 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:25 DEBUG TaskMemoryManager: Task 368 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2aa7dad6
18/03/19 07:52:25 DEBUG TaskMemoryManager: Task 367 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2f16a6da
18/03/19 07:52:26 DEBUG TaskMemoryManager: Task 368 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2aa7dad6
18/03/19 07:52:27 DEBUG TaskMemoryManager: Task 368 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2aa7dad6
18/03/19 07:52:27 DEBUG TaskMemoryManager: Task 367 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2b21e09b
18/03/19 07:52:27 DEBUG TaskMemoryManager: Task 367 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2b21e09b
18/03/19 07:52:27 DEBUG TaskMemoryManager: Task 367 acquired 20.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2b21e09b
18/03/19 07:52:28 DEBUG TaskMemoryManager: Task 368 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7ee37811
18/03/19 07:52:28 DEBUG TaskMemoryManager: Task 368 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7ee37811
18/03/19 07:52:28 DEBUG TaskMemoryManager: Task 367 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2f16a6da
18/03/19 07:52:28 DEBUG TaskMemoryManager: Task 367 release 35.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2b21e09b
18/03/19 07:52:28 INFO Executor: Finished task 50.0 in stage 13.0 (TID 367). 1219 bytes result sent to driver
18/03/19 07:52:28 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:28 INFO TaskSetManager: Starting task 52.0 in stage 13.0 (TID 369, localhost, executor driver, partition 52, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:28 INFO TaskSetManager: Finished task 50.0 in stage 13.0 (TID 367) in 3211 ms on localhost (executor driver) (51/96)
18/03/19 07:52:28 INFO Executor: Running task 52.0 in stage 13.0 (TID 369)
18/03/19 07:52:28 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 52-53
18/03/19 07:52:28 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:28 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:28 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:52:28 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 52-53
18/03/19 07:52:28 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:28 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:28 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:52:28 DEBUG TaskMemoryManager: Task 368 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7ee37811
18/03/19 07:52:28 DEBUG TaskMemoryManager: Task 369 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@161e65fa
18/03/19 07:52:28 DEBUG TaskMemoryManager: Task 368 acquired 43.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7ee37811
18/03/19 07:52:29 DEBUG TaskMemoryManager: Task 368 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2aa7dad6
18/03/19 07:52:29 DEBUG TaskMemoryManager: Task 368 release 78.4 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@7ee37811
18/03/19 07:52:29 INFO Executor: Finished task 51.0 in stage 13.0 (TID 368). 1219 bytes result sent to driver
18/03/19 07:52:29 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:29 INFO TaskSetManager: Starting task 53.0 in stage 13.0 (TID 370, localhost, executor driver, partition 53, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:29 INFO Executor: Running task 53.0 in stage 13.0 (TID 370)
18/03/19 07:52:29 INFO TaskSetManager: Finished task 51.0 in stage 13.0 (TID 368) in 3565 ms on localhost (executor driver) (52/96)
18/03/19 07:52:29 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 53-54
18/03/19 07:52:29 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:29 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:29 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:52:29 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 53-54
18/03/19 07:52:29 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:29 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:29 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:29 DEBUG TaskMemoryManager: Task 369 acquired 10.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@161e65fa
18/03/19 07:52:29 DEBUG TaskMemoryManager: Task 370 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@67793f48
18/03/19 07:52:29 DEBUG TaskMemoryManager: Task 370 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@67793f48
18/03/19 07:52:30 DEBUG TaskMemoryManager: Task 369 acquired 20.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@161e65fa
18/03/19 07:52:31 DEBUG TaskMemoryManager: Task 370 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@67793f48
18/03/19 07:52:31 DEBUG TaskMemoryManager: Task 369 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@960496d
18/03/19 07:52:31 DEBUG TaskMemoryManager: Task 369 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@960496d
18/03/19 07:52:31 DEBUG TaskMemoryManager: Task 369 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@960496d
18/03/19 07:52:31 DEBUG TaskMemoryManager: Task 369 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@960496d
18/03/19 07:52:32 DEBUG TaskMemoryManager: Task 369 release 35.7 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@161e65fa
18/03/19 07:52:32 DEBUG TaskMemoryManager: Task 369 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@960496d
18/03/19 07:52:32 INFO Executor: Finished task 52.0 in stage 13.0 (TID 369). 1219 bytes result sent to driver
18/03/19 07:52:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:32 INFO TaskSetManager: Starting task 54.0 in stage 13.0 (TID 371, localhost, executor driver, partition 54, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:32 INFO Executor: Running task 54.0 in stage 13.0 (TID 371)
18/03/19 07:52:32 INFO TaskSetManager: Finished task 52.0 in stage 13.0 (TID 369) in 3687 ms on localhost (executor driver) (53/96)
18/03/19 07:52:32 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 54-55
18/03/19 07:52:32 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:32 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:32 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:52:32 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 54-55
18/03/19 07:52:32 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:32 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:32 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:32 DEBUG TaskMemoryManager: Task 370 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6b299984
18/03/19 07:52:32 DEBUG TaskMemoryManager: Task 371 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5ebcf19d
18/03/19 07:52:32 DEBUG TaskMemoryManager: Task 370 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6b299984
18/03/19 07:52:32 DEBUG TaskMemoryManager: Task 370 acquired 20.9 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6b299984
18/03/19 07:52:32 DEBUG TaskMemoryManager: Task 371 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5ebcf19d
18/03/19 07:52:32 DEBUG TaskMemoryManager: Task 370 acquired 40.9 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6b299984
18/03/19 07:52:33 DEBUG TaskMemoryManager: Task 370 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@67793f48
18/03/19 07:52:33 DEBUG TaskMemoryManager: Task 370 release 76.9 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@6b299984
18/03/19 07:52:33 INFO Executor: Finished task 53.0 in stage 13.0 (TID 370). 1176 bytes result sent to driver
18/03/19 07:52:33 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:33 INFO TaskSetManager: Starting task 55.0 in stage 13.0 (TID 372, localhost, executor driver, partition 55, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:33 INFO TaskSetManager: Finished task 53.0 in stage 13.0 (TID 370) in 4068 ms on localhost (executor driver) (54/96)
18/03/19 07:52:33 INFO Executor: Running task 55.0 in stage 13.0 (TID 372)
18/03/19 07:52:33 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 55-56
18/03/19 07:52:33 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:33 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:33 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:52:33 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 55-56
18/03/19 07:52:33 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:33 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:33 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:33 DEBUG TaskMemoryManager: Task 372 acquired 5.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4b228e7d
18/03/19 07:52:33 DEBUG TaskMemoryManager: Task 371 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5ebcf19d
18/03/19 07:52:33 DEBUG TaskMemoryManager: Task 372 acquired 10.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4b228e7d
18/03/19 07:52:34 DEBUG TaskMemoryManager: Task 371 acquired 5.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@374ab4b2
18/03/19 07:52:34 DEBUG TaskMemoryManager: Task 372 acquired 20.7 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4b228e7d
18/03/19 07:52:34 DEBUG TaskMemoryManager: Task 371 acquired 10.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@374ab4b2
18/03/19 07:52:35 DEBUG TaskMemoryManager: Task 371 acquired 20.7 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@374ab4b2
18/03/19 07:52:35 DEBUG TaskMemoryManager: Task 371 acquired 41.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@374ab4b2
18/03/19 07:52:35 DEBUG TaskMemoryManager: Task 371 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5ebcf19d
18/03/19 07:52:35 DEBUG TaskMemoryManager: Task 371 release 77.8 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@374ab4b2
18/03/19 07:52:35 INFO Executor: Finished task 54.0 in stage 13.0 (TID 371). 1219 bytes result sent to driver
18/03/19 07:52:35 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:35 INFO TaskSetManager: Starting task 56.0 in stage 13.0 (TID 373, localhost, executor driver, partition 56, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:35 INFO TaskSetManager: Finished task 54.0 in stage 13.0 (TID 371) in 3425 ms on localhost (executor driver) (55/96)
18/03/19 07:52:35 INFO Executor: Running task 56.0 in stage 13.0 (TID 373)
18/03/19 07:52:35 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 56-57
18/03/19 07:52:35 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:35 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:35 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:52:35 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 56-57
18/03/19 07:52:35 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:35 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:35 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:35 DEBUG TaskMemoryManager: Task 373 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2c96c2c0
18/03/19 07:52:36 DEBUG TaskMemoryManager: Task 372 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@69eea4c4
18/03/19 07:52:36 DEBUG TaskMemoryManager: Task 372 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@69eea4c4
18/03/19 07:52:36 DEBUG TaskMemoryManager: Task 373 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2c96c2c0
18/03/19 07:52:36 DEBUG TaskMemoryManager: Task 372 acquired 20.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@69eea4c4
18/03/19 07:52:36 DEBUG TaskMemoryManager: Task 372 acquired 40.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@69eea4c4
18/03/19 07:52:36 DEBUG TaskMemoryManager: Task 372 release 36.5 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@4b228e7d
18/03/19 07:52:37 DEBUG TaskMemoryManager: Task 372 release 75.5 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@69eea4c4
18/03/19 07:52:37 INFO Executor: Finished task 55.0 in stage 13.0 (TID 372). 1219 bytes result sent to driver
18/03/19 07:52:37 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:37 INFO TaskSetManager: Starting task 57.0 in stage 13.0 (TID 374, localhost, executor driver, partition 57, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:37 INFO Executor: Running task 57.0 in stage 13.0 (TID 374)
18/03/19 07:52:37 INFO TaskSetManager: Finished task 55.0 in stage 13.0 (TID 372) in 3834 ms on localhost (executor driver) (56/96)
18/03/19 07:52:37 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 57-58
18/03/19 07:52:37 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:37 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:37 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  3 ms
18/03/19 07:52:37 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 57-58
18/03/19 07:52:37 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:37 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:37 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:37 DEBUG TaskMemoryManager: Task 374 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3e73a060
18/03/19 07:52:37 DEBUG TaskMemoryManager: Task 373 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2c96c2c0
18/03/19 07:52:37 DEBUG TaskMemoryManager: Task 374 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3e73a060
18/03/19 07:52:38 DEBUG TaskMemoryManager: Task 373 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2599cf8b
18/03/19 07:52:38 DEBUG TaskMemoryManager: Task 373 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2599cf8b
18/03/19 07:52:38 DEBUG TaskMemoryManager: Task 373 acquired 20.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2599cf8b
18/03/19 07:52:38 DEBUG TaskMemoryManager: Task 374 acquired 20.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3e73a060
18/03/19 07:52:39 DEBUG TaskMemoryManager: Task 373 acquired 40.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2599cf8b
18/03/19 07:52:39 DEBUG TaskMemoryManager: Task 373 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2c96c2c0
18/03/19 07:52:39 DEBUG TaskMemoryManager: Task 373 release 75.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2599cf8b
18/03/19 07:52:39 INFO Executor: Finished task 56.0 in stage 13.0 (TID 373). 1176 bytes result sent to driver
18/03/19 07:52:39 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:39 INFO TaskSetManager: Starting task 58.0 in stage 13.0 (TID 375, localhost, executor driver, partition 58, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:39 INFO Executor: Running task 58.0 in stage 13.0 (TID 375)
18/03/19 07:52:39 INFO TaskSetManager: Finished task 56.0 in stage 13.0 (TID 373) in 3885 ms on localhost (executor driver) (57/96)
18/03/19 07:52:39 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 58-59
18/03/19 07:52:39 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:39 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:39 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:52:39 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 58-59
18/03/19 07:52:39 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:39 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:39 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:39 DEBUG TaskMemoryManager: Task 375 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4a4680d7
18/03/19 07:52:40 DEBUG TaskMemoryManager: Task 375 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4a4680d7
18/03/19 07:52:40 DEBUG TaskMemoryManager: Task 374 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2fc85b1e
18/03/19 07:52:40 DEBUG TaskMemoryManager: Task 374 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2fc85b1e
18/03/19 07:52:41 DEBUG TaskMemoryManager: Task 374 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2fc85b1e
18/03/19 07:52:41 DEBUG TaskMemoryManager: Task 375 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4a4680d7
18/03/19 07:52:41 DEBUG TaskMemoryManager: Task 374 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2fc85b1e
18/03/19 07:52:41 DEBUG TaskMemoryManager: Task 374 release 35.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3e73a060
18/03/19 07:52:41 DEBUG TaskMemoryManager: Task 374 release 75.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2fc85b1e
18/03/19 07:52:41 INFO Executor: Finished task 57.0 in stage 13.0 (TID 374). 1219 bytes result sent to driver
18/03/19 07:52:41 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:41 INFO TaskSetManager: Starting task 59.0 in stage 13.0 (TID 376, localhost, executor driver, partition 59, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:41 INFO Executor: Running task 59.0 in stage 13.0 (TID 376)
18/03/19 07:52:41 INFO TaskSetManager: Finished task 57.0 in stage 13.0 (TID 374) in 4741 ms on localhost (executor driver) (58/96)
18/03/19 07:52:41 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 59-60
18/03/19 07:52:41 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:41 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:41 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:52:41 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 59-60
18/03/19 07:52:41 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:41 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:41 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:42 DEBUG TaskMemoryManager: Task 376 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7c75761b
18/03/19 07:52:42 DEBUG TaskMemoryManager: Task 376 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7c75761b
18/03/19 07:52:43 DEBUG TaskMemoryManager: Task 375 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@27cc33bc
18/03/19 07:52:43 DEBUG TaskMemoryManager: Task 375 acquired 10.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@27cc33bc
18/03/19 07:52:43 DEBUG TaskMemoryManager: Task 375 acquired 20.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@27cc33bc
18/03/19 07:52:43 DEBUG TaskMemoryManager: Task 375 acquired 41.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@27cc33bc
18/03/19 07:52:43 DEBUG TaskMemoryManager: Task 376 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7c75761b
18/03/19 07:52:44 DEBUG TaskMemoryManager: Task 375 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@4a4680d7
18/03/19 07:52:44 DEBUG TaskMemoryManager: Task 375 release 77.3 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@27cc33bc
18/03/19 07:52:44 INFO Executor: Finished task 58.0 in stage 13.0 (TID 375). 1176 bytes result sent to driver
18/03/19 07:52:44 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:44 INFO TaskSetManager: Starting task 60.0 in stage 13.0 (TID 377, localhost, executor driver, partition 60, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:44 INFO TaskSetManager: Finished task 58.0 in stage 13.0 (TID 375) in 4742 ms on localhost (executor driver) (59/96)
18/03/19 07:52:44 INFO Executor: Running task 60.0 in stage 13.0 (TID 377)
18/03/19 07:52:44 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 60-61
18/03/19 07:52:44 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:44 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:52:44 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:52:44 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 60-61
18/03/19 07:52:44 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:44 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:44 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:44 DEBUG TaskMemoryManager: Task 377 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6a60f6a7
18/03/19 07:52:44 DEBUG TaskMemoryManager: Task 377 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6a60f6a7
18/03/19 07:52:45 DEBUG TaskMemoryManager: Task 376 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@46ff1ddc
18/03/19 07:52:45 DEBUG TaskMemoryManager: Task 376 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@46ff1ddc
18/03/19 07:52:45 DEBUG TaskMemoryManager: Task 376 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@46ff1ddc
18/03/19 07:52:45 DEBUG TaskMemoryManager: Task 377 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6a60f6a7
18/03/19 07:52:45 DEBUG TaskMemoryManager: Task 376 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@46ff1ddc
18/03/19 07:52:46 DEBUG TaskMemoryManager: Task 376 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@7c75761b
18/03/19 07:52:46 DEBUG TaskMemoryManager: Task 376 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@46ff1ddc
18/03/19 07:52:46 INFO Executor: Finished task 59.0 in stage 13.0 (TID 376). 1219 bytes result sent to driver
18/03/19 07:52:46 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:46 INFO TaskSetManager: Starting task 61.0 in stage 13.0 (TID 378, localhost, executor driver, partition 61, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:46 INFO Executor: Running task 61.0 in stage 13.0 (TID 378)
18/03/19 07:52:46 INFO TaskSetManager: Finished task 59.0 in stage 13.0 (TID 376) in 4442 ms on localhost (executor driver) (60/96)
18/03/19 07:52:46 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 61-62
18/03/19 07:52:46 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:46 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:52:46 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:52:46 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 61-62
18/03/19 07:52:46 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:46 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:46 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:46 DEBUG TaskMemoryManager: Task 378 acquired 5.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4e3b6f1b
18/03/19 07:52:46 DEBUG TaskMemoryManager: Task 378 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4e3b6f1b
18/03/19 07:52:47 DEBUG TaskMemoryManager: Task 377 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6ab8eb89
18/03/19 07:52:47 DEBUG TaskMemoryManager: Task 377 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6ab8eb89
18/03/19 07:52:47 DEBUG TaskMemoryManager: Task 377 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6ab8eb89
18/03/19 07:52:47 DEBUG TaskMemoryManager: Task 378 acquired 20.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4e3b6f1b
18/03/19 07:52:48 DEBUG TaskMemoryManager: Task 377 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6ab8eb89
18/03/19 07:52:48 DEBUG TaskMemoryManager: Task 377 release 35.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@6a60f6a7
18/03/19 07:52:48 DEBUG TaskMemoryManager: Task 377 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@6ab8eb89
18/03/19 07:52:48 INFO Executor: Finished task 60.0 in stage 13.0 (TID 377). 1176 bytes result sent to driver
18/03/19 07:52:48 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:48 INFO TaskSetManager: Starting task 62.0 in stage 13.0 (TID 379, localhost, executor driver, partition 62, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:48 INFO TaskSetManager: Finished task 60.0 in stage 13.0 (TID 377) in 4112 ms on localhost (executor driver) (61/96)
18/03/19 07:52:48 INFO Executor: Running task 62.0 in stage 13.0 (TID 379)
18/03/19 07:52:48 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 62-63
18/03/19 07:52:48 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:48 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:52:48 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  3 ms
18/03/19 07:52:48 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 62-63
18/03/19 07:52:48 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:48 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:48 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:48 DEBUG TaskMemoryManager: Task 379 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2947820
18/03/19 07:52:48 DEBUG TaskMemoryManager: Task 379 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2947820
18/03/19 07:52:49 DEBUG TaskMemoryManager: Task 378 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@47aebbfa
18/03/19 07:52:49 DEBUG TaskMemoryManager: Task 378 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@47aebbfa
18/03/19 07:52:49 DEBUG TaskMemoryManager: Task 378 acquired 20.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@47aebbfa
18/03/19 07:52:49 DEBUG TaskMemoryManager: Task 379 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2947820
18/03/19 07:52:49 DEBUG TaskMemoryManager: Task 378 acquired 40.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@47aebbfa
18/03/19 07:52:50 DEBUG TaskMemoryManager: Task 378 release 35.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@4e3b6f1b
18/03/19 07:52:50 DEBUG TaskMemoryManager: Task 378 release 75.3 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@47aebbfa
18/03/19 07:52:50 INFO Executor: Finished task 61.0 in stage 13.0 (TID 378). 1176 bytes result sent to driver
18/03/19 07:52:50 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:50 INFO TaskSetManager: Starting task 63.0 in stage 13.0 (TID 380, localhost, executor driver, partition 63, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:50 INFO TaskSetManager: Finished task 61.0 in stage 13.0 (TID 378) in 3893 ms on localhost (executor driver) (62/96)
18/03/19 07:52:50 INFO Executor: Running task 63.0 in stage 13.0 (TID 380)
18/03/19 07:52:50 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 63-64
18/03/19 07:52:50 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:50 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:50 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:52:50 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 63-64
18/03/19 07:52:50 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:50 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:50 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:50 DEBUG TaskMemoryManager: Task 380 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7627953c
18/03/19 07:52:50 DEBUG TaskMemoryManager: Task 380 acquired 10.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7627953c
18/03/19 07:52:51 DEBUG TaskMemoryManager: Task 379 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@29b15bc2
18/03/19 07:52:51 DEBUG TaskMemoryManager: Task 379 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@29b15bc2
18/03/19 07:52:51 DEBUG TaskMemoryManager: Task 379 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@29b15bc2
18/03/19 07:52:51 DEBUG TaskMemoryManager: Task 380 acquired 20.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7627953c
18/03/19 07:52:51 DEBUG TaskMemoryManager: Task 379 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@29b15bc2
18/03/19 07:52:52 DEBUG TaskMemoryManager: Task 379 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2947820
18/03/19 07:52:52 DEBUG TaskMemoryManager: Task 379 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@29b15bc2
18/03/19 07:52:52 INFO Executor: Finished task 62.0 in stage 13.0 (TID 379). 1219 bytes result sent to driver
18/03/19 07:52:52 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:52 INFO TaskSetManager: Starting task 64.0 in stage 13.0 (TID 381, localhost, executor driver, partition 64, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:52 INFO Executor: Running task 64.0 in stage 13.0 (TID 381)
18/03/19 07:52:52 INFO TaskSetManager: Finished task 62.0 in stage 13.0 (TID 379) in 3903 ms on localhost (executor driver) (63/96)
18/03/19 07:52:52 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 64-65
18/03/19 07:52:52 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:52 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:52 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:52:52 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 64-65
18/03/19 07:52:52 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:52 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:52:52 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:52:52 DEBUG TaskMemoryManager: Task 381 acquired 5.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6d11b49c
18/03/19 07:52:52 DEBUG TaskMemoryManager: Task 381 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6d11b49c
18/03/19 07:52:53 DEBUG TaskMemoryManager: Task 380 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@99ea954
18/03/19 07:52:54 DEBUG TaskMemoryManager: Task 380 acquired 10.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@99ea954
18/03/19 07:52:54 DEBUG TaskMemoryManager: Task 381 acquired 20.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6d11b49c
18/03/19 07:52:54 DEBUG TaskMemoryManager: Task 380 acquired 20.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@99ea954
18/03/19 07:52:54 DEBUG TaskMemoryManager: Task 380 acquired 40.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@99ea954
18/03/19 07:52:54 DEBUG TaskMemoryManager: Task 380 release 35.7 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@7627953c
18/03/19 07:52:54 DEBUG TaskMemoryManager: Task 380 release 75.7 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@99ea954
18/03/19 07:52:54 INFO Executor: Finished task 63.0 in stage 13.0 (TID 380). 1219 bytes result sent to driver
18/03/19 07:52:54 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:54 INFO TaskSetManager: Starting task 65.0 in stage 13.0 (TID 382, localhost, executor driver, partition 65, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:54 INFO TaskSetManager: Finished task 63.0 in stage 13.0 (TID 380) in 4729 ms on localhost (executor driver) (64/96)
18/03/19 07:52:54 INFO Executor: Running task 65.0 in stage 13.0 (TID 382)
18/03/19 07:52:54 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 65-66
18/03/19 07:52:54 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:54 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:54 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:52:54 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 65-66
18/03/19 07:52:54 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:54 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:52:54 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:52:55 DEBUG TaskMemoryManager: Task 382 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@47d2021d
18/03/19 07:52:55 DEBUG TaskMemoryManager: Task 381 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@a288225
18/03/19 07:52:55 DEBUG TaskMemoryManager: Task 381 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@a288225
18/03/19 07:52:55 DEBUG TaskMemoryManager: Task 381 acquired 21.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@a288225
18/03/19 07:52:55 DEBUG TaskMemoryManager: Task 382 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@47d2021d
18/03/19 07:52:56 DEBUG TaskMemoryManager: Task 381 acquired 41.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@a288225
18/03/19 07:52:56 DEBUG TaskMemoryManager: Task 381 release 35.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@6d11b49c
18/03/19 07:52:56 DEBUG TaskMemoryManager: Task 381 release 78.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@a288225
18/03/19 07:52:56 INFO Executor: Finished task 64.0 in stage 13.0 (TID 381). 1219 bytes result sent to driver
18/03/19 07:52:56 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:56 INFO TaskSetManager: Starting task 66.0 in stage 13.0 (TID 383, localhost, executor driver, partition 66, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:56 INFO Executor: Running task 66.0 in stage 13.0 (TID 383)
18/03/19 07:52:56 INFO TaskSetManager: Finished task 64.0 in stage 13.0 (TID 381) in 4332 ms on localhost (executor driver) (65/96)
18/03/19 07:52:56 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 66-67
18/03/19 07:52:56 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:56 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:52:56 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:52:56 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 66-67
18/03/19 07:52:56 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:56 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:56 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:56 DEBUG TaskMemoryManager: Task 383 acquired 5.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@f07ba39
18/03/19 07:52:57 DEBUG TaskMemoryManager: Task 383 acquired 10.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@f07ba39
18/03/19 07:52:57 DEBUG TaskMemoryManager: Task 382 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@47d2021d
18/03/19 07:52:57 DEBUG TaskMemoryManager: Task 383 acquired 20.9 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@f07ba39
18/03/19 07:52:58 DEBUG TaskMemoryManager: Task 382 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4db096c7
18/03/19 07:52:58 DEBUG TaskMemoryManager: Task 382 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4db096c7
18/03/19 07:52:58 DEBUG TaskMemoryManager: Task 382 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4db096c7
18/03/19 07:52:58 DEBUG TaskMemoryManager: Task 382 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4db096c7
18/03/19 07:52:58 DEBUG TaskMemoryManager: Task 382 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@47d2021d
18/03/19 07:52:58 DEBUG TaskMemoryManager: Task 382 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@4db096c7
18/03/19 07:52:58 INFO Executor: Finished task 65.0 in stage 13.0 (TID 382). 1176 bytes result sent to driver
18/03/19 07:52:58 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:52:58 INFO TaskSetManager: Starting task 67.0 in stage 13.0 (TID 384, localhost, executor driver, partition 67, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:52:58 INFO Executor: Running task 67.0 in stage 13.0 (TID 384)
18/03/19 07:52:58 INFO TaskSetManager: Finished task 65.0 in stage 13.0 (TID 382) in 4174 ms on localhost (executor driver) (66/96)
18/03/19 07:52:58 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 67-68
18/03/19 07:52:58 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:58 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:52:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:58 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:52:58 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 67-68
18/03/19 07:52:58 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:52:58 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:52:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:52:58 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:52:59 DEBUG TaskMemoryManager: Task 383 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6b11f762
18/03/19 07:52:59 DEBUG TaskMemoryManager: Task 384 acquired 5.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@140d6d72
18/03/19 07:52:59 DEBUG TaskMemoryManager: Task 383 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6b11f762
18/03/19 07:52:59 DEBUG TaskMemoryManager: Task 383 acquired 20.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6b11f762
18/03/19 07:52:59 DEBUG TaskMemoryManager: Task 384 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@140d6d72
18/03/19 07:53:00 DEBUG TaskMemoryManager: Task 383 acquired 40.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6b11f762
18/03/19 07:53:00 DEBUG TaskMemoryManager: Task 383 release 36.3 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@f07ba39
18/03/19 07:53:00 DEBUG TaskMemoryManager: Task 383 release 76.3 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@6b11f762
18/03/19 07:53:00 INFO Executor: Finished task 66.0 in stage 13.0 (TID 383). 1176 bytes result sent to driver
18/03/19 07:53:00 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:00 INFO TaskSetManager: Starting task 68.0 in stage 13.0 (TID 385, localhost, executor driver, partition 68, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:00 INFO Executor: Running task 68.0 in stage 13.0 (TID 385)
18/03/19 07:53:00 INFO TaskSetManager: Finished task 66.0 in stage 13.0 (TID 383) in 3717 ms on localhost (executor driver) (67/96)
18/03/19 07:53:00 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 68-69
18/03/19 07:53:00 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:00 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:00 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:00 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 68-69
18/03/19 07:53:00 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:00 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:00 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:53:00 DEBUG TaskMemoryManager: Task 385 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7c49e504
18/03/19 07:53:00 DEBUG TaskMemoryManager: Task 384 acquired 20.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@140d6d72
18/03/19 07:53:00 DEBUG TaskMemoryManager: Task 385 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7c49e504
18/03/19 07:53:01 DEBUG TaskMemoryManager: Task 384 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6f3d404e
18/03/19 07:53:01 DEBUG TaskMemoryManager: Task 385 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7c49e504
18/03/19 07:53:01 DEBUG TaskMemoryManager: Task 384 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6f3d404e
18/03/19 07:53:01 DEBUG TaskMemoryManager: Task 384 acquired 20.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6f3d404e
18/03/19 07:53:02 DEBUG TaskMemoryManager: Task 384 acquired 42.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6f3d404e
18/03/19 07:53:02 DEBUG TaskMemoryManager: Task 384 release 35.7 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@140d6d72
18/03/19 07:53:02 DEBUG TaskMemoryManager: Task 384 release 77.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@6f3d404e
18/03/19 07:53:02 INFO Executor: Finished task 67.0 in stage 13.0 (TID 384). 1176 bytes result sent to driver
18/03/19 07:53:02 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:02 INFO TaskSetManager: Starting task 69.0 in stage 13.0 (TID 386, localhost, executor driver, partition 69, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:02 INFO Executor: Running task 69.0 in stage 13.0 (TID 386)
18/03/19 07:53:02 INFO TaskSetManager: Finished task 67.0 in stage 13.0 (TID 384) in 3326 ms on localhost (executor driver) (68/96)
18/03/19 07:53:02 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 69-70
18/03/19 07:53:02 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:02 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:02 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:02 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 69-70
18/03/19 07:53:02 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:02 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:02 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:53:02 DEBUG TaskMemoryManager: Task 385 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@377d49b3
18/03/19 07:53:02 DEBUG TaskMemoryManager: Task 386 acquired 5.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@68d63fa3
18/03/19 07:53:02 DEBUG TaskMemoryManager: Task 385 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@377d49b3
18/03/19 07:53:02 DEBUG TaskMemoryManager: Task 385 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@377d49b3
18/03/19 07:53:03 DEBUG TaskMemoryManager: Task 385 acquired 42.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@377d49b3
18/03/19 07:53:03 DEBUG TaskMemoryManager: Task 386 acquired 10.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@68d63fa3
18/03/19 07:53:03 DEBUG TaskMemoryManager: Task 385 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@7c49e504
18/03/19 07:53:03 DEBUG TaskMemoryManager: Task 385 release 77.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@377d49b3
18/03/19 07:53:03 INFO Executor: Finished task 68.0 in stage 13.0 (TID 385). 1219 bytes result sent to driver
18/03/19 07:53:03 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:03 INFO TaskSetManager: Starting task 70.0 in stage 13.0 (TID 387, localhost, executor driver, partition 70, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:03 INFO Executor: Running task 70.0 in stage 13.0 (TID 387)
18/03/19 07:53:03 INFO TaskSetManager: Finished task 68.0 in stage 13.0 (TID 385) in 3124 ms on localhost (executor driver) (69/96)
18/03/19 07:53:03 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 70-71
18/03/19 07:53:03 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:03 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:03 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:03 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 70-71
18/03/19 07:53:03 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:03 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:53:03 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:03 DEBUG TaskMemoryManager: Task 387 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7bbf80b6
18/03/19 07:53:04 DEBUG TaskMemoryManager: Task 387 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7bbf80b6
18/03/19 07:53:04 DEBUG TaskMemoryManager: Task 387 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7bbf80b6
18/03/19 07:53:04 DEBUG TaskMemoryManager: Task 386 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@24f31aab
18/03/19 07:53:05 DEBUG TaskMemoryManager: Task 386 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@24f31aab
18/03/19 07:53:05 DEBUG TaskMemoryManager: Task 386 acquired 20.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@24f31aab
18/03/19 07:53:05 DEBUG TaskMemoryManager: Task 387 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6936a1d1
18/03/19 07:53:05 DEBUG TaskMemoryManager: Task 386 release 15.5 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@68d63fa3
18/03/19 07:53:05 DEBUG TaskMemoryManager: Task 386 release 35.7 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@24f31aab
18/03/19 07:53:05 INFO Executor: Finished task 69.0 in stage 13.0 (TID 386). 1219 bytes result sent to driver
18/03/19 07:53:05 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:05 INFO TaskSetManager: Starting task 71.0 in stage 13.0 (TID 388, localhost, executor driver, partition 71, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:05 INFO Executor: Running task 71.0 in stage 13.0 (TID 388)
18/03/19 07:53:05 INFO TaskSetManager: Finished task 69.0 in stage 13.0 (TID 386) in 3470 ms on localhost (executor driver) (70/96)
18/03/19 07:53:05 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 71-72
18/03/19 07:53:05 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:05 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:05 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:05 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 71-72
18/03/19 07:53:05 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:05 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:53:05 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:05 DEBUG TaskMemoryManager: Task 387 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6936a1d1
18/03/19 07:53:06 DEBUG TaskMemoryManager: Task 387 acquired 20.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6936a1d1
18/03/19 07:53:06 DEBUG TaskMemoryManager: Task 388 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6b4deea3
18/03/19 07:53:06 DEBUG TaskMemoryManager: Task 387 acquired 48.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6936a1d1
18/03/19 07:53:06 DEBUG TaskMemoryManager: Task 387 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@7bbf80b6
18/03/19 07:53:06 DEBUG TaskMemoryManager: Task 387 release 84.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@6936a1d1
18/03/19 07:53:06 INFO Executor: Finished task 70.0 in stage 13.0 (TID 387). 1176 bytes result sent to driver
18/03/19 07:53:06 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:06 INFO TaskSetManager: Starting task 72.0 in stage 13.0 (TID 389, localhost, executor driver, partition 72, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:06 INFO TaskSetManager: Finished task 70.0 in stage 13.0 (TID 387) in 3167 ms on localhost (executor driver) (71/96)
18/03/19 07:53:06 INFO Executor: Running task 72.0 in stage 13.0 (TID 389)
18/03/19 07:53:06 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 72-73
18/03/19 07:53:06 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:06 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:06 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:53:06 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 72-73
18/03/19 07:53:06 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:06 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:06 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:53:06 DEBUG TaskMemoryManager: Task 389 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@61c469fe
18/03/19 07:53:06 DEBUG TaskMemoryManager: Task 388 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6b4deea3
18/03/19 07:53:07 DEBUG TaskMemoryManager: Task 389 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@61c469fe
18/03/19 07:53:08 DEBUG TaskMemoryManager: Task 388 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@65500702
18/03/19 07:53:08 DEBUG TaskMemoryManager: Task 389 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@534aac8b
18/03/19 07:53:08 DEBUG TaskMemoryManager: Task 388 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@65500702
18/03/19 07:53:08 DEBUG TaskMemoryManager: Task 389 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@534aac8b
18/03/19 07:53:08 DEBUG TaskMemoryManager: Task 388 acquired 23.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@65500702
18/03/19 07:53:08 DEBUG TaskMemoryManager: Task 389 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@534aac8b
18/03/19 07:53:09 DEBUG TaskMemoryManager: Task 388 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@6b4deea3
18/03/19 07:53:09 DEBUG TaskMemoryManager: Task 389 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@61c469fe
18/03/19 07:53:09 DEBUG TaskMemoryManager: Task 388 release 38.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@65500702
18/03/19 07:53:09 INFO Executor: Finished task 71.0 in stage 13.0 (TID 388). 1176 bytes result sent to driver
18/03/19 07:53:09 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:09 INFO TaskSetManager: Starting task 73.0 in stage 13.0 (TID 390, localhost, executor driver, partition 73, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:09 INFO Executor: Running task 73.0 in stage 13.0 (TID 390)
18/03/19 07:53:09 INFO TaskSetManager: Finished task 71.0 in stage 13.0 (TID 388) in 3374 ms on localhost (executor driver) (72/96)
18/03/19 07:53:09 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 73-74
18/03/19 07:53:09 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:09 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:09 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:53:09 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 73-74
18/03/19 07:53:09 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:09 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:09 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:09 DEBUG TaskMemoryManager: Task 389 release 35.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@534aac8b
18/03/19 07:53:09 INFO Executor: Finished task 72.0 in stage 13.0 (TID 389). 1219 bytes result sent to driver
18/03/19 07:53:09 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:09 INFO TaskSetManager: Starting task 74.0 in stage 13.0 (TID 391, localhost, executor driver, partition 74, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:09 INFO TaskSetManager: Finished task 72.0 in stage 13.0 (TID 389) in 2695 ms on localhost (executor driver) (73/96)
18/03/19 07:53:09 INFO Executor: Running task 74.0 in stage 13.0 (TID 391)
18/03/19 07:53:09 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 74-75
18/03/19 07:53:09 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:09 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:09 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:09 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 74-75
18/03/19 07:53:09 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:09 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:09 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:09 DEBUG TaskMemoryManager: Task 390 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3bd95171
18/03/19 07:53:09 DEBUG TaskMemoryManager: Task 391 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@74ad6c75
18/03/19 07:53:09 DEBUG TaskMemoryManager: Task 390 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3bd95171
18/03/19 07:53:10 DEBUG TaskMemoryManager: Task 391 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@74ad6c75
18/03/19 07:53:11 DEBUG TaskMemoryManager: Task 390 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@31bf9e70
18/03/19 07:53:11 DEBUG TaskMemoryManager: Task 390 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@31bf9e70
18/03/19 07:53:11 DEBUG TaskMemoryManager: Task 391 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7bea3dca
18/03/19 07:53:11 DEBUG TaskMemoryManager: Task 390 acquired 20.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@31bf9e70
18/03/19 07:53:11 DEBUG TaskMemoryManager: Task 391 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7bea3dca
18/03/19 07:53:11 DEBUG TaskMemoryManager: Task 390 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3bd95171
18/03/19 07:53:11 DEBUG TaskMemoryManager: Task 390 release 35.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@31bf9e70
18/03/19 07:53:11 INFO Executor: Finished task 73.0 in stage 13.0 (TID 390). 1219 bytes result sent to driver
18/03/19 07:53:11 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:11 INFO TaskSetManager: Starting task 75.0 in stage 13.0 (TID 392, localhost, executor driver, partition 75, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:11 INFO Executor: Running task 75.0 in stage 13.0 (TID 392)
18/03/19 07:53:11 INFO TaskSetManager: Finished task 73.0 in stage 13.0 (TID 390) in 2382 ms on localhost (executor driver) (74/96)
18/03/19 07:53:11 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 75-76
18/03/19 07:53:11 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:11 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:11 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:11 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 75-76
18/03/19 07:53:11 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:11 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:11 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:53:11 DEBUG TaskMemoryManager: Task 391 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7bea3dca
18/03/19 07:53:11 DEBUG TaskMemoryManager: Task 391 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@74ad6c75
18/03/19 07:53:11 DEBUG TaskMemoryManager: Task 391 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@7bea3dca
18/03/19 07:53:11 INFO Executor: Finished task 74.0 in stage 13.0 (TID 391). 1176 bytes result sent to driver
18/03/19 07:53:11 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:11 INFO TaskSetManager: Starting task 76.0 in stage 13.0 (TID 393, localhost, executor driver, partition 76, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:11 INFO TaskSetManager: Finished task 74.0 in stage 13.0 (TID 391) in 2476 ms on localhost (executor driver) (75/96)
18/03/19 07:53:11 INFO Executor: Running task 76.0 in stage 13.0 (TID 393)
18/03/19 07:53:11 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 76-77
18/03/19 07:53:11 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:11 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:11 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:11 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 76-77
18/03/19 07:53:11 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:11 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:11 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:53:11 DEBUG TaskMemoryManager: Task 392 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5da70f46
18/03/19 07:53:11 DEBUG TaskMemoryManager: Task 393 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@14707c81
18/03/19 07:53:12 DEBUG TaskMemoryManager: Task 393 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@14707c81
18/03/19 07:53:12 DEBUG TaskMemoryManager: Task 392 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5da70f46
18/03/19 07:53:13 DEBUG TaskMemoryManager: Task 392 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@338a779a
18/03/19 07:53:13 DEBUG TaskMemoryManager: Task 393 acquired 5.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5cb73bd8
18/03/19 07:53:13 DEBUG TaskMemoryManager: Task 392 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@338a779a
18/03/19 07:53:13 DEBUG TaskMemoryManager: Task 393 acquired 10.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5cb73bd8
18/03/19 07:53:13 DEBUG TaskMemoryManager: Task 392 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@338a779a
18/03/19 07:53:14 DEBUG TaskMemoryManager: Task 393 acquired 22.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5cb73bd8
18/03/19 07:53:14 DEBUG TaskMemoryManager: Task 392 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5da70f46
18/03/19 07:53:14 DEBUG TaskMemoryManager: Task 392 release 35.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@338a779a
18/03/19 07:53:14 INFO Executor: Finished task 75.0 in stage 13.0 (TID 392). 1219 bytes result sent to driver
18/03/19 07:53:14 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:14 INFO TaskSetManager: Starting task 77.0 in stage 13.0 (TID 394, localhost, executor driver, partition 77, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:14 INFO Executor: Running task 77.0 in stage 13.0 (TID 394)
18/03/19 07:53:14 INFO TaskSetManager: Finished task 75.0 in stage 13.0 (TID 392) in 2568 ms on localhost (executor driver) (76/96)
18/03/19 07:53:14 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 77-78
18/03/19 07:53:14 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:14 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:14 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:53:14 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 77-78
18/03/19 07:53:14 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:14 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:14 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:53:14 DEBUG TaskMemoryManager: Task 393 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@14707c81
18/03/19 07:53:14 DEBUG TaskMemoryManager: Task 393 release 37.4 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5cb73bd8
18/03/19 07:53:14 INFO Executor: Finished task 76.0 in stage 13.0 (TID 393). 1219 bytes result sent to driver
18/03/19 07:53:14 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:14 INFO TaskSetManager: Starting task 78.0 in stage 13.0 (TID 395, localhost, executor driver, partition 78, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:14 INFO TaskSetManager: Finished task 76.0 in stage 13.0 (TID 393) in 2599 ms on localhost (executor driver) (77/96)
18/03/19 07:53:14 INFO Executor: Running task 78.0 in stage 13.0 (TID 395)
18/03/19 07:53:14 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 78-79
18/03/19 07:53:14 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:14 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:53:14 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:14 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 78-79
18/03/19 07:53:14 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:14 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:14 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:53:14 DEBUG TaskMemoryManager: Task 394 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2f04d809
18/03/19 07:53:14 DEBUG TaskMemoryManager: Task 395 acquired 5.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4657be5c
18/03/19 07:53:14 DEBUG TaskMemoryManager: Task 394 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2f04d809
18/03/19 07:53:15 DEBUG TaskMemoryManager: Task 395 acquired 10.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4657be5c
18/03/19 07:53:16 DEBUG TaskMemoryManager: Task 394 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@70d327f0
18/03/19 07:53:16 DEBUG TaskMemoryManager: Task 395 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@37ed925
18/03/19 07:53:16 DEBUG TaskMemoryManager: Task 394 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@70d327f0
18/03/19 07:53:16 DEBUG TaskMemoryManager: Task 394 acquired 20.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@70d327f0
18/03/19 07:53:16 DEBUG TaskMemoryManager: Task 395 acquired 10.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@37ed925
18/03/19 07:53:16 DEBUG TaskMemoryManager: Task 395 acquired 21.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@37ed925
18/03/19 07:53:16 DEBUG TaskMemoryManager: Task 394 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2f04d809
18/03/19 07:53:16 DEBUG TaskMemoryManager: Task 394 release 35.5 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@70d327f0
18/03/19 07:53:16 INFO Executor: Finished task 77.0 in stage 13.0 (TID 394). 1219 bytes result sent to driver
18/03/19 07:53:16 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:16 INFO TaskSetManager: Starting task 79.0 in stage 13.0 (TID 396, localhost, executor driver, partition 79, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:16 INFO Executor: Running task 79.0 in stage 13.0 (TID 396)
18/03/19 07:53:16 INFO TaskSetManager: Finished task 77.0 in stage 13.0 (TID 394) in 2670 ms on localhost (executor driver) (78/96)
18/03/19 07:53:16 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 79-80
18/03/19 07:53:16 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:16 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:16 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:16 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 79-80
18/03/19 07:53:16 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:16 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:16 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:53:16 DEBUG TaskMemoryManager: Task 395 release 15.5 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@4657be5c
18/03/19 07:53:16 DEBUG TaskMemoryManager: Task 395 release 36.8 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@37ed925
18/03/19 07:53:16 INFO Executor: Finished task 78.0 in stage 13.0 (TID 395). 1176 bytes result sent to driver
18/03/19 07:53:16 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:16 INFO TaskSetManager: Starting task 80.0 in stage 13.0 (TID 397, localhost, executor driver, partition 80, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:16 INFO TaskSetManager: Finished task 78.0 in stage 13.0 (TID 395) in 2680 ms on localhost (executor driver) (79/96)
18/03/19 07:53:16 INFO Executor: Running task 80.0 in stage 13.0 (TID 397)
18/03/19 07:53:16 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 80-81
18/03/19 07:53:16 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:16 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:16 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:53:16 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 80-81
18/03/19 07:53:16 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:16 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:16 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:53:17 DEBUG TaskMemoryManager: Task 396 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@63ec74e8
18/03/19 07:53:17 DEBUG TaskMemoryManager: Task 397 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3d2ee922
18/03/19 07:53:17 DEBUG TaskMemoryManager: Task 396 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@63ec74e8
18/03/19 07:53:17 DEBUG TaskMemoryManager: Task 397 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3d2ee922
18/03/19 07:53:18 TRACE HeartbeatReceiver: Checking for hosts with no recent heartbeats in HeartbeatReceiver.
18/03/19 07:53:19 DEBUG TaskMemoryManager: Task 396 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@25f15591
18/03/19 07:53:19 DEBUG TaskMemoryManager: Task 397 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3608ccab
18/03/19 07:53:19 DEBUG TaskMemoryManager: Task 396 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@25f15591
18/03/19 07:53:19 DEBUG TaskMemoryManager: Task 397 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3608ccab
18/03/19 07:53:19 DEBUG TaskMemoryManager: Task 396 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@25f15591
18/03/19 07:53:19 DEBUG TaskMemoryManager: Task 397 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3608ccab
18/03/19 07:53:19 DEBUG TaskMemoryManager: Task 396 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@63ec74e8
18/03/19 07:53:19 DEBUG TaskMemoryManager: Task 396 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@25f15591
18/03/19 07:53:19 INFO Executor: Finished task 79.0 in stage 13.0 (TID 396). 1219 bytes result sent to driver
18/03/19 07:53:19 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:19 INFO TaskSetManager: Starting task 81.0 in stage 13.0 (TID 398, localhost, executor driver, partition 81, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:19 INFO Executor: Running task 81.0 in stage 13.0 (TID 398)
18/03/19 07:53:19 INFO TaskSetManager: Finished task 79.0 in stage 13.0 (TID 396) in 3047 ms on localhost (executor driver) (80/96)
18/03/19 07:53:19 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 81-82
18/03/19 07:53:19 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:19 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:19 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:19 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 81-82
18/03/19 07:53:19 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:19 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:19 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:53:19 DEBUG TaskMemoryManager: Task 397 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3d2ee922
18/03/19 07:53:20 DEBUG TaskMemoryManager: Task 397 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3608ccab
18/03/19 07:53:20 INFO Executor: Finished task 80.0 in stage 13.0 (TID 397). 1219 bytes result sent to driver
18/03/19 07:53:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:20 INFO TaskSetManager: Starting task 82.0 in stage 13.0 (TID 399, localhost, executor driver, partition 82, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:20 INFO TaskSetManager: Finished task 80.0 in stage 13.0 (TID 397) in 3164 ms on localhost (executor driver) (81/96)
18/03/19 07:53:20 INFO Executor: Running task 82.0 in stage 13.0 (TID 399)
18/03/19 07:53:20 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 82-83
18/03/19 07:53:20 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:20 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:20 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:53:20 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 82-83
18/03/19 07:53:20 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:20 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:20 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:53:20 DEBUG TaskMemoryManager: Task 398 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@71276747
18/03/19 07:53:20 DEBUG TaskMemoryManager: Task 399 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@631a4167
18/03/19 07:53:20 DEBUG TaskMemoryManager: Task 399 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@631a4167
18/03/19 07:53:20 DEBUG TaskMemoryManager: Task 398 acquired 10.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@71276747
18/03/19 07:53:22 DEBUG TaskMemoryManager: Task 398 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@e0fcd52
18/03/19 07:53:22 DEBUG TaskMemoryManager: Task 398 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@e0fcd52
18/03/19 07:53:22 DEBUG TaskMemoryManager: Task 399 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@155d958f
18/03/19 07:53:22 DEBUG TaskMemoryManager: Task 398 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@e0fcd52
18/03/19 07:53:22 DEBUG TaskMemoryManager: Task 399 acquired 10.7 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@155d958f
18/03/19 07:53:22 DEBUG TaskMemoryManager: Task 398 acquired 40.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@e0fcd52
18/03/19 07:53:22 DEBUG TaskMemoryManager: Task 399 acquired 20.7 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@155d958f
18/03/19 07:53:23 DEBUG TaskMemoryManager: Task 398 release 15.4 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@71276747
18/03/19 07:53:23 DEBUG TaskMemoryManager: Task 398 release 75.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@e0fcd52
18/03/19 07:53:23 INFO Executor: Finished task 81.0 in stage 13.0 (TID 398). 1219 bytes result sent to driver
18/03/19 07:53:23 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:23 INFO TaskSetManager: Starting task 83.0 in stage 13.0 (TID 400, localhost, executor driver, partition 83, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:23 INFO Executor: Running task 83.0 in stage 13.0 (TID 400)
18/03/19 07:53:23 INFO TaskSetManager: Finished task 81.0 in stage 13.0 (TID 398) in 3227 ms on localhost (executor driver) (82/96)
18/03/19 07:53:23 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 83-84
18/03/19 07:53:23 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:23 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:23 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:23 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 83-84
18/03/19 07:53:23 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:23 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:23 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:53:23 DEBUG TaskMemoryManager: Task 399 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@631a4167
18/03/19 07:53:23 DEBUG TaskMemoryManager: Task 400 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5ed030dc
18/03/19 07:53:23 DEBUG TaskMemoryManager: Task 399 release 36.4 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@155d958f
18/03/19 07:53:23 INFO Executor: Finished task 82.0 in stage 13.0 (TID 399). 1219 bytes result sent to driver
18/03/19 07:53:23 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:23 INFO TaskSetManager: Starting task 84.0 in stage 13.0 (TID 401, localhost, executor driver, partition 84, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:23 INFO Executor: Running task 84.0 in stage 13.0 (TID 401)
18/03/19 07:53:23 INFO TaskSetManager: Finished task 82.0 in stage 13.0 (TID 399) in 3202 ms on localhost (executor driver) (83/96)
18/03/19 07:53:23 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 84-85
18/03/19 07:53:23 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:23 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:23 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:53:23 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 84-85
18/03/19 07:53:23 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:23 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:53:23 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:23 DEBUG TaskMemoryManager: Task 401 acquired 5.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3a3a877d
18/03/19 07:53:23 DEBUG TaskMemoryManager: Task 400 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5ed030dc
18/03/19 07:53:24 DEBUG TaskMemoryManager: Task 401 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3a3a877d
18/03/19 07:53:24 DEBUG TaskMemoryManager: Task 400 acquired 20.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5ed030dc
18/03/19 07:53:25 DEBUG TaskMemoryManager: Task 401 acquired 20.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3a3a877d
18/03/19 07:53:25 DEBUG TaskMemoryManager: Task 401 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5a7b08a9
18/03/19 07:53:26 DEBUG TaskMemoryManager: Task 400 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5f9e47ed
18/03/19 07:53:26 DEBUG TaskMemoryManager: Task 401 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5a7b08a9
18/03/19 07:53:26 DEBUG TaskMemoryManager: Task 400 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5f9e47ed
18/03/19 07:53:26 DEBUG TaskMemoryManager: Task 401 acquired 20.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5a7b08a9
18/03/19 07:53:26 DEBUG TaskMemoryManager: Task 400 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5f9e47ed
18/03/19 07:53:26 DEBUG TaskMemoryManager: Task 401 acquired 42.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5a7b08a9
18/03/19 07:53:26 DEBUG TaskMemoryManager: Task 400 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5f9e47ed
18/03/19 07:53:26 DEBUG TaskMemoryManager: Task 401 release 35.5 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3a3a877d
18/03/19 07:53:26 DEBUG TaskMemoryManager: Task 401 release 77.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5a7b08a9
18/03/19 07:53:26 INFO Executor: Finished task 84.0 in stage 13.0 (TID 401). 1176 bytes result sent to driver
18/03/19 07:53:26 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:26 INFO TaskSetManager: Starting task 85.0 in stage 13.0 (TID 402, localhost, executor driver, partition 85, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:26 INFO Executor: Running task 85.0 in stage 13.0 (TID 402)
18/03/19 07:53:26 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 85-86
18/03/19 07:53:26 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:26 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:26 INFO TaskSetManager: Finished task 84.0 in stage 13.0 (TID 401) in 3464 ms on localhost (executor driver) (84/96)
18/03/19 07:53:26 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:26 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 85-86
18/03/19 07:53:26 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:26 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:53:26 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:26 DEBUG TaskMemoryManager: Task 400 release 35.3 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5ed030dc
18/03/19 07:53:27 DEBUG TaskMemoryManager: Task 400 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5f9e47ed
18/03/19 07:53:27 INFO Executor: Finished task 83.0 in stage 13.0 (TID 400). 1219 bytes result sent to driver
18/03/19 07:53:27 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:27 INFO TaskSetManager: Starting task 86.0 in stage 13.0 (TID 403, localhost, executor driver, partition 86, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:27 INFO Executor: Running task 86.0 in stage 13.0 (TID 403)
18/03/19 07:53:27 INFO TaskSetManager: Finished task 83.0 in stage 13.0 (TID 400) in 4484 ms on localhost (executor driver) (85/96)
18/03/19 07:53:27 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 86-87
18/03/19 07:53:27 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:27 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:27 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:27 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 86-87
18/03/19 07:53:27 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:27 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:27 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:53:27 DEBUG TaskMemoryManager: Task 403 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@20b52fa4
18/03/19 07:53:27 DEBUG TaskMemoryManager: Task 402 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@42d3a0c5
18/03/19 07:53:28 DEBUG TaskMemoryManager: Task 403 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@20b52fa4
18/03/19 07:53:28 DEBUG TaskMemoryManager: Task 402 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@42d3a0c5
18/03/19 07:53:29 DEBUG TaskMemoryManager: Task 403 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@20b52fa4
18/03/19 07:53:29 DEBUG TaskMemoryManager: Task 402 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@9534800
18/03/19 07:53:30 DEBUG TaskMemoryManager: Task 402 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@9534800
18/03/19 07:53:30 DEBUG TaskMemoryManager: Task 402 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@9534800
18/03/19 07:53:30 DEBUG TaskMemoryManager: Task 403 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@8e9e18a
18/03/19 07:53:30 DEBUG TaskMemoryManager: Task 402 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@9534800
18/03/19 07:53:30 DEBUG TaskMemoryManager: Task 402 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@42d3a0c5
18/03/19 07:53:30 DEBUG TaskMemoryManager: Task 402 release 75.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@9534800
18/03/19 07:53:30 INFO Executor: Finished task 85.0 in stage 13.0 (TID 402). 1219 bytes result sent to driver
18/03/19 07:53:30 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:30 INFO TaskSetManager: Starting task 87.0 in stage 13.0 (TID 404, localhost, executor driver, partition 87, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:30 INFO Executor: Running task 87.0 in stage 13.0 (TID 404)
18/03/19 07:53:30 INFO TaskSetManager: Finished task 85.0 in stage 13.0 (TID 402) in 4083 ms on localhost (executor driver) (86/96)
18/03/19 07:53:30 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 87-88
18/03/19 07:53:30 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:30 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:30 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:30 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 87-88
18/03/19 07:53:30 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:30 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:30 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:53:30 DEBUG TaskMemoryManager: Task 403 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@8e9e18a
18/03/19 07:53:31 DEBUG TaskMemoryManager: Task 404 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@54cd2401
18/03/19 07:53:31 DEBUG TaskMemoryManager: Task 403 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@8e9e18a
18/03/19 07:53:31 DEBUG TaskMemoryManager: Task 403 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@8e9e18a
18/03/19 07:53:31 DEBUG TaskMemoryManager: Task 403 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@20b52fa4
18/03/19 07:53:31 DEBUG TaskMemoryManager: Task 404 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@54cd2401
18/03/19 07:53:31 DEBUG TaskMemoryManager: Task 403 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@8e9e18a
18/03/19 07:53:31 INFO Executor: Finished task 86.0 in stage 13.0 (TID 403). 1219 bytes result sent to driver
18/03/19 07:53:31 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:31 INFO TaskSetManager: Starting task 88.0 in stage 13.0 (TID 405, localhost, executor driver, partition 88, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:31 INFO TaskSetManager: Finished task 86.0 in stage 13.0 (TID 403) in 4133 ms on localhost (executor driver) (87/96)
18/03/19 07:53:31 INFO Executor: Running task 88.0 in stage 13.0 (TID 405)
18/03/19 07:53:31 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 88-89
18/03/19 07:53:31 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:31 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:31 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:31 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 88-89
18/03/19 07:53:31 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:31 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:31 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:53:31 DEBUG TaskMemoryManager: Task 405 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@f9674bf
18/03/19 07:53:32 DEBUG TaskMemoryManager: Task 405 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@f9674bf
18/03/19 07:53:32 DEBUG TaskMemoryManager: Task 405 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@f9674bf
18/03/19 07:53:32 DEBUG TaskMemoryManager: Task 404 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@54cd2401
18/03/19 07:53:33 DEBUG TaskMemoryManager: Task 404 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@18714d36
18/03/19 07:53:33 DEBUG TaskMemoryManager: Task 404 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@18714d36
18/03/19 07:53:34 DEBUG TaskMemoryManager: Task 404 acquired 20.7 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@18714d36
18/03/19 07:53:34 DEBUG TaskMemoryManager: Task 405 acquired 5.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4231340d
18/03/19 07:53:34 DEBUG TaskMemoryManager: Task 404 acquired 40.7 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@18714d36
18/03/19 07:53:34 DEBUG TaskMemoryManager: Task 405 acquired 10.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4231340d
18/03/19 07:53:34 DEBUG TaskMemoryManager: Task 404 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@54cd2401
18/03/19 07:53:34 DEBUG TaskMemoryManager: Task 404 release 76.5 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@18714d36
18/03/19 07:53:34 INFO Executor: Finished task 87.0 in stage 13.0 (TID 404). 1219 bytes result sent to driver
18/03/19 07:53:34 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:34 INFO TaskSetManager: Starting task 89.0 in stage 13.0 (TID 406, localhost, executor driver, partition 89, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:34 INFO Executor: Running task 89.0 in stage 13.0 (TID 406)
18/03/19 07:53:34 INFO TaskSetManager: Finished task 87.0 in stage 13.0 (TID 404) in 3996 ms on localhost (executor driver) (88/96)
18/03/19 07:53:34 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 89-90
18/03/19 07:53:34 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:34 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:34 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:34 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 89-90
18/03/19 07:53:34 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:34 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:34 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:53:34 DEBUG TaskMemoryManager: Task 405 acquired 20.9 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4231340d
18/03/19 07:53:34 DEBUG TaskMemoryManager: Task 406 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2ba42a2d
18/03/19 07:53:35 DEBUG TaskMemoryManager: Task 405 acquired 45.7 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4231340d
18/03/19 07:53:35 DEBUG TaskMemoryManager: Task 406 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2ba42a2d
18/03/19 07:53:35 DEBUG TaskMemoryManager: Task 405 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@f9674bf
18/03/19 07:53:35 DEBUG TaskMemoryManager: Task 405 release 82.5 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@4231340d
18/03/19 07:53:35 INFO Executor: Finished task 88.0 in stage 13.0 (TID 405). 1219 bytes result sent to driver
18/03/19 07:53:35 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:35 INFO TaskSetManager: Starting task 90.0 in stage 13.0 (TID 407, localhost, executor driver, partition 90, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:35 INFO Executor: Running task 90.0 in stage 13.0 (TID 407)
18/03/19 07:53:35 INFO TaskSetManager: Finished task 88.0 in stage 13.0 (TID 405) in 3930 ms on localhost (executor driver) (89/96)
18/03/19 07:53:35 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 90-91
18/03/19 07:53:35 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:35 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:35 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:35 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 90-91
18/03/19 07:53:35 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:35 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:35 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:53:35 DEBUG TaskMemoryManager: Task 407 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@44af9951
18/03/19 07:53:36 DEBUG TaskMemoryManager: Task 406 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2ba42a2d
18/03/19 07:53:36 DEBUG TaskMemoryManager: Task 407 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@44af9951
18/03/19 07:53:37 DEBUG TaskMemoryManager: Task 407 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@44af9951
18/03/19 07:53:37 DEBUG TaskMemoryManager: Task 406 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7b3051d
18/03/19 07:53:38 DEBUG TaskMemoryManager: Task 406 acquired 10.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7b3051d
18/03/19 07:53:38 DEBUG TaskMemoryManager: Task 406 acquired 20.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7b3051d
18/03/19 07:53:38 DEBUG TaskMemoryManager: Task 406 acquired 40.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7b3051d
18/03/19 07:53:38 DEBUG TaskMemoryManager: Task 406 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2ba42a2d
18/03/19 07:53:38 DEBUG TaskMemoryManager: Task 406 release 75.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@7b3051d
18/03/19 07:53:38 INFO Executor: Finished task 89.0 in stage 13.0 (TID 406). 1219 bytes result sent to driver
18/03/19 07:53:38 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:38 INFO TaskSetManager: Starting task 91.0 in stage 13.0 (TID 408, localhost, executor driver, partition 91, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:38 INFO Executor: Running task 91.0 in stage 13.0 (TID 408)
18/03/19 07:53:38 INFO TaskSetManager: Finished task 89.0 in stage 13.0 (TID 406) in 4131 ms on localhost (executor driver) (90/96)
18/03/19 07:53:38 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 91-92
18/03/19 07:53:38 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:38 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:53:38 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:38 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 91-92
18/03/19 07:53:38 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:38 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:38 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:53:39 DEBUG TaskMemoryManager: Task 407 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5a2801ad
18/03/19 07:53:39 DEBUG TaskMemoryManager: Task 407 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5a2801ad
18/03/19 07:53:39 DEBUG TaskMemoryManager: Task 408 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6d173252
18/03/19 07:53:39 DEBUG TaskMemoryManager: Task 407 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5a2801ad
18/03/19 07:53:39 DEBUG TaskMemoryManager: Task 407 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5a2801ad
18/03/19 07:53:39 DEBUG TaskMemoryManager: Task 408 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6d173252
18/03/19 07:53:39 DEBUG TaskMemoryManager: Task 407 release 35.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@44af9951
18/03/19 07:53:39 DEBUG TaskMemoryManager: Task 407 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5a2801ad
18/03/19 07:53:39 INFO Executor: Finished task 90.0 in stage 13.0 (TID 407). 1219 bytes result sent to driver
18/03/19 07:53:39 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:39 INFO TaskSetManager: Starting task 92.0 in stage 13.0 (TID 409, localhost, executor driver, partition 92, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:39 INFO TaskSetManager: Finished task 90.0 in stage 13.0 (TID 407) in 4389 ms on localhost (executor driver) (91/96)
18/03/19 07:53:39 INFO Executor: Running task 92.0 in stage 13.0 (TID 409)
18/03/19 07:53:39 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 92-93
18/03/19 07:53:39 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:39 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:39 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:39 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 92-93
18/03/19 07:53:39 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:39 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:39 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:53:40 DEBUG TaskMemoryManager: Task 409 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@347481df
18/03/19 07:53:40 DEBUG TaskMemoryManager: Task 408 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6d173252
18/03/19 07:53:40 DEBUG TaskMemoryManager: Task 409 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@347481df
18/03/19 07:53:42 DEBUG TaskMemoryManager: Task 408 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@518c5157
18/03/19 07:53:42 DEBUG TaskMemoryManager: Task 409 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@347481df
18/03/19 07:53:42 DEBUG TaskMemoryManager: Task 408 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@518c5157
18/03/19 07:53:43 DEBUG TaskMemoryManager: Task 408 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@518c5157
18/03/19 07:53:43 DEBUG TaskMemoryManager: Task 408 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@518c5157
18/03/19 07:53:43 DEBUG TaskMemoryManager: Task 408 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@6d173252
18/03/19 07:53:43 DEBUG TaskMemoryManager: Task 408 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@518c5157
18/03/19 07:53:43 INFO Executor: Finished task 91.0 in stage 13.0 (TID 408). 1176 bytes result sent to driver
18/03/19 07:53:43 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:43 INFO TaskSetManager: Starting task 93.0 in stage 13.0 (TID 410, localhost, executor driver, partition 93, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:43 INFO TaskSetManager: Finished task 91.0 in stage 13.0 (TID 408) in 4840 ms on localhost (executor driver) (92/96)
18/03/19 07:53:43 INFO Executor: Running task 93.0 in stage 13.0 (TID 410)
18/03/19 07:53:43 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 93-94
18/03/19 07:53:43 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:43 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:43 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:53:43 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 93-94
18/03/19 07:53:43 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:43 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:43 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:53:43 DEBUG TaskMemoryManager: Task 410 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@64efc748
18/03/19 07:53:44 DEBUG TaskMemoryManager: Task 409 acquired 5.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@46ebf2f6
18/03/19 07:53:44 DEBUG TaskMemoryManager: Task 410 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@64efc748
18/03/19 07:53:44 DEBUG TaskMemoryManager: Task 409 acquired 10.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@46ebf2f6
18/03/19 07:53:44 DEBUG TaskMemoryManager: Task 409 acquired 21.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@46ebf2f6
18/03/19 07:53:45 DEBUG TaskMemoryManager: Task 409 acquired 47.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@46ebf2f6
18/03/19 07:53:45 DEBUG TaskMemoryManager: Task 410 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@64efc748
18/03/19 07:53:45 DEBUG TaskMemoryManager: Task 409 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@347481df
18/03/19 07:53:45 DEBUG TaskMemoryManager: Task 409 release 84.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@46ebf2f6
18/03/19 07:53:45 INFO Executor: Finished task 92.0 in stage 13.0 (TID 409). 1219 bytes result sent to driver
18/03/19 07:53:45 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:45 INFO TaskSetManager: Starting task 94.0 in stage 13.0 (TID 411, localhost, executor driver, partition 94, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:45 INFO Executor: Running task 94.0 in stage 13.0 (TID 411)
18/03/19 07:53:45 INFO TaskSetManager: Finished task 92.0 in stage 13.0 (TID 409) in 5236 ms on localhost (executor driver) (93/96)
18/03/19 07:53:45 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 94-95
18/03/19 07:53:45 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:45 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:53:45 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:53:45 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 94-95
18/03/19 07:53:45 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:45 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:45 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:45 DEBUG TaskMemoryManager: Task 411 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@52cc87b9
18/03/19 07:53:45 DEBUG TaskMemoryManager: Task 411 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@52cc87b9
18/03/19 07:53:46 DEBUG TaskMemoryManager: Task 411 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@52cc87b9
18/03/19 07:53:47 DEBUG TaskMemoryManager: Task 410 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6a5e91f6
18/03/19 07:53:47 DEBUG TaskMemoryManager: Task 410 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6a5e91f6
18/03/19 07:53:47 DEBUG TaskMemoryManager: Task 410 acquired 25.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6a5e91f6
18/03/19 07:53:47 DEBUG TaskMemoryManager: Task 410 acquired 48.9 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6a5e91f6
18/03/19 07:53:47 DEBUG TaskMemoryManager: Task 410 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@64efc748
18/03/19 07:53:47 DEBUG TaskMemoryManager: Task 410 release 89.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@6a5e91f6
18/03/19 07:53:47 INFO Executor: Finished task 93.0 in stage 13.0 (TID 410). 1219 bytes result sent to driver
18/03/19 07:53:47 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:47 INFO TaskSetManager: Starting task 95.0 in stage 13.0 (TID 412, localhost, executor driver, partition 95, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:47 INFO TaskSetManager: Finished task 93.0 in stage 13.0 (TID 410) in 4185 ms on localhost (executor driver) (94/96)
18/03/19 07:53:47 INFO Executor: Running task 95.0 in stage 13.0 (TID 412)
18/03/19 07:53:47 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 95-96
18/03/19 07:53:47 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:47 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:47 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:47 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 95-96
18/03/19 07:53:47 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:47 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:53:47 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:48 DEBUG TaskMemoryManager: Task 412 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4332902f
18/03/19 07:53:48 DEBUG TaskMemoryManager: Task 411 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@76a0d90c
18/03/19 07:53:48 DEBUG TaskMemoryManager: Task 411 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@76a0d90c
18/03/19 07:53:48 DEBUG TaskMemoryManager: Task 411 acquired 21.8 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@76a0d90c
18/03/19 07:53:48 DEBUG TaskMemoryManager: Task 412 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4332902f
18/03/19 07:53:48 DEBUG TaskMemoryManager: Task 411 acquired 41.9 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@76a0d90c
18/03/19 07:53:49 DEBUG TaskMemoryManager: Task 411 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@52cc87b9
18/03/19 07:53:49 DEBUG TaskMemoryManager: Task 411 release 78.7 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@76a0d90c
18/03/19 07:53:49 INFO Executor: Finished task 94.0 in stage 13.0 (TID 411). 1219 bytes result sent to driver
18/03/19 07:53:49 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 1
18/03/19 07:53:49 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
18/03/19 07:53:49 INFO TaskSetManager: Finished task 94.0 in stage 13.0 (TID 411) in 3937 ms on localhost (executor driver) (95/96)
18/03/19 07:53:49 DEBUG TaskMemoryManager: Task 412 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4332902f
18/03/19 07:53:50 DEBUG TaskMemoryManager: Task 412 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6e93c981
18/03/19 07:53:50 DEBUG TaskMemoryManager: Task 412 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6e93c981
18/03/19 07:53:51 DEBUG TaskMemoryManager: Task 412 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6e93c981
18/03/19 07:53:51 DEBUG TaskMemoryManager: Task 412 acquired 40.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6e93c981
18/03/19 07:53:51 DEBUG TaskMemoryManager: Task 412 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@4332902f
18/03/19 07:53:51 DEBUG TaskMemoryManager: Task 412 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@6e93c981
18/03/19 07:53:51 INFO Executor: Finished task 95.0 in stage 13.0 (TID 412). 1219 bytes result sent to driver
18/03/19 07:53:51 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13.0, runningTasks: 0
18/03/19 07:53:51 INFO TaskSetManager: Finished task 95.0 in stage 13.0 (TID 412) in 3561 ms on localhost (executor driver) (96/96)
18/03/19 07:53:51 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
18/03/19 07:53:51 INFO DAGScheduler: ResultStage 13 (count at SBMJ_GB.scala:67) finished in 174.186 s
18/03/19 07:53:51 DEBUG DAGScheduler: After removal of stage 11, remaining stages = 2
18/03/19 07:53:51 DEBUG DAGScheduler: After removal of stage 13, remaining stages = 1
18/03/19 07:53:51 DEBUG DAGScheduler: After removal of stage 12, remaining stages = 0
18/03/19 07:53:51 INFO DAGScheduler: Job 9 finished: count at SBMJ_GB.scala:67, took 174.190178 s
1500000
18/03/19 07:53:51 DEBUG ClosureCleaner: +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1$$anonfun$30) +++
18/03/19 07:53:51 DEBUG ClosureCleaner:  + declared fields: 1
18/03/19 07:53:51 DEBUG ClosureCleaner:      public static final long org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1$$anonfun$30.serialVersionUID
18/03/19 07:53:51 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:53:51 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1$$anonfun$30.apply(java.lang.Object)
18/03/19 07:53:51 DEBUG ClosureCleaner:      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1$$anonfun$30.apply(scala.collection.Iterator)
18/03/19 07:53:51 DEBUG ClosureCleaner:  + inner classes: 1
18/03/19 07:53:51 DEBUG ClosureCleaner:      org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1$$anonfun$30$$anonfun$apply$53
18/03/19 07:53:51 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:53:51 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:53:51 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:53:51 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:53:51 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:53:51 DEBUG ClosureCleaner:  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1$$anonfun$30) is now cleaned +++
18/03/19 07:53:51 DEBUG HadoopMapRedWriteConfigUtil: Saving as hadoop file of type (NullWritable, Text)
18/03/19 07:53:51 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
18/03/19 07:53:51 DEBUG ClosureCleaner: +++ Cleaning closure <function2> (org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3) +++
18/03/19 07:53:51 DEBUG ClosureCleaner:  + declared fields: 6
18/03/19 07:53:51 DEBUG ClosureCleaner:      public static final long org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.serialVersionUID
18/03/19 07:53:51 DEBUG ClosureCleaner:      private final org.apache.spark.internal.io.HadoopWriteConfigUtil org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.config$1
18/03/19 07:53:51 DEBUG ClosureCleaner:      private final scala.reflect.ClassTag org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.evidence$1$1
18/03/19 07:53:51 DEBUG ClosureCleaner:      private final int org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.commitJobId$1
18/03/19 07:53:51 DEBUG ClosureCleaner:      private final java.lang.String org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.jobTrackerId$1
18/03/19 07:53:51 DEBUG ClosureCleaner:      private final org.apache.spark.internal.io.HadoopMapReduceCommitProtocol org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.committer$1
18/03/19 07:53:51 DEBUG ClosureCleaner:  + declared methods: 2
18/03/19 07:53:51 DEBUG ClosureCleaner:      public final java.lang.Object org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(java.lang.Object,java.lang.Object)
18/03/19 07:53:51 DEBUG ClosureCleaner:      public final org.apache.spark.internal.io.FileCommitProtocol$TaskCommitMessage org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
18/03/19 07:53:51 DEBUG ClosureCleaner:  + inner classes: 0
18/03/19 07:53:51 DEBUG ClosureCleaner:  + outer classes: 0
18/03/19 07:53:51 DEBUG ClosureCleaner:  + outer objects: 0
18/03/19 07:53:51 DEBUG ClosureCleaner:  + populating accessed fields because this is the starting closure
18/03/19 07:53:51 DEBUG ClosureCleaner:  + fields accessed by starting closure: 0
18/03/19 07:53:51 DEBUG ClosureCleaner:  + there are no enclosing objects!
18/03/19 07:53:51 DEBUG ClosureCleaner:  +++ closure <function2> (org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3) is now cleaned +++
18/03/19 07:53:51 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
18/03/19 07:53:51 INFO DAGScheduler: Got job 10 (runJob at SparkHadoopWriter.scala:78) with 96 output partitions
18/03/19 07:53:51 INFO DAGScheduler: Final stage: ResultStage 16 (runJob at SparkHadoopWriter.scala:78)
18/03/19 07:53:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15, ShuffleMapStage 14)
18/03/19 07:53:51 INFO DAGScheduler: Missing parents: List()
18/03/19 07:53:51 DEBUG DAGScheduler: submitStage(ResultStage 16)
18/03/19 07:53:51 DEBUG DAGScheduler: missing: List()
18/03/19 07:53:51 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[17] at saveAsTextFile at SBMJ_GB.scala:69), which has no missing parents
18/03/19 07:53:51 DEBUG DAGScheduler: submitMissingTasks(ResultStage 16)
18/03/19 07:53:51 TRACE BlockInfoManager: Task -1024 trying to put broadcast_14
18/03/19 07:53:51 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_14
18/03/19 07:53:51 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_14
18/03/19 07:53:51 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_14
18/03/19 07:53:51 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 66.7 KB, free 852.1 MB)
18/03/19 07:53:51 DEBUG BlockManager: Put block broadcast_14 locally took  1 ms
18/03/19 07:53:51 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_14
18/03/19 07:53:51 DEBUG BlockManager: Putting block broadcast_14 without replication took  1 ms
18/03/19 07:53:51 TRACE BlockInfoManager: Task -1024 trying to put broadcast_14_piece0
18/03/19 07:53:51 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_14_piece0
18/03/19 07:53:51 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_14_piece0
18/03/19 07:53:51 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_14_piece0
18/03/19 07:53:51 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 24.0 KB, free 852.0 MB)
18/03/19 07:53:51 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 192.168.8.100:40919 (size: 24.0 KB, free: 852.5 MB)
18/03/19 07:53:51 DEBUG BlockManagerMaster: Updated info of block broadcast_14_piece0
18/03/19 07:53:51 DEBUG BlockManager: Told master about block broadcast_14_piece0
18/03/19 07:53:51 DEBUG BlockManager: Put block broadcast_14_piece0 locally took  1 ms
18/03/19 07:53:51 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_14_piece0
18/03/19 07:53:51 DEBUG BlockManager: Putting block broadcast_14_piece0 without replication took  2 ms
18/03/19 07:53:51 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1039
18/03/19 07:53:51 INFO DAGScheduler: Submitting 96 missing tasks from ResultStage 16 (MapPartitionsRDD[17] at saveAsTextFile at SBMJ_GB.scala:69) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
18/03/19 07:53:51 INFO TaskSchedulerImpl: Adding task set 16.0 with 96 tasks
18/03/19 07:53:51 DEBUG TaskSetManager: Epoch for TaskSet 16.0: 2
18/03/19 07:53:51 DEBUG TaskSetManager: Valid locality levels for TaskSet 16.0: NO_PREF, ANY
18/03/19 07:53:51 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 0
18/03/19 07:53:51 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 413, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:51 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 414, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:51 INFO Executor: Running task 0.0 in stage 16.0 (TID 413)
18/03/19 07:53:51 INFO Executor: Running task 1.0 in stage 16.0 (TID 414)
18/03/19 07:53:51 DEBUG BlockManager: Getting local block broadcast_14
18/03/19 07:53:51 TRACE BlockInfoManager: Task 414 trying to acquire read lock for broadcast_14
18/03/19 07:53:51 TRACE BlockInfoManager: Task 414 acquired read lock for broadcast_14
18/03/19 07:53:51 DEBUG BlockManager: Level for block broadcast_14 is StorageLevel(disk, memory, deserialized, 1 replicas)
18/03/19 07:53:51 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 1-2
18/03/19 07:53:51 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:51 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:53:51 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:53:51 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 1-2
18/03/19 07:53:51 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:51 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:51 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:51 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 0-1
18/03/19 07:53:51 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:51 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:51 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:53:51 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 0-1
18/03/19 07:53:51 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:51 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:51 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:53:52 DEBUG TaskMemoryManager: Task 413 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@685470cd
18/03/19 07:53:52 DEBUG TaskMemoryManager: Task 414 acquired 5.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4659d3c5
18/03/19 07:53:52 DEBUG TaskMemoryManager: Task 413 acquired 10.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@685470cd
18/03/19 07:53:53 DEBUG TaskMemoryManager: Task 413 acquired 20.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@685470cd
18/03/19 07:53:53 DEBUG TaskMemoryManager: Task 414 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4659d3c5
18/03/19 07:53:54 DEBUG TaskMemoryManager: Task 413 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@500bdd41
18/03/19 07:53:54 DEBUG TaskMemoryManager: Task 413 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@500bdd41
18/03/19 07:53:54 DEBUG TaskMemoryManager: Task 413 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@500bdd41
18/03/19 07:53:54 DEBUG TaskMemoryManager: Task 414 acquired 20.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4659d3c5
18/03/19 07:53:55 DEBUG TaskMemoryManager: Task 413 acquired 44.8 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@500bdd41
18/03/19 07:53:55 DEBUG TaskMemoryManager: Task 413 release 35.7 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@685470cd
18/03/19 07:53:55 DEBUG TaskMemoryManager: Task 413 release 79.9 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@500bdd41
18/03/19 07:53:55 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=0
18/03/19 07:53:55 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000000_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000000
18/03/19 07:53:55 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000000_0: Committed
18/03/19 07:53:55 INFO Executor: Finished task 0.0 in stage 16.0 (TID 413). 1545 bytes result sent to driver
18/03/19 07:53:55 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:53:55 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 415, localhost, executor driver, partition 2, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:55 INFO Executor: Running task 2.0 in stage 16.0 (TID 415)
18/03/19 07:53:55 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 413) in 3925 ms on localhost (executor driver) (1/96)
18/03/19 07:53:55 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 2-3
18/03/19 07:53:55 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:55 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:55 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:53:55 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 2-3
18/03/19 07:53:55 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:55 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:55 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:53:56 DEBUG TaskMemoryManager: Task 415 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@25982102
18/03/19 07:53:56 DEBUG TaskMemoryManager: Task 414 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7fee3753
18/03/19 07:53:56 DEBUG TaskMemoryManager: Task 414 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7fee3753
18/03/19 07:53:56 DEBUG TaskMemoryManager: Task 415 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@25982102
18/03/19 07:53:56 DEBUG TaskMemoryManager: Task 414 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7fee3753
18/03/19 07:53:56 DEBUG TaskMemoryManager: Task 414 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7fee3753
18/03/19 07:53:56 DEBUG TaskMemoryManager: Task 414 release 35.4 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@4659d3c5
18/03/19 07:53:56 DEBUG TaskMemoryManager: Task 415 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@25982102
18/03/19 07:53:57 DEBUG TaskMemoryManager: Task 414 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@7fee3753
18/03/19 07:53:57 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=1
18/03/19 07:53:57 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000001_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000001
18/03/19 07:53:57 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000001_0: Committed
18/03/19 07:53:57 TRACE BlockInfoManager: Task 414 releasing lock for broadcast_14
18/03/19 07:53:57 INFO Executor: Finished task 1.0 in stage 16.0 (TID 414). 1502 bytes result sent to driver
18/03/19 07:53:57 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:53:57 INFO TaskSetManager: Starting task 3.0 in stage 16.0 (TID 416, localhost, executor driver, partition 3, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:57 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 414) in 5157 ms on localhost (executor driver) (2/96)
18/03/19 07:53:57 INFO Executor: Running task 3.0 in stage 16.0 (TID 416)
18/03/19 07:53:57 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 3-4
18/03/19 07:53:57 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:57 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:57 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:57 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 3-4
18/03/19 07:53:57 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:57 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:57 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:53:57 DEBUG TaskMemoryManager: Task 416 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@130cf126
18/03/19 07:53:57 DEBUG TaskMemoryManager: Task 416 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@130cf126
18/03/19 07:53:58 DEBUG TaskMemoryManager: Task 415 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7826695d
18/03/19 07:53:58 DEBUG TaskMemoryManager: Task 415 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7826695d
18/03/19 07:53:58 DEBUG TaskMemoryManager: Task 415 acquired 25.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7826695d
18/03/19 07:53:58 DEBUG TaskMemoryManager: Task 416 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@130cf126
18/03/19 07:53:59 DEBUG TaskMemoryManager: Task 415 acquired 45.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7826695d
18/03/19 07:53:59 DEBUG TaskMemoryManager: Task 415 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@25982102
18/03/19 07:53:59 DEBUG TaskMemoryManager: Task 415 release 85.8 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@7826695d
18/03/19 07:53:59 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=2
18/03/19 07:53:59 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000002_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000002
18/03/19 07:53:59 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000002_0: Committed
18/03/19 07:53:59 INFO Executor: Finished task 2.0 in stage 16.0 (TID 415). 1502 bytes result sent to driver
18/03/19 07:53:59 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:53:59 INFO TaskSetManager: Starting task 4.0 in stage 16.0 (TID 417, localhost, executor driver, partition 4, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:53:59 INFO Executor: Running task 4.0 in stage 16.0 (TID 417)
18/03/19 07:53:59 INFO TaskSetManager: Finished task 2.0 in stage 16.0 (TID 415) in 3607 ms on localhost (executor driver) (3/96)
18/03/19 07:53:59 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 4-5
18/03/19 07:53:59 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:59 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:53:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:53:59 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  4 ms
18/03/19 07:53:59 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 4-5
18/03/19 07:53:59 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:53:59 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:53:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:53:59 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:53:59 DEBUG TaskMemoryManager: Task 416 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@36aaddca
18/03/19 07:53:59 DEBUG TaskMemoryManager: Task 417 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@14388c14
18/03/19 07:53:59 DEBUG TaskMemoryManager: Task 416 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@36aaddca
18/03/19 07:54:00 DEBUG TaskMemoryManager: Task 416 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@36aaddca
18/03/19 07:54:00 DEBUG TaskMemoryManager: Task 417 acquired 10.9 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@14388c14
18/03/19 07:54:00 DEBUG TaskMemoryManager: Task 416 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@36aaddca
18/03/19 07:54:00 DEBUG TaskMemoryManager: Task 416 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@130cf126
18/03/19 07:54:00 DEBUG TaskMemoryManager: Task 416 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@36aaddca
18/03/19 07:54:00 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=3
18/03/19 07:54:00 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000003_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000003
18/03/19 07:54:00 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000003_0: Committed
18/03/19 07:54:00 INFO Executor: Finished task 3.0 in stage 16.0 (TID 416). 1502 bytes result sent to driver
18/03/19 07:54:00 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:00 INFO TaskSetManager: Starting task 5.0 in stage 16.0 (TID 418, localhost, executor driver, partition 5, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:00 INFO Executor: Running task 5.0 in stage 16.0 (TID 418)
18/03/19 07:54:00 INFO TaskSetManager: Finished task 3.0 in stage 16.0 (TID 416) in 3511 ms on localhost (executor driver) (4/96)
18/03/19 07:54:00 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 5-6
18/03/19 07:54:00 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:00 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:00 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:00 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 5-6
18/03/19 07:54:00 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:00 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:00 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:01 DEBUG TaskMemoryManager: Task 418 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@467a2b81
18/03/19 07:54:01 DEBUG TaskMemoryManager: Task 418 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@467a2b81
18/03/19 07:54:01 DEBUG TaskMemoryManager: Task 417 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@237678d1
18/03/19 07:54:02 DEBUG TaskMemoryManager: Task 417 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@237678d1
18/03/19 07:54:02 DEBUG TaskMemoryManager: Task 417 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@237678d1
18/03/19 07:54:02 DEBUG TaskMemoryManager: Task 417 release 15.9 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@14388c14
18/03/19 07:54:02 DEBUG TaskMemoryManager: Task 417 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@237678d1
18/03/19 07:54:02 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=4
18/03/19 07:54:02 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000004_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000004
18/03/19 07:54:02 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000004_0: Committed
18/03/19 07:54:02 INFO Executor: Finished task 4.0 in stage 16.0 (TID 417). 1502 bytes result sent to driver
18/03/19 07:54:02 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:02 INFO TaskSetManager: Starting task 6.0 in stage 16.0 (TID 419, localhost, executor driver, partition 6, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:02 INFO Executor: Running task 6.0 in stage 16.0 (TID 419)
18/03/19 07:54:02 INFO TaskSetManager: Finished task 4.0 in stage 16.0 (TID 417) in 3297 ms on localhost (executor driver) (5/96)
18/03/19 07:54:02 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 6-7
18/03/19 07:54:02 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:02 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:54:02 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:54:02 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 6-7
18/03/19 07:54:02 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:02 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:02 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:03 DEBUG TaskMemoryManager: Task 419 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2576e1e7
18/03/19 07:54:03 DEBUG TaskMemoryManager: Task 419 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2576e1e7
18/03/19 07:54:03 DEBUG TaskMemoryManager: Task 418 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@50ce6f4e
18/03/19 07:54:03 DEBUG TaskMemoryManager: Task 418 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@50ce6f4e
18/03/19 07:54:04 DEBUG TaskMemoryManager: Task 418 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@50ce6f4e
18/03/19 07:54:04 DEBUG TaskMemoryManager: Task 419 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2576e1e7
18/03/19 07:54:04 DEBUG TaskMemoryManager: Task 418 release 15.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@467a2b81
18/03/19 07:54:04 DEBUG TaskMemoryManager: Task 418 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@50ce6f4e
18/03/19 07:54:04 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=5
18/03/19 07:54:04 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000005_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000005
18/03/19 07:54:04 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000005_0: Committed
18/03/19 07:54:04 INFO Executor: Finished task 5.0 in stage 16.0 (TID 418). 1502 bytes result sent to driver
18/03/19 07:54:04 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:04 INFO TaskSetManager: Starting task 7.0 in stage 16.0 (TID 420, localhost, executor driver, partition 7, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:04 INFO TaskSetManager: Finished task 5.0 in stage 16.0 (TID 418) in 4232 ms on localhost (executor driver) (6/96)
18/03/19 07:54:04 INFO Executor: Running task 7.0 in stage 16.0 (TID 420)
18/03/19 07:54:04 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 7-8
18/03/19 07:54:04 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:04 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:04 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:04 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 7-8
18/03/19 07:54:04 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:04 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:04 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:05 DEBUG TaskMemoryManager: Task 420 acquired 5.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6905a0e8
18/03/19 07:54:05 DEBUG TaskMemoryManager: Task 419 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4aa9c840
18/03/19 07:54:05 DEBUG TaskMemoryManager: Task 419 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4aa9c840
18/03/19 07:54:05 DEBUG TaskMemoryManager: Task 419 acquired 21.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4aa9c840
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanAccum(286)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning accumulator 286
18/03/19 07:54:06 INFO ContextCleaner: Cleaned accumulator 286
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanAccum(275)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning accumulator 275
18/03/19 07:54:06 INFO ContextCleaner: Cleaned accumulator 275
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanAccum(297)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning accumulator 297
18/03/19 07:54:06 INFO ContextCleaner: Cleaned accumulator 297
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanAccum(285)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning accumulator 285
18/03/19 07:54:06 INFO ContextCleaner: Cleaned accumulator 285
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanAccum(276)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning accumulator 276
18/03/19 07:54:06 INFO ContextCleaner: Cleaned accumulator 276
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanAccum(281)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning accumulator 281
18/03/19 07:54:06 INFO ContextCleaner: Cleaned accumulator 281
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanAccum(279)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning accumulator 279
18/03/19 07:54:06 INFO ContextCleaner: Cleaned accumulator 279
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanAccum(294)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning accumulator 294
18/03/19 07:54:06 INFO ContextCleaner: Cleaned accumulator 294
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanAccum(282)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning accumulator 282
18/03/19 07:54:06 INFO ContextCleaner: Cleaned accumulator 282
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanAccum(278)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning accumulator 278
18/03/19 07:54:06 INFO ContextCleaner: Cleaned accumulator 278
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(13)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning broadcast 13
18/03/19 07:54:06 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 13
18/03/19 07:54:06 DEBUG BlockManagerSlaveEndpoint: removing broadcast 13
18/03/19 07:54:06 DEBUG BlockManager: Removing broadcast 13
18/03/19 07:54:06 DEBUG BlockManager: Removing block broadcast_13_piece0
18/03/19 07:54:06 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_13_piece0
18/03/19 07:54:06 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_13_piece0
18/03/19 07:54:06 DEBUG MemoryStore: Block broadcast_13_piece0 of size 2295 dropped from memory (free 813314206)
18/03/19 07:54:06 TRACE BlockInfoManager: Task -1024 trying to remove block broadcast_13_piece0
18/03/19 07:54:06 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 192.168.8.100:40919 in memory (size: 2.2 KB, free: 852.5 MB)
18/03/19 07:54:06 DEBUG BlockManagerMaster: Updated info of block broadcast_13_piece0
18/03/19 07:54:06 DEBUG BlockManager: Told master about block broadcast_13_piece0
18/03/19 07:54:06 DEBUG BlockManager: Removing block broadcast_13
18/03/19 07:54:06 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_13
18/03/19 07:54:06 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_13
18/03/19 07:54:06 DEBUG MemoryStore: Block broadcast_13 of size 4520 dropped from memory (free 813318726)
18/03/19 07:54:06 TRACE BlockInfoManager: Task -1024 trying to remove block broadcast_13
18/03/19 07:54:06 DEBUG BlockManagerSlaveEndpoint: Done removing broadcast 13, response is 0
18/03/19 07:54:06 DEBUG BlockManagerSlaveEndpoint: Sent response: 0 to 192.168.8.100:45639
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaned broadcast 13
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanAccum(289)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning accumulator 289
18/03/19 07:54:06 INFO ContextCleaner: Cleaned accumulator 289
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanAccum(291)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning accumulator 291
18/03/19 07:54:06 INFO ContextCleaner: Cleaned accumulator 291
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanAccum(287)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning accumulator 287
18/03/19 07:54:06 INFO ContextCleaner: Cleaned accumulator 287
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanAccum(288)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning accumulator 288
18/03/19 07:54:06 INFO ContextCleaner: Cleaned accumulator 288
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanAccum(298)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning accumulator 298
18/03/19 07:54:06 INFO ContextCleaner: Cleaned accumulator 298
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanAccum(277)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning accumulator 277
18/03/19 07:54:06 INFO ContextCleaner: Cleaned accumulator 277
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanAccum(299)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning accumulator 299
18/03/19 07:54:06 INFO ContextCleaner: Cleaned accumulator 299
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanAccum(296)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning accumulator 296
18/03/19 07:54:06 INFO ContextCleaner: Cleaned accumulator 296
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanAccum(283)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning accumulator 283
18/03/19 07:54:06 INFO ContextCleaner: Cleaned accumulator 283
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanAccum(280)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning accumulator 280
18/03/19 07:54:06 INFO ContextCleaner: Cleaned accumulator 280
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanAccum(295)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning accumulator 295
18/03/19 07:54:06 INFO ContextCleaner: Cleaned accumulator 295
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanAccum(290)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning accumulator 290
18/03/19 07:54:06 INFO ContextCleaner: Cleaned accumulator 290
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanAccum(293)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning accumulator 293
18/03/19 07:54:06 INFO ContextCleaner: Cleaned accumulator 293
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanAccum(292)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning accumulator 292
18/03/19 07:54:06 INFO ContextCleaner: Cleaned accumulator 292
18/03/19 07:54:06 DEBUG ContextCleaner: Got cleaning task CleanAccum(284)
18/03/19 07:54:06 DEBUG ContextCleaner: Cleaning accumulator 284
18/03/19 07:54:06 INFO ContextCleaner: Cleaned accumulator 284
18/03/19 07:54:06 DEBUG TaskMemoryManager: Task 420 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6905a0e8
18/03/19 07:54:06 DEBUG TaskMemoryManager: Task 419 acquired 41.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4aa9c840
18/03/19 07:54:06 DEBUG TaskMemoryManager: Task 419 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2576e1e7
18/03/19 07:54:07 DEBUG TaskMemoryManager: Task 419 release 77.8 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@4aa9c840
18/03/19 07:54:07 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=6
18/03/19 07:54:07 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000006_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000006
18/03/19 07:54:07 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000006_0: Committed
18/03/19 07:54:07 INFO Executor: Finished task 6.0 in stage 16.0 (TID 419). 1502 bytes result sent to driver
18/03/19 07:54:07 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:07 INFO TaskSetManager: Starting task 8.0 in stage 16.0 (TID 421, localhost, executor driver, partition 8, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:07 INFO TaskSetManager: Finished task 6.0 in stage 16.0 (TID 419) in 4327 ms on localhost (executor driver) (7/96)
18/03/19 07:54:07 INFO Executor: Running task 8.0 in stage 16.0 (TID 421)
18/03/19 07:54:07 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 8-9
18/03/19 07:54:07 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:07 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:07 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  3 ms
18/03/19 07:54:07 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 8-9
18/03/19 07:54:07 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:07 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:07 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:07 DEBUG TaskMemoryManager: Task 421 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@498db14c
18/03/19 07:54:07 DEBUG TaskMemoryManager: Task 420 acquired 5.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@57d10c3f
18/03/19 07:54:07 DEBUG TaskMemoryManager: Task 421 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@498db14c
18/03/19 07:54:08 DEBUG TaskMemoryManager: Task 420 acquired 10.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@57d10c3f
18/03/19 07:54:08 DEBUG TaskMemoryManager: Task 420 acquired 20.9 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@57d10c3f
18/03/19 07:54:08 DEBUG TaskMemoryManager: Task 420 release 15.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@6905a0e8
18/03/19 07:54:08 DEBUG TaskMemoryManager: Task 420 release 36.8 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@57d10c3f
18/03/19 07:54:08 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=7
18/03/19 07:54:08 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000007_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000007
18/03/19 07:54:08 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000007_0: Committed
18/03/19 07:54:08 INFO Executor: Finished task 7.0 in stage 16.0 (TID 420). 1502 bytes result sent to driver
18/03/19 07:54:08 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:08 INFO TaskSetManager: Starting task 9.0 in stage 16.0 (TID 422, localhost, executor driver, partition 9, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:08 INFO Executor: Running task 9.0 in stage 16.0 (TID 422)
18/03/19 07:54:08 INFO TaskSetManager: Finished task 7.0 in stage 16.0 (TID 420) in 3833 ms on localhost (executor driver) (8/96)
18/03/19 07:54:08 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 9-10
18/03/19 07:54:08 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:08 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:08 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:54:08 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 9-10
18/03/19 07:54:08 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:08 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:08 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:08 DEBUG TaskMemoryManager: Task 422 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4d242c8a
18/03/19 07:54:09 DEBUG TaskMemoryManager: Task 421 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2930ce80
18/03/19 07:54:09 DEBUG TaskMemoryManager: Task 421 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2930ce80
18/03/19 07:54:09 DEBUG TaskMemoryManager: Task 422 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4d242c8a
18/03/19 07:54:09 DEBUG TaskMemoryManager: Task 421 acquired 21.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2930ce80
18/03/19 07:54:09 DEBUG TaskMemoryManager: Task 421 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@498db14c
18/03/19 07:54:09 DEBUG TaskMemoryManager: Task 421 release 36.5 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2930ce80
18/03/19 07:54:09 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=8
18/03/19 07:54:09 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000008_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000008
18/03/19 07:54:09 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000008_0: Committed
18/03/19 07:54:09 INFO Executor: Finished task 8.0 in stage 16.0 (TID 421). 1545 bytes result sent to driver
18/03/19 07:54:09 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:09 INFO TaskSetManager: Starting task 10.0 in stage 16.0 (TID 423, localhost, executor driver, partition 10, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:09 INFO TaskSetManager: Finished task 8.0 in stage 16.0 (TID 421) in 2563 ms on localhost (executor driver) (9/96)
18/03/19 07:54:09 INFO Executor: Running task 10.0 in stage 16.0 (TID 423)
18/03/19 07:54:09 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 10-11
18/03/19 07:54:09 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:09 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:09 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:09 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 10-11
18/03/19 07:54:09 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:09 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:09 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:09 DEBUG TaskMemoryManager: Task 423 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@785a4bb5
18/03/19 07:54:10 DEBUG TaskMemoryManager: Task 423 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@785a4bb5
18/03/19 07:54:10 DEBUG TaskMemoryManager: Task 422 acquired 5.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@14831117
18/03/19 07:54:10 DEBUG TaskMemoryManager: Task 422 acquired 10.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@14831117
18/03/19 07:54:10 DEBUG TaskMemoryManager: Task 422 acquired 21.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@14831117
18/03/19 07:54:10 DEBUG TaskMemoryManager: Task 422 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@4d242c8a
18/03/19 07:54:11 DEBUG TaskMemoryManager: Task 422 release 36.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@14831117
18/03/19 07:54:11 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=9
18/03/19 07:54:11 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000009_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000009
18/03/19 07:54:11 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000009_0: Committed
18/03/19 07:54:11 INFO Executor: Finished task 9.0 in stage 16.0 (TID 422). 1502 bytes result sent to driver
18/03/19 07:54:11 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:11 INFO TaskSetManager: Starting task 11.0 in stage 16.0 (TID 424, localhost, executor driver, partition 11, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:11 INFO TaskSetManager: Finished task 9.0 in stage 16.0 (TID 422) in 2408 ms on localhost (executor driver) (10/96)
18/03/19 07:54:11 INFO Executor: Running task 11.0 in stage 16.0 (TID 424)
18/03/19 07:54:11 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 11-12
18/03/19 07:54:11 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:11 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:11 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:11 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 11-12
18/03/19 07:54:11 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:11 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:11 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:11 DEBUG TaskMemoryManager: Task 423 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@31f86c49
18/03/19 07:54:11 DEBUG TaskMemoryManager: Task 424 acquired 5.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3c223a61
18/03/19 07:54:11 DEBUG TaskMemoryManager: Task 423 acquired 10.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@31f86c49
18/03/19 07:54:11 DEBUG TaskMemoryManager: Task 423 acquired 20.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@31f86c49
18/03/19 07:54:11 DEBUG TaskMemoryManager: Task 423 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@785a4bb5
18/03/19 07:54:11 DEBUG TaskMemoryManager: Task 423 release 36.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@31f86c49
18/03/19 07:54:11 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=10
18/03/19 07:54:11 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000010_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000010
18/03/19 07:54:11 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000010_0: Committed
18/03/19 07:54:11 INFO Executor: Finished task 10.0 in stage 16.0 (TID 423). 1502 bytes result sent to driver
18/03/19 07:54:11 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:11 INFO TaskSetManager: Starting task 12.0 in stage 16.0 (TID 425, localhost, executor driver, partition 12, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:11 INFO TaskSetManager: Finished task 10.0 in stage 16.0 (TID 423) in 2300 ms on localhost (executor driver) (11/96)
18/03/19 07:54:11 INFO Executor: Running task 12.0 in stage 16.0 (TID 425)
18/03/19 07:54:11 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 12-13
18/03/19 07:54:11 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:11 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:11 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:11 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 12-13
18/03/19 07:54:11 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:11 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:11 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:12 DEBUG TaskMemoryManager: Task 424 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3c223a61
18/03/19 07:54:12 DEBUG TaskMemoryManager: Task 425 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@10432800
18/03/19 07:54:12 DEBUG TaskMemoryManager: Task 425 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@10432800
18/03/19 07:54:13 DEBUG TaskMemoryManager: Task 424 acquired 5.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@55acf7b5
18/03/19 07:54:13 DEBUG TaskMemoryManager: Task 424 acquired 10.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@55acf7b5
18/03/19 07:54:13 DEBUG TaskMemoryManager: Task 425 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5e7907c9
18/03/19 07:54:13 DEBUG TaskMemoryManager: Task 425 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5e7907c9
18/03/19 07:54:14 DEBUG TaskMemoryManager: Task 424 acquired 21.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@55acf7b5
18/03/19 07:54:14 DEBUG TaskMemoryManager: Task 424 release 15.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3c223a61
18/03/19 07:54:14 DEBUG TaskMemoryManager: Task 424 release 37.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@55acf7b5
18/03/19 07:54:14 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=11
18/03/19 07:54:14 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000011_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000011
18/03/19 07:54:14 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000011_0: Committed
18/03/19 07:54:14 INFO Executor: Finished task 11.0 in stage 16.0 (TID 424). 1502 bytes result sent to driver
18/03/19 07:54:14 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:14 INFO TaskSetManager: Starting task 13.0 in stage 16.0 (TID 426, localhost, executor driver, partition 13, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:14 INFO Executor: Running task 13.0 in stage 16.0 (TID 426)
18/03/19 07:54:14 INFO TaskSetManager: Finished task 11.0 in stage 16.0 (TID 424) in 3116 ms on localhost (executor driver) (12/96)
18/03/19 07:54:14 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 13-14
18/03/19 07:54:14 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:14 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:54:14 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:14 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 13-14
18/03/19 07:54:14 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:14 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:54:14 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:14 DEBUG TaskMemoryManager: Task 425 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5e7907c9
18/03/19 07:54:14 DEBUG TaskMemoryManager: Task 425 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@10432800
18/03/19 07:54:14 DEBUG TaskMemoryManager: Task 425 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5e7907c9
18/03/19 07:54:14 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=12
18/03/19 07:54:14 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000012_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000012
18/03/19 07:54:14 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000012_0: Committed
18/03/19 07:54:14 INFO Executor: Finished task 12.0 in stage 16.0 (TID 425). 1502 bytes result sent to driver
18/03/19 07:54:14 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:14 INFO TaskSetManager: Starting task 14.0 in stage 16.0 (TID 427, localhost, executor driver, partition 14, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:14 INFO TaskSetManager: Finished task 12.0 in stage 16.0 (TID 425) in 2441 ms on localhost (executor driver) (13/96)
18/03/19 07:54:14 INFO Executor: Running task 14.0 in stage 16.0 (TID 427)
18/03/19 07:54:14 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 14-15
18/03/19 07:54:14 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:14 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:14 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:14 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 14-15
18/03/19 07:54:14 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:14 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:14 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:14 DEBUG TaskMemoryManager: Task 426 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@59c5ba9c
18/03/19 07:54:14 DEBUG TaskMemoryManager: Task 427 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@280d6a02
18/03/19 07:54:14 DEBUG TaskMemoryManager: Task 426 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@59c5ba9c
18/03/19 07:54:15 DEBUG TaskMemoryManager: Task 427 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@280d6a02
18/03/19 07:54:15 DEBUG TaskMemoryManager: Task 426 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2b29fa98
18/03/19 07:54:16 DEBUG TaskMemoryManager: Task 426 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2b29fa98
18/03/19 07:54:16 DEBUG TaskMemoryManager: Task 427 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@20584e2
18/03/19 07:54:16 DEBUG TaskMemoryManager: Task 426 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2b29fa98
18/03/19 07:54:16 DEBUG TaskMemoryManager: Task 426 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@59c5ba9c
18/03/19 07:54:16 DEBUG TaskMemoryManager: Task 426 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2b29fa98
18/03/19 07:54:16 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=13
18/03/19 07:54:16 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000013_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000013
18/03/19 07:54:16 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000013_0: Committed
18/03/19 07:54:16 INFO Executor: Finished task 13.0 in stage 16.0 (TID 426). 1502 bytes result sent to driver
18/03/19 07:54:16 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:16 INFO TaskSetManager: Starting task 15.0 in stage 16.0 (TID 428, localhost, executor driver, partition 15, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:16 INFO TaskSetManager: Finished task 13.0 in stage 16.0 (TID 426) in 2360 ms on localhost (executor driver) (14/96)
18/03/19 07:54:16 INFO Executor: Running task 15.0 in stage 16.0 (TID 428)
18/03/19 07:54:16 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 15-16
18/03/19 07:54:16 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:16 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:54:16 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:16 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 15-16
18/03/19 07:54:16 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:16 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:16 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:16 DEBUG TaskMemoryManager: Task 427 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@20584e2
18/03/19 07:54:16 DEBUG TaskMemoryManager: Task 428 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@353b10ca
18/03/19 07:54:16 DEBUG TaskMemoryManager: Task 427 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@20584e2
18/03/19 07:54:16 DEBUG TaskMemoryManager: Task 427 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@280d6a02
18/03/19 07:54:16 DEBUG TaskMemoryManager: Task 427 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@20584e2
18/03/19 07:54:16 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=14
18/03/19 07:54:16 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000014_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000014
18/03/19 07:54:16 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000014_0: Committed
18/03/19 07:54:16 INFO Executor: Finished task 14.0 in stage 16.0 (TID 427). 1502 bytes result sent to driver
18/03/19 07:54:16 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:16 INFO TaskSetManager: Starting task 16.0 in stage 16.0 (TID 429, localhost, executor driver, partition 16, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:16 INFO TaskSetManager: Finished task 14.0 in stage 16.0 (TID 427) in 2547 ms on localhost (executor driver) (15/96)
18/03/19 07:54:16 INFO Executor: Running task 16.0 in stage 16.0 (TID 429)
18/03/19 07:54:16 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 16-17
18/03/19 07:54:16 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:16 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:16 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:16 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 16-17
18/03/19 07:54:16 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:16 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:16 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:17 DEBUG TaskMemoryManager: Task 428 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@353b10ca
18/03/19 07:54:17 DEBUG TaskMemoryManager: Task 429 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@cb930dc
18/03/19 07:54:17 DEBUG TaskMemoryManager: Task 429 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@cb930dc
18/03/19 07:54:18 DEBUG TaskMemoryManager: Task 428 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7abb18b4
18/03/19 07:54:18 DEBUG TaskMemoryManager: Task 428 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7abb18b4
18/03/19 07:54:18 TRACE HeartbeatReceiver: Checking for hosts with no recent heartbeats in HeartbeatReceiver.
18/03/19 07:54:18 DEBUG TaskMemoryManager: Task 428 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7abb18b4
18/03/19 07:54:19 DEBUG TaskMemoryManager: Task 428 release 15.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@353b10ca
18/03/19 07:54:19 DEBUG TaskMemoryManager: Task 428 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@7abb18b4
18/03/19 07:54:19 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=15
18/03/19 07:54:19 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000015_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000015
18/03/19 07:54:19 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000015_0: Committed
18/03/19 07:54:19 INFO Executor: Finished task 15.0 in stage 16.0 (TID 428). 1502 bytes result sent to driver
18/03/19 07:54:19 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:19 INFO TaskSetManager: Starting task 17.0 in stage 16.0 (TID 430, localhost, executor driver, partition 17, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:19 INFO Executor: Running task 17.0 in stage 16.0 (TID 430)
18/03/19 07:54:19 INFO TaskSetManager: Finished task 15.0 in stage 16.0 (TID 428) in 2598 ms on localhost (executor driver) (16/96)
18/03/19 07:54:19 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 17-18
18/03/19 07:54:19 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:19 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:19 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:54:19 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 17-18
18/03/19 07:54:19 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:19 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:19 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:19 DEBUG TaskMemoryManager: Task 429 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@42b09f86
18/03/19 07:54:19 DEBUG TaskMemoryManager: Task 430 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2d0fac86
18/03/19 07:54:19 DEBUG TaskMemoryManager: Task 429 acquired 10.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@42b09f86
18/03/19 07:54:19 DEBUG TaskMemoryManager: Task 429 acquired 20.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@42b09f86
18/03/19 07:54:19 DEBUG TaskMemoryManager: Task 430 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2d0fac86
18/03/19 07:54:20 DEBUG TaskMemoryManager: Task 429 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@cb930dc
18/03/19 07:54:20 DEBUG TaskMemoryManager: Task 429 release 35.4 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@42b09f86
18/03/19 07:54:20 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=16
18/03/19 07:54:20 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000016_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000016
18/03/19 07:54:20 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000016_0: Committed
18/03/19 07:54:20 INFO Executor: Finished task 16.0 in stage 16.0 (TID 429). 1502 bytes result sent to driver
18/03/19 07:54:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:20 INFO TaskSetManager: Starting task 18.0 in stage 16.0 (TID 431, localhost, executor driver, partition 18, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:20 INFO Executor: Running task 18.0 in stage 16.0 (TID 431)
18/03/19 07:54:20 INFO TaskSetManager: Finished task 16.0 in stage 16.0 (TID 429) in 3162 ms on localhost (executor driver) (17/96)
18/03/19 07:54:20 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 18-19
18/03/19 07:54:20 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:20 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:20 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:20 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 18-19
18/03/19 07:54:20 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:20 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:20 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:20 DEBUG TaskMemoryManager: Task 431 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5ee4ccb7
18/03/19 07:54:20 DEBUG TaskMemoryManager: Task 431 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5ee4ccb7
18/03/19 07:54:21 DEBUG TaskMemoryManager: Task 430 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4581676b
18/03/19 07:54:21 DEBUG TaskMemoryManager: Task 430 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4581676b
18/03/19 07:54:21 DEBUG TaskMemoryManager: Task 430 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4581676b
18/03/19 07:54:21 DEBUG TaskMemoryManager: Task 430 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2d0fac86
18/03/19 07:54:21 DEBUG TaskMemoryManager: Task 430 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@4581676b
18/03/19 07:54:21 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=17
18/03/19 07:54:21 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000017_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000017
18/03/19 07:54:21 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000017_0: Committed
18/03/19 07:54:21 INFO Executor: Finished task 17.0 in stage 16.0 (TID 430). 1502 bytes result sent to driver
18/03/19 07:54:21 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:21 INFO TaskSetManager: Starting task 19.0 in stage 16.0 (TID 432, localhost, executor driver, partition 19, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:21 INFO TaskSetManager: Finished task 17.0 in stage 16.0 (TID 430) in 2769 ms on localhost (executor driver) (18/96)
18/03/19 07:54:21 INFO Executor: Running task 19.0 in stage 16.0 (TID 432)
18/03/19 07:54:21 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 19-20
18/03/19 07:54:21 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:21 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:21 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:21 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 19-20
18/03/19 07:54:21 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:21 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:21 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:22 DEBUG TaskMemoryManager: Task 432 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@67141d9b
18/03/19 07:54:22 DEBUG TaskMemoryManager: Task 431 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6230ed1
18/03/19 07:54:22 DEBUG TaskMemoryManager: Task 431 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6230ed1
18/03/19 07:54:22 DEBUG TaskMemoryManager: Task 432 acquired 10.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@67141d9b
18/03/19 07:54:22 DEBUG TaskMemoryManager: Task 431 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6230ed1
18/03/19 07:54:23 DEBUG TaskMemoryManager: Task 431 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5ee4ccb7
18/03/19 07:54:23 DEBUG TaskMemoryManager: Task 431 release 35.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@6230ed1
18/03/19 07:54:23 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=18
18/03/19 07:54:23 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000018_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000018
18/03/19 07:54:23 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000018_0: Committed
18/03/19 07:54:23 INFO Executor: Finished task 18.0 in stage 16.0 (TID 431). 1545 bytes result sent to driver
18/03/19 07:54:23 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:23 INFO TaskSetManager: Starting task 20.0 in stage 16.0 (TID 433, localhost, executor driver, partition 20, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:23 INFO Executor: Running task 20.0 in stage 16.0 (TID 433)
18/03/19 07:54:23 INFO TaskSetManager: Finished task 18.0 in stage 16.0 (TID 431) in 3077 ms on localhost (executor driver) (19/96)
18/03/19 07:54:23 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 20-21
18/03/19 07:54:23 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:23 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:23 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:23 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 20-21
18/03/19 07:54:23 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:23 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:23 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:23 DEBUG TaskMemoryManager: Task 433 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@44c32d43
18/03/19 07:54:23 DEBUG TaskMemoryManager: Task 433 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@44c32d43
18/03/19 07:54:24 DEBUG TaskMemoryManager: Task 432 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3f8d4d1f
18/03/19 07:54:24 DEBUG TaskMemoryManager: Task 432 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3f8d4d1f
18/03/19 07:54:24 DEBUG TaskMemoryManager: Task 432 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3f8d4d1f
18/03/19 07:54:24 DEBUG TaskMemoryManager: Task 433 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@44c32d43
18/03/19 07:54:24 DEBUG TaskMemoryManager: Task 432 acquired 40.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3f8d4d1f
18/03/19 07:54:24 DEBUG TaskMemoryManager: Task 432 release 15.3 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@67141d9b
18/03/19 07:54:24 DEBUG TaskMemoryManager: Task 432 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3f8d4d1f
18/03/19 07:54:24 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=19
18/03/19 07:54:24 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000019_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000019
18/03/19 07:54:24 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000019_0: Committed
18/03/19 07:54:24 INFO Executor: Finished task 19.0 in stage 16.0 (TID 432). 1502 bytes result sent to driver
18/03/19 07:54:24 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:24 INFO TaskSetManager: Starting task 21.0 in stage 16.0 (TID 434, localhost, executor driver, partition 21, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:24 INFO TaskSetManager: Finished task 19.0 in stage 16.0 (TID 432) in 3101 ms on localhost (executor driver) (20/96)
18/03/19 07:54:24 INFO Executor: Running task 21.0 in stage 16.0 (TID 434)
18/03/19 07:54:24 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 21-22
18/03/19 07:54:24 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:24 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:24 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:24 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 21-22
18/03/19 07:54:24 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:24 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:24 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:25 DEBUG TaskMemoryManager: Task 434 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@39b154a3
18/03/19 07:54:25 DEBUG TaskMemoryManager: Task 433 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5153459f
18/03/19 07:54:25 DEBUG TaskMemoryManager: Task 434 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@39b154a3
18/03/19 07:54:25 DEBUG TaskMemoryManager: Task 433 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5153459f
18/03/19 07:54:25 DEBUG TaskMemoryManager: Task 433 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5153459f
18/03/19 07:54:26 DEBUG TaskMemoryManager: Task 433 acquired 40.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5153459f
18/03/19 07:54:26 DEBUG TaskMemoryManager: Task 433 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@44c32d43
18/03/19 07:54:26 DEBUG TaskMemoryManager: Task 433 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5153459f
18/03/19 07:54:26 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=20
18/03/19 07:54:26 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000020_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000020
18/03/19 07:54:26 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000020_0: Committed
18/03/19 07:54:26 INFO Executor: Finished task 20.0 in stage 16.0 (TID 433). 1502 bytes result sent to driver
18/03/19 07:54:26 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:26 INFO TaskSetManager: Starting task 22.0 in stage 16.0 (TID 435, localhost, executor driver, partition 22, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:26 INFO TaskSetManager: Finished task 20.0 in stage 16.0 (TID 433) in 3259 ms on localhost (executor driver) (21/96)
18/03/19 07:54:26 INFO Executor: Running task 22.0 in stage 16.0 (TID 435)
18/03/19 07:54:26 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 22-23
18/03/19 07:54:26 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:26 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:26 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:26 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 22-23
18/03/19 07:54:26 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:26 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:26 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:26 DEBUG TaskMemoryManager: Task 434 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@39b154a3
18/03/19 07:54:26 DEBUG TaskMemoryManager: Task 435 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@60bab1f2
18/03/19 07:54:27 DEBUG TaskMemoryManager: Task 435 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@60bab1f2
18/03/19 07:54:27 DEBUG TaskMemoryManager: Task 434 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4f9698b3
18/03/19 07:54:27 DEBUG TaskMemoryManager: Task 434 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4f9698b3
18/03/19 07:54:27 DEBUG TaskMemoryManager: Task 434 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4f9698b3
18/03/19 07:54:28 DEBUG TaskMemoryManager: Task 434 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4f9698b3
18/03/19 07:54:28 DEBUG TaskMemoryManager: Task 434 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@39b154a3
18/03/19 07:54:29 DEBUG TaskMemoryManager: Task 434 release 75.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@4f9698b3
18/03/19 07:54:29 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=21
18/03/19 07:54:29 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000021_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000021
18/03/19 07:54:29 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000021_0: Committed
18/03/19 07:54:29 INFO Executor: Finished task 21.0 in stage 16.0 (TID 434). 1502 bytes result sent to driver
18/03/19 07:54:29 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:29 INFO TaskSetManager: Starting task 23.0 in stage 16.0 (TID 436, localhost, executor driver, partition 23, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:29 INFO Executor: Running task 23.0 in stage 16.0 (TID 436)
18/03/19 07:54:29 INFO TaskSetManager: Finished task 21.0 in stage 16.0 (TID 434) in 4341 ms on localhost (executor driver) (22/96)
18/03/19 07:54:29 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 23-24
18/03/19 07:54:29 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:29 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:29 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:29 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 23-24
18/03/19 07:54:29 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:29 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:29 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:29 DEBUG TaskMemoryManager: Task 436 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@182804aa
18/03/19 07:54:29 DEBUG TaskMemoryManager: Task 435 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4629c888
18/03/19 07:54:29 DEBUG TaskMemoryManager: Task 436 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@182804aa
18/03/19 07:54:29 DEBUG TaskMemoryManager: Task 435 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4629c888
18/03/19 07:54:30 DEBUG TaskMemoryManager: Task 435 acquired 20.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4629c888
18/03/19 07:54:30 DEBUG TaskMemoryManager: Task 436 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@182804aa
18/03/19 07:54:30 DEBUG TaskMemoryManager: Task 435 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@60bab1f2
18/03/19 07:54:30 DEBUG TaskMemoryManager: Task 435 release 35.4 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@4629c888
18/03/19 07:54:30 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=22
18/03/19 07:54:30 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000022_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000022
18/03/19 07:54:30 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000022_0: Committed
18/03/19 07:54:30 INFO Executor: Finished task 22.0 in stage 16.0 (TID 435). 1502 bytes result sent to driver
18/03/19 07:54:30 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:30 INFO TaskSetManager: Starting task 24.0 in stage 16.0 (TID 437, localhost, executor driver, partition 24, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:30 INFO Executor: Running task 24.0 in stage 16.0 (TID 437)
18/03/19 07:54:30 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 24-25
18/03/19 07:54:30 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:30 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:30 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:30 INFO TaskSetManager: Finished task 22.0 in stage 16.0 (TID 435) in 4249 ms on localhost (executor driver) (23/96)
18/03/19 07:54:30 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 24-25
18/03/19 07:54:30 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:30 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:30 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:30 DEBUG TaskMemoryManager: Task 437 acquired 5.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@588f2395
18/03/19 07:54:31 DEBUG TaskMemoryManager: Task 437 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@588f2395
18/03/19 07:54:32 DEBUG TaskMemoryManager: Task 436 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@8f82d6c
18/03/19 07:54:32 DEBUG TaskMemoryManager: Task 437 acquired 20.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@588f2395
18/03/19 07:54:32 DEBUG TaskMemoryManager: Task 436 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@8f82d6c
18/03/19 07:54:32 DEBUG TaskMemoryManager: Task 436 acquired 20.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@8f82d6c
18/03/19 07:54:32 DEBUG TaskMemoryManager: Task 436 acquired 40.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@8f82d6c
18/03/19 07:54:33 DEBUG TaskMemoryManager: Task 436 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@182804aa
18/03/19 07:54:33 DEBUG TaskMemoryManager: Task 436 release 75.3 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@8f82d6c
18/03/19 07:54:33 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=23
18/03/19 07:54:33 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000023_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000023
18/03/19 07:54:33 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000023_0: Committed
18/03/19 07:54:33 INFO Executor: Finished task 23.0 in stage 16.0 (TID 436). 1502 bytes result sent to driver
18/03/19 07:54:33 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:33 INFO TaskSetManager: Starting task 25.0 in stage 16.0 (TID 438, localhost, executor driver, partition 25, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:33 INFO Executor: Running task 25.0 in stage 16.0 (TID 438)
18/03/19 07:54:33 INFO TaskSetManager: Finished task 23.0 in stage 16.0 (TID 436) in 3925 ms on localhost (executor driver) (24/96)
18/03/19 07:54:33 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 25-26
18/03/19 07:54:33 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:33 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:33 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:33 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 25-26
18/03/19 07:54:33 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:33 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:33 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:33 DEBUG TaskMemoryManager: Task 437 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2b015cc2
18/03/19 07:54:33 DEBUG TaskMemoryManager: Task 438 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@312f556
18/03/19 07:54:33 DEBUG TaskMemoryManager: Task 437 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2b015cc2
18/03/19 07:54:33 DEBUG TaskMemoryManager: Task 437 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2b015cc2
18/03/19 07:54:33 DEBUG TaskMemoryManager: Task 438 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@312f556
18/03/19 07:54:34 DEBUG TaskMemoryManager: Task 437 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2b015cc2
18/03/19 07:54:34 DEBUG TaskMemoryManager: Task 437 release 35.4 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@588f2395
18/03/19 07:54:34 DEBUG TaskMemoryManager: Task 437 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2b015cc2
18/03/19 07:54:34 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=24
18/03/19 07:54:34 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000024_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000024
18/03/19 07:54:34 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000024_0: Committed
18/03/19 07:54:34 INFO Executor: Finished task 24.0 in stage 16.0 (TID 437). 1502 bytes result sent to driver
18/03/19 07:54:34 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:34 INFO TaskSetManager: Starting task 26.0 in stage 16.0 (TID 439, localhost, executor driver, partition 26, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:34 INFO Executor: Running task 26.0 in stage 16.0 (TID 439)
18/03/19 07:54:34 INFO TaskSetManager: Finished task 24.0 in stage 16.0 (TID 437) in 3788 ms on localhost (executor driver) (25/96)
18/03/19 07:54:34 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 26-27
18/03/19 07:54:34 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:34 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:34 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:34 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 26-27
18/03/19 07:54:34 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:34 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:34 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:34 DEBUG TaskMemoryManager: Task 439 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@22405ed7
18/03/19 07:54:34 DEBUG TaskMemoryManager: Task 438 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@312f556
18/03/19 07:54:35 DEBUG TaskMemoryManager: Task 439 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@22405ed7
18/03/19 07:54:36 DEBUG TaskMemoryManager: Task 439 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@22405ed7
18/03/19 07:54:36 DEBUG TaskMemoryManager: Task 438 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6e313646
18/03/19 07:54:36 DEBUG TaskMemoryManager: Task 438 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6e313646
18/03/19 07:54:36 DEBUG TaskMemoryManager: Task 438 acquired 20.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6e313646
18/03/19 07:54:36 DEBUG TaskMemoryManager: Task 438 acquired 44.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6e313646
18/03/19 07:54:37 DEBUG TaskMemoryManager: Task 438 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@312f556
18/03/19 07:54:37 DEBUG TaskMemoryManager: Task 438 release 79.7 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@6e313646
18/03/19 07:54:37 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=25
18/03/19 07:54:37 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000025_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000025
18/03/19 07:54:37 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000025_0: Committed
18/03/19 07:54:37 INFO Executor: Finished task 25.0 in stage 16.0 (TID 438). 1502 bytes result sent to driver
18/03/19 07:54:37 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:37 INFO TaskSetManager: Starting task 27.0 in stage 16.0 (TID 440, localhost, executor driver, partition 27, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:37 INFO Executor: Running task 27.0 in stage 16.0 (TID 440)
18/03/19 07:54:37 INFO TaskSetManager: Finished task 25.0 in stage 16.0 (TID 438) in 3910 ms on localhost (executor driver) (26/96)
18/03/19 07:54:37 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 27-28
18/03/19 07:54:37 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:37 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:54:37 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:54:37 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 27-28
18/03/19 07:54:37 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:37 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:37 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:37 DEBUG TaskMemoryManager: Task 439 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@48460f4c
18/03/19 07:54:37 DEBUG TaskMemoryManager: Task 440 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@403401fa
18/03/19 07:54:37 DEBUG TaskMemoryManager: Task 439 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@48460f4c
18/03/19 07:54:37 DEBUG TaskMemoryManager: Task 439 acquired 20.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@48460f4c
18/03/19 07:54:37 DEBUG TaskMemoryManager: Task 440 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@403401fa
18/03/19 07:54:38 DEBUG TaskMemoryManager: Task 439 acquired 40.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@48460f4c
18/03/19 07:54:38 DEBUG TaskMemoryManager: Task 439 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@22405ed7
18/03/19 07:54:38 DEBUG TaskMemoryManager: Task 439 release 75.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@48460f4c
18/03/19 07:54:38 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=26
18/03/19 07:54:38 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000026_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000026
18/03/19 07:54:38 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000026_0: Committed
18/03/19 07:54:38 INFO Executor: Finished task 26.0 in stage 16.0 (TID 439). 1502 bytes result sent to driver
18/03/19 07:54:38 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:38 INFO TaskSetManager: Starting task 28.0 in stage 16.0 (TID 441, localhost, executor driver, partition 28, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:38 INFO Executor: Running task 28.0 in stage 16.0 (TID 441)
18/03/19 07:54:38 INFO TaskSetManager: Finished task 26.0 in stage 16.0 (TID 439) in 3981 ms on localhost (executor driver) (27/96)
18/03/19 07:54:38 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 28-29
18/03/19 07:54:38 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:38 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:38 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:38 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 28-29
18/03/19 07:54:38 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:38 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:38 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:38 DEBUG TaskMemoryManager: Task 441 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@43e61b7a
18/03/19 07:54:39 DEBUG TaskMemoryManager: Task 441 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@43e61b7a
18/03/19 07:54:39 DEBUG TaskMemoryManager: Task 440 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@403401fa
18/03/19 07:54:40 DEBUG TaskMemoryManager: Task 441 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@43e61b7a
18/03/19 07:54:40 DEBUG TaskMemoryManager: Task 440 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@495c3d06
18/03/19 07:54:40 DEBUG TaskMemoryManager: Task 440 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@495c3d06
18/03/19 07:54:40 DEBUG TaskMemoryManager: Task 440 acquired 22.8 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@495c3d06
18/03/19 07:54:41 DEBUG TaskMemoryManager: Task 440 acquired 42.9 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@495c3d06
18/03/19 07:54:41 DEBUG TaskMemoryManager: Task 440 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@403401fa
18/03/19 07:54:41 DEBUG TaskMemoryManager: Task 440 release 80.8 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@495c3d06
18/03/19 07:54:41 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=27
18/03/19 07:54:41 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000027_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000027
18/03/19 07:54:41 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000027_0: Committed
18/03/19 07:54:41 INFO Executor: Finished task 27.0 in stage 16.0 (TID 440). 1502 bytes result sent to driver
18/03/19 07:54:41 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:41 INFO TaskSetManager: Starting task 29.0 in stage 16.0 (TID 442, localhost, executor driver, partition 29, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:41 INFO TaskSetManager: Finished task 27.0 in stage 16.0 (TID 440) in 4243 ms on localhost (executor driver) (28/96)
18/03/19 07:54:41 INFO Executor: Running task 29.0 in stage 16.0 (TID 442)
18/03/19 07:54:41 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 29-30
18/03/19 07:54:41 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:41 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:41 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:41 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 29-30
18/03/19 07:54:41 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:41 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:41 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:41 DEBUG TaskMemoryManager: Task 442 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@120e2d96
18/03/19 07:54:42 DEBUG TaskMemoryManager: Task 442 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@120e2d96
18/03/19 07:54:42 DEBUG TaskMemoryManager: Task 441 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4eab0977
18/03/19 07:54:42 DEBUG TaskMemoryManager: Task 441 acquired 10.8 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4eab0977
18/03/19 07:54:42 DEBUG TaskMemoryManager: Task 441 acquired 20.8 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4eab0977
18/03/19 07:54:42 DEBUG TaskMemoryManager: Task 441 acquired 41.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4eab0977
18/03/19 07:54:42 DEBUG TaskMemoryManager: Task 441 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@43e61b7a
18/03/19 07:54:43 DEBUG TaskMemoryManager: Task 442 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@120e2d96
18/03/19 07:54:43 DEBUG TaskMemoryManager: Task 441 release 78.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@4eab0977
18/03/19 07:54:43 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=28
18/03/19 07:54:43 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000028_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000028
18/03/19 07:54:43 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000028_0: Committed
18/03/19 07:54:43 INFO Executor: Finished task 28.0 in stage 16.0 (TID 441). 1502 bytes result sent to driver
18/03/19 07:54:43 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:43 INFO TaskSetManager: Starting task 30.0 in stage 16.0 (TID 443, localhost, executor driver, partition 30, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:43 INFO TaskSetManager: Finished task 28.0 in stage 16.0 (TID 441) in 4734 ms on localhost (executor driver) (29/96)
18/03/19 07:54:43 INFO Executor: Running task 30.0 in stage 16.0 (TID 443)
18/03/19 07:54:43 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 30-31
18/03/19 07:54:43 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:43 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:43 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:43 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 30-31
18/03/19 07:54:43 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:43 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:43 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:43 DEBUG TaskMemoryManager: Task 443 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2d93b955
18/03/19 07:54:43 DEBUG TaskMemoryManager: Task 443 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2d93b955
18/03/19 07:54:45 DEBUG TaskMemoryManager: Task 443 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2d93b955
18/03/19 07:54:45 DEBUG TaskMemoryManager: Task 442 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@14d5a977
18/03/19 07:54:45 DEBUG TaskMemoryManager: Task 442 acquired 11.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@14d5a977
18/03/19 07:54:45 DEBUG TaskMemoryManager: Task 442 acquired 21.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@14d5a977
18/03/19 07:54:45 DEBUG TaskMemoryManager: Task 442 acquired 42.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@14d5a977
18/03/19 07:54:46 DEBUG TaskMemoryManager: Task 442 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@120e2d96
18/03/19 07:54:46 DEBUG TaskMemoryManager: Task 442 release 79.7 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@14d5a977
18/03/19 07:54:46 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=29
18/03/19 07:54:46 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000029_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000029
18/03/19 07:54:46 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000029_0: Committed
18/03/19 07:54:46 INFO Executor: Finished task 29.0 in stage 16.0 (TID 442). 1502 bytes result sent to driver
18/03/19 07:54:46 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:46 INFO TaskSetManager: Starting task 31.0 in stage 16.0 (TID 444, localhost, executor driver, partition 31, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:46 INFO TaskSetManager: Finished task 29.0 in stage 16.0 (TID 442) in 4804 ms on localhost (executor driver) (30/96)
18/03/19 07:54:46 INFO Executor: Running task 31.0 in stage 16.0 (TID 444)
18/03/19 07:54:46 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 31-32
18/03/19 07:54:46 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:46 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:54:46 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:46 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 31-32
18/03/19 07:54:46 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:46 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:54:46 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:46 DEBUG TaskMemoryManager: Task 444 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@ef7413e
18/03/19 07:54:46 DEBUG TaskMemoryManager: Task 443 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@12effe78
18/03/19 07:54:46 DEBUG TaskMemoryManager: Task 443 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@12effe78
18/03/19 07:54:46 DEBUG TaskMemoryManager: Task 443 acquired 20.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@12effe78
18/03/19 07:54:47 DEBUG TaskMemoryManager: Task 444 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@ef7413e
18/03/19 07:54:47 DEBUG TaskMemoryManager: Task 443 acquired 40.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@12effe78
18/03/19 07:54:47 DEBUG TaskMemoryManager: Task 443 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2d93b955
18/03/19 07:54:47 DEBUG TaskMemoryManager: Task 443 release 76.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@12effe78
18/03/19 07:54:47 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=30
18/03/19 07:54:47 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000030_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000030
18/03/19 07:54:47 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000030_0: Committed
18/03/19 07:54:47 INFO Executor: Finished task 30.0 in stage 16.0 (TID 443). 1502 bytes result sent to driver
18/03/19 07:54:47 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:47 INFO TaskSetManager: Starting task 32.0 in stage 16.0 (TID 445, localhost, executor driver, partition 32, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:47 INFO TaskSetManager: Finished task 30.0 in stage 16.0 (TID 443) in 4512 ms on localhost (executor driver) (31/96)
18/03/19 07:54:47 INFO Executor: Running task 32.0 in stage 16.0 (TID 445)
18/03/19 07:54:47 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 32-33
18/03/19 07:54:47 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:47 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:47 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:47 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 32-33
18/03/19 07:54:47 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:47 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:47 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:47 DEBUG TaskMemoryManager: Task 445 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@80de00a
18/03/19 07:54:47 DEBUG TaskMemoryManager: Task 444 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@ef7413e
18/03/19 07:54:48 DEBUG TaskMemoryManager: Task 445 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@80de00a
18/03/19 07:54:48 DEBUG TaskMemoryManager: Task 445 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@80de00a
18/03/19 07:54:49 DEBUG TaskMemoryManager: Task 444 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1a2239cb
18/03/19 07:54:49 DEBUG TaskMemoryManager: Task 444 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1a2239cb
18/03/19 07:54:49 DEBUG TaskMemoryManager: Task 444 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1a2239cb
18/03/19 07:54:49 DEBUG TaskMemoryManager: Task 444 acquired 41.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1a2239cb
18/03/19 07:54:50 DEBUG TaskMemoryManager: Task 444 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@ef7413e
18/03/19 07:54:50 DEBUG TaskMemoryManager: Task 444 release 76.3 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@1a2239cb
18/03/19 07:54:50 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=31
18/03/19 07:54:50 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000031_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000031
18/03/19 07:54:50 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000031_0: Committed
18/03/19 07:54:50 INFO Executor: Finished task 31.0 in stage 16.0 (TID 444). 1502 bytes result sent to driver
18/03/19 07:54:50 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:50 INFO TaskSetManager: Starting task 33.0 in stage 16.0 (TID 446, localhost, executor driver, partition 33, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:50 INFO Executor: Running task 33.0 in stage 16.0 (TID 446)
18/03/19 07:54:50 INFO TaskSetManager: Finished task 31.0 in stage 16.0 (TID 444) in 3980 ms on localhost (executor driver) (32/96)
18/03/19 07:54:50 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 33-34
18/03/19 07:54:50 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:50 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:50 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:50 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 33-34
18/03/19 07:54:50 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:50 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:50 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:50 DEBUG TaskMemoryManager: Task 446 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5bca1a01
18/03/19 07:54:50 DEBUG TaskMemoryManager: Task 445 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5daf1c89
18/03/19 07:54:50 DEBUG TaskMemoryManager: Task 445 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5daf1c89
18/03/19 07:54:50 DEBUG TaskMemoryManager: Task 446 acquired 10.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5bca1a01
18/03/19 07:54:50 DEBUG TaskMemoryManager: Task 445 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5daf1c89
18/03/19 07:54:51 DEBUG TaskMemoryManager: Task 445 acquired 40.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5daf1c89
18/03/19 07:54:51 DEBUG TaskMemoryManager: Task 445 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@80de00a
18/03/19 07:54:51 DEBUG TaskMemoryManager: Task 445 release 75.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5daf1c89
18/03/19 07:54:51 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=32
18/03/19 07:54:51 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000032_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000032
18/03/19 07:54:51 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000032_0: Committed
18/03/19 07:54:51 INFO Executor: Finished task 32.0 in stage 16.0 (TID 445). 1502 bytes result sent to driver
18/03/19 07:54:51 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:51 INFO TaskSetManager: Starting task 34.0 in stage 16.0 (TID 447, localhost, executor driver, partition 34, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:51 INFO Executor: Running task 34.0 in stage 16.0 (TID 447)
18/03/19 07:54:51 INFO TaskSetManager: Finished task 32.0 in stage 16.0 (TID 445) in 3939 ms on localhost (executor driver) (33/96)
18/03/19 07:54:51 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 34-35
18/03/19 07:54:51 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:51 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:51 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:51 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 34-35
18/03/19 07:54:51 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:51 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:51 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:51 DEBUG TaskMemoryManager: Task 446 acquired 20.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5bca1a01
18/03/19 07:54:51 DEBUG TaskMemoryManager: Task 447 acquired 5.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@49ec7d79
18/03/19 07:54:52 DEBUG TaskMemoryManager: Task 447 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@49ec7d79
18/03/19 07:54:53 DEBUG TaskMemoryManager: Task 446 acquired 5.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2cc9899d
18/03/19 07:54:53 DEBUG TaskMemoryManager: Task 446 acquired 10.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2cc9899d
18/03/19 07:54:53 DEBUG TaskMemoryManager: Task 446 acquired 21.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2cc9899d
18/03/19 07:54:53 DEBUG TaskMemoryManager: Task 446 acquired 42.7 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2cc9899d
18/03/19 07:54:53 DEBUG TaskMemoryManager: Task 446 release 35.9 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5bca1a01
18/03/19 07:54:54 DEBUG TaskMemoryManager: Task 446 release 79.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2cc9899d
18/03/19 07:54:54 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=33
18/03/19 07:54:54 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000033_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000033
18/03/19 07:54:54 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000033_0: Committed
18/03/19 07:54:54 INFO Executor: Finished task 33.0 in stage 16.0 (TID 446). 1502 bytes result sent to driver
18/03/19 07:54:54 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:54 INFO TaskSetManager: Starting task 35.0 in stage 16.0 (TID 448, localhost, executor driver, partition 35, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:54 INFO TaskSetManager: Finished task 33.0 in stage 16.0 (TID 446) in 3836 ms on localhost (executor driver) (34/96)
18/03/19 07:54:54 INFO Executor: Running task 35.0 in stage 16.0 (TID 448)
18/03/19 07:54:54 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 35-36
18/03/19 07:54:54 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:54 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:54 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:54 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 35-36
18/03/19 07:54:54 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:54 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:54 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:54 DEBUG TaskMemoryManager: Task 447 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@190884e4
18/03/19 07:54:54 DEBUG TaskMemoryManager: Task 447 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@190884e4
18/03/19 07:54:54 DEBUG TaskMemoryManager: Task 448 acquired 5.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@287e06f9
18/03/19 07:54:54 DEBUG TaskMemoryManager: Task 447 acquired 21.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@190884e4
18/03/19 07:54:54 DEBUG TaskMemoryManager: Task 447 release 15.3 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@49ec7d79
18/03/19 07:54:55 DEBUG TaskMemoryManager: Task 447 release 36.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@190884e4
18/03/19 07:54:55 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=34
18/03/19 07:54:55 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000034_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000034
18/03/19 07:54:55 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000034_0: Committed
18/03/19 07:54:55 INFO Executor: Finished task 34.0 in stage 16.0 (TID 447). 1502 bytes result sent to driver
18/03/19 07:54:55 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:55 INFO TaskSetManager: Starting task 36.0 in stage 16.0 (TID 449, localhost, executor driver, partition 36, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:55 INFO TaskSetManager: Finished task 34.0 in stage 16.0 (TID 447) in 3429 ms on localhost (executor driver) (35/96)
18/03/19 07:54:55 INFO Executor: Running task 36.0 in stage 16.0 (TID 449)
18/03/19 07:54:55 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 36-37
18/03/19 07:54:55 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:55 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:55 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:55 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 36-37
18/03/19 07:54:55 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:55 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:55 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:55 DEBUG TaskMemoryManager: Task 448 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@287e06f9
18/03/19 07:54:55 DEBUG TaskMemoryManager: Task 449 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3e3c818e
18/03/19 07:54:55 DEBUG TaskMemoryManager: Task 449 acquired 10.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3e3c818e
18/03/19 07:54:55 DEBUG TaskMemoryManager: Task 448 acquired 20.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@287e06f9
18/03/19 07:54:56 DEBUG TaskMemoryManager: Task 448 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4e5d3861
18/03/19 07:54:56 DEBUG TaskMemoryManager: Task 448 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4e5d3861
18/03/19 07:54:56 DEBUG TaskMemoryManager: Task 449 acquired 20.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3e3c818e
18/03/19 07:54:56 DEBUG TaskMemoryManager: Task 448 acquired 22.8 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4e5d3861
18/03/19 07:54:57 DEBUG TaskMemoryManager: Task 448 acquired 42.9 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4e5d3861
18/03/19 07:54:57 DEBUG TaskMemoryManager: Task 448 release 35.4 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@287e06f9
18/03/19 07:54:57 DEBUG TaskMemoryManager: Task 448 release 80.7 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@4e5d3861
18/03/19 07:54:57 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=35
18/03/19 07:54:57 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000035_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000035
18/03/19 07:54:57 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000035_0: Committed
18/03/19 07:54:57 INFO Executor: Finished task 35.0 in stage 16.0 (TID 448). 1502 bytes result sent to driver
18/03/19 07:54:57 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:57 INFO TaskSetManager: Starting task 37.0 in stage 16.0 (TID 450, localhost, executor driver, partition 37, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:57 INFO Executor: Running task 37.0 in stage 16.0 (TID 450)
18/03/19 07:54:57 INFO TaskSetManager: Finished task 35.0 in stage 16.0 (TID 448) in 3385 ms on localhost (executor driver) (36/96)
18/03/19 07:54:57 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 37-38
18/03/19 07:54:57 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:57 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:57 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:57 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 37-38
18/03/19 07:54:57 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:57 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:57 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:57 DEBUG TaskMemoryManager: Task 449 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@23e8a5b3
18/03/19 07:54:57 DEBUG TaskMemoryManager: Task 450 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1b756182
18/03/19 07:54:57 DEBUG TaskMemoryManager: Task 449 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@23e8a5b3
18/03/19 07:54:58 DEBUG TaskMemoryManager: Task 449 acquired 21.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@23e8a5b3
18/03/19 07:54:58 DEBUG TaskMemoryManager: Task 450 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1b756182
18/03/19 07:54:58 DEBUG TaskMemoryManager: Task 449 acquired 41.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@23e8a5b3
18/03/19 07:54:58 DEBUG TaskMemoryManager: Task 449 release 36.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3e3c818e
18/03/19 07:54:58 DEBUG TaskMemoryManager: Task 449 release 77.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@23e8a5b3
18/03/19 07:54:58 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=36
18/03/19 07:54:58 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000036_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000036
18/03/19 07:54:58 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000036_0: Committed
18/03/19 07:54:58 INFO Executor: Finished task 36.0 in stage 16.0 (TID 449). 1545 bytes result sent to driver
18/03/19 07:54:58 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:54:58 INFO TaskSetManager: Starting task 38.0 in stage 16.0 (TID 451, localhost, executor driver, partition 38, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:54:58 INFO TaskSetManager: Finished task 36.0 in stage 16.0 (TID 449) in 3419 ms on localhost (executor driver) (37/96)
18/03/19 07:54:58 INFO Executor: Running task 38.0 in stage 16.0 (TID 451)
18/03/19 07:54:58 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 38-39
18/03/19 07:54:58 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:58 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:54:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:58 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:54:58 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 38-39
18/03/19 07:54:58 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:54:58 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:54:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:54:58 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:54:58 DEBUG TaskMemoryManager: Task 451 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@a2b0b7
18/03/19 07:54:59 DEBUG TaskMemoryManager: Task 451 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@a2b0b7
18/03/19 07:54:59 DEBUG TaskMemoryManager: Task 451 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@a2b0b7
18/03/19 07:54:59 DEBUG TaskMemoryManager: Task 450 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@21252e37
18/03/19 07:55:00 DEBUG TaskMemoryManager: Task 450 acquired 10.8 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@21252e37
18/03/19 07:55:00 DEBUG TaskMemoryManager: Task 450 acquired 20.8 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@21252e37
18/03/19 07:55:00 DEBUG TaskMemoryManager: Task 451 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@555516b0
18/03/19 07:55:00 DEBUG TaskMemoryManager: Task 450 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@1b756182
18/03/19 07:55:00 DEBUG TaskMemoryManager: Task 450 release 36.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@21252e37
18/03/19 07:55:00 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=37
18/03/19 07:55:00 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000037_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000037
18/03/19 07:55:00 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000037_0: Committed
18/03/19 07:55:00 INFO Executor: Finished task 37.0 in stage 16.0 (TID 450). 1502 bytes result sent to driver
18/03/19 07:55:00 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:00 INFO TaskSetManager: Starting task 39.0 in stage 16.0 (TID 452, localhost, executor driver, partition 39, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:00 INFO TaskSetManager: Finished task 37.0 in stage 16.0 (TID 450) in 3271 ms on localhost (executor driver) (38/96)
18/03/19 07:55:00 INFO Executor: Running task 39.0 in stage 16.0 (TID 452)
18/03/19 07:55:00 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 39-40
18/03/19 07:55:00 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:00 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:00 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:00 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 39-40
18/03/19 07:55:00 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:00 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:00 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:00 DEBUG TaskMemoryManager: Task 451 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@555516b0
18/03/19 07:55:01 DEBUG TaskMemoryManager: Task 451 acquired 20.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@555516b0
18/03/19 07:55:01 DEBUG TaskMemoryManager: Task 452 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@17b99185
18/03/19 07:55:01 DEBUG TaskMemoryManager: Task 451 acquired 41.9 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@555516b0
18/03/19 07:55:01 DEBUG TaskMemoryManager: Task 451 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@a2b0b7
18/03/19 07:55:01 DEBUG TaskMemoryManager: Task 451 release 77.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@555516b0
18/03/19 07:55:01 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=38
18/03/19 07:55:01 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000038_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000038
18/03/19 07:55:01 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000038_0: Committed
18/03/19 07:55:01 INFO Executor: Finished task 38.0 in stage 16.0 (TID 451). 1502 bytes result sent to driver
18/03/19 07:55:01 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:01 INFO TaskSetManager: Starting task 40.0 in stage 16.0 (TID 453, localhost, executor driver, partition 40, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:01 INFO TaskSetManager: Finished task 38.0 in stage 16.0 (TID 451) in 3297 ms on localhost (executor driver) (39/96)
18/03/19 07:55:01 INFO Executor: Running task 40.0 in stage 16.0 (TID 453)
18/03/19 07:55:01 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 40-41
18/03/19 07:55:01 DEBUG TaskMemoryManager: Task 452 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@17b99185
18/03/19 07:55:01 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:01 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:01 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:01 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 40-41
18/03/19 07:55:01 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:01 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:01 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:01 DEBUG TaskMemoryManager: Task 453 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7d27e1e6
18/03/19 07:55:02 DEBUG TaskMemoryManager: Task 453 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7d27e1e6
18/03/19 07:55:03 DEBUG TaskMemoryManager: Task 452 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6b6bf739
18/03/19 07:55:03 DEBUG TaskMemoryManager: Task 452 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6b6bf739
18/03/19 07:55:03 DEBUG TaskMemoryManager: Task 452 acquired 21.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6b6bf739
18/03/19 07:55:03 DEBUG TaskMemoryManager: Task 453 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5542a2aa
18/03/19 07:55:03 DEBUG TaskMemoryManager: Task 452 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@17b99185
18/03/19 07:55:03 DEBUG TaskMemoryManager: Task 452 release 36.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@6b6bf739
18/03/19 07:55:03 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=39
18/03/19 07:55:03 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000039_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000039
18/03/19 07:55:03 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000039_0: Committed
18/03/19 07:55:03 INFO Executor: Finished task 39.0 in stage 16.0 (TID 452). 1502 bytes result sent to driver
18/03/19 07:55:03 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:03 INFO TaskSetManager: Starting task 41.0 in stage 16.0 (TID 454, localhost, executor driver, partition 41, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:03 INFO Executor: Running task 41.0 in stage 16.0 (TID 454)
18/03/19 07:55:03 INFO TaskSetManager: Finished task 39.0 in stage 16.0 (TID 452) in 3173 ms on localhost (executor driver) (40/96)
18/03/19 07:55:03 DEBUG TaskMemoryManager: Task 453 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5542a2aa
18/03/19 07:55:03 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 41-42
18/03/19 07:55:03 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:03 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:03 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:03 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 41-42
18/03/19 07:55:03 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:03 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:03 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:04 DEBUG TaskMemoryManager: Task 453 acquired 21.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5542a2aa
18/03/19 07:55:04 DEBUG TaskMemoryManager: Task 454 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@28bb3e32
18/03/19 07:55:04 DEBUG TaskMemoryManager: Task 453 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@7d27e1e6
18/03/19 07:55:04 DEBUG TaskMemoryManager: Task 453 release 36.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5542a2aa
18/03/19 07:55:04 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=40
18/03/19 07:55:04 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000040_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000040
18/03/19 07:55:04 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000040_0: Committed
18/03/19 07:55:04 INFO Executor: Finished task 40.0 in stage 16.0 (TID 453). 1502 bytes result sent to driver
18/03/19 07:55:04 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:04 INFO TaskSetManager: Starting task 42.0 in stage 16.0 (TID 455, localhost, executor driver, partition 42, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:04 INFO Executor: Running task 42.0 in stage 16.0 (TID 455)
18/03/19 07:55:04 INFO TaskSetManager: Finished task 40.0 in stage 16.0 (TID 453) in 2524 ms on localhost (executor driver) (41/96)
18/03/19 07:55:04 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 42-43
18/03/19 07:55:04 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:04 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:04 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:55:04 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 42-43
18/03/19 07:55:04 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:04 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:04 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:04 DEBUG TaskMemoryManager: Task 455 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@35fd92a2
18/03/19 07:55:04 DEBUG TaskMemoryManager: Task 454 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@28bb3e32
18/03/19 07:55:04 DEBUG TaskMemoryManager: Task 455 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@35fd92a2
18/03/19 07:55:05 DEBUG TaskMemoryManager: Task 454 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@57cddeff
18/03/19 07:55:05 DEBUG TaskMemoryManager: Task 454 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@57cddeff
18/03/19 07:55:05 DEBUG TaskMemoryManager: Task 454 acquired 21.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@57cddeff
18/03/19 07:55:06 DEBUG TaskMemoryManager: Task 454 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@28bb3e32
18/03/19 07:55:06 DEBUG TaskMemoryManager: Task 455 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2bcadeb3
18/03/19 07:55:06 DEBUG TaskMemoryManager: Task 454 release 36.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@57cddeff
18/03/19 07:55:06 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=41
18/03/19 07:55:06 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000041_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000041
18/03/19 07:55:06 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000041_0: Committed
18/03/19 07:55:06 INFO Executor: Finished task 41.0 in stage 16.0 (TID 454). 1502 bytes result sent to driver
18/03/19 07:55:06 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:06 INFO TaskSetManager: Starting task 43.0 in stage 16.0 (TID 456, localhost, executor driver, partition 43, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:06 INFO Executor: Running task 43.0 in stage 16.0 (TID 456)
18/03/19 07:55:06 INFO TaskSetManager: Finished task 41.0 in stage 16.0 (TID 454) in 2389 ms on localhost (executor driver) (42/96)
18/03/19 07:55:06 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 43-44
18/03/19 07:55:06 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:06 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:06 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:06 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 43-44
18/03/19 07:55:06 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:06 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:06 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:06 DEBUG TaskMemoryManager: Task 455 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2bcadeb3
18/03/19 07:55:06 DEBUG TaskMemoryManager: Task 456 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3bd26c2e
18/03/19 07:55:06 DEBUG TaskMemoryManager: Task 455 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2bcadeb3
18/03/19 07:55:06 DEBUG TaskMemoryManager: Task 455 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@35fd92a2
18/03/19 07:55:06 DEBUG TaskMemoryManager: Task 455 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2bcadeb3
18/03/19 07:55:06 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=42
18/03/19 07:55:06 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000042_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000042
18/03/19 07:55:06 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000042_0: Committed
18/03/19 07:55:06 INFO Executor: Finished task 42.0 in stage 16.0 (TID 455). 1502 bytes result sent to driver
18/03/19 07:55:06 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:06 INFO TaskSetManager: Starting task 44.0 in stage 16.0 (TID 457, localhost, executor driver, partition 44, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:06 INFO TaskSetManager: Finished task 42.0 in stage 16.0 (TID 455) in 2481 ms on localhost (executor driver) (43/96)
18/03/19 07:55:06 INFO Executor: Running task 44.0 in stage 16.0 (TID 457)
18/03/19 07:55:06 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 44-45
18/03/19 07:55:06 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:06 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:06 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:06 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 44-45
18/03/19 07:55:06 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:06 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:06 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:06 DEBUG TaskMemoryManager: Task 456 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3bd26c2e
18/03/19 07:55:07 DEBUG TaskMemoryManager: Task 457 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@21f6563
18/03/19 07:55:07 DEBUG TaskMemoryManager: Task 457 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@21f6563
18/03/19 07:55:07 DEBUG TaskMemoryManager: Task 456 acquired 5.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@9f506a3
18/03/19 07:55:08 DEBUG TaskMemoryManager: Task 456 acquired 10.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@9f506a3
18/03/19 07:55:08 DEBUG TaskMemoryManager: Task 456 acquired 20.8 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@9f506a3
18/03/19 07:55:08 DEBUG TaskMemoryManager: Task 456 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3bd26c2e
18/03/19 07:55:08 DEBUG TaskMemoryManager: Task 456 release 36.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@9f506a3
18/03/19 07:55:08 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=43
18/03/19 07:55:08 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000043_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000043
18/03/19 07:55:08 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000043_0: Committed
18/03/19 07:55:08 INFO Executor: Finished task 43.0 in stage 16.0 (TID 456). 1502 bytes result sent to driver
18/03/19 07:55:08 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:08 INFO TaskSetManager: Starting task 45.0 in stage 16.0 (TID 458, localhost, executor driver, partition 45, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:08 INFO Executor: Running task 45.0 in stage 16.0 (TID 458)
18/03/19 07:55:08 INFO TaskSetManager: Finished task 43.0 in stage 16.0 (TID 456) in 2181 ms on localhost (executor driver) (44/96)
18/03/19 07:55:08 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 45-46
18/03/19 07:55:08 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:08 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:55:08 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:55:08 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 45-46
18/03/19 07:55:08 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:08 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:08 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:08 DEBUG TaskMemoryManager: Task 457 acquired 5.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4a9689f1
18/03/19 07:55:08 DEBUG TaskMemoryManager: Task 458 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@614a1105
18/03/19 07:55:08 DEBUG TaskMemoryManager: Task 457 acquired 10.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4a9689f1
18/03/19 07:55:08 DEBUG TaskMemoryManager: Task 457 acquired 20.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4a9689f1
18/03/19 07:55:09 DEBUG TaskMemoryManager: Task 457 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@21f6563
18/03/19 07:55:09 DEBUG TaskMemoryManager: Task 457 release 35.8 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@4a9689f1
18/03/19 07:55:09 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=44
18/03/19 07:55:09 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000044_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000044
18/03/19 07:55:09 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000044_0: Committed
18/03/19 07:55:09 INFO Executor: Finished task 44.0 in stage 16.0 (TID 457). 1502 bytes result sent to driver
18/03/19 07:55:09 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:09 INFO TaskSetManager: Starting task 46.0 in stage 16.0 (TID 459, localhost, executor driver, partition 46, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:09 INFO TaskSetManager: Finished task 44.0 in stage 16.0 (TID 457) in 2396 ms on localhost (executor driver) (45/96)
18/03/19 07:55:09 INFO Executor: Running task 46.0 in stage 16.0 (TID 459)
18/03/19 07:55:09 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 46-47
18/03/19 07:55:09 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:09 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:09 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:09 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 46-47
18/03/19 07:55:09 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:09 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:09 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:09 DEBUG TaskMemoryManager: Task 458 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@614a1105
18/03/19 07:55:09 DEBUG TaskMemoryManager: Task 459 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@69ca6d3d
18/03/19 07:55:09 DEBUG TaskMemoryManager: Task 459 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@69ca6d3d
18/03/19 07:55:10 DEBUG TaskMemoryManager: Task 458 acquired 5.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@73dc42e7
18/03/19 07:55:10 DEBUG TaskMemoryManager: Task 458 acquired 11.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@73dc42e7
18/03/19 07:55:10 DEBUG TaskMemoryManager: Task 458 acquired 21.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@73dc42e7
18/03/19 07:55:10 DEBUG TaskMemoryManager: Task 458 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@614a1105
18/03/19 07:55:10 DEBUG TaskMemoryManager: Task 458 release 37.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@73dc42e7
18/03/19 07:55:10 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=45
18/03/19 07:55:10 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000045_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000045
18/03/19 07:55:10 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000045_0: Committed
18/03/19 07:55:10 INFO Executor: Finished task 45.0 in stage 16.0 (TID 458). 1502 bytes result sent to driver
18/03/19 07:55:10 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:10 INFO TaskSetManager: Starting task 47.0 in stage 16.0 (TID 460, localhost, executor driver, partition 47, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:10 INFO Executor: Running task 47.0 in stage 16.0 (TID 460)
18/03/19 07:55:10 INFO TaskSetManager: Finished task 45.0 in stage 16.0 (TID 458) in 2351 ms on localhost (executor driver) (46/96)
18/03/19 07:55:10 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 47-48
18/03/19 07:55:10 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:10 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:10 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:10 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 47-48
18/03/19 07:55:10 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:10 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:10 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:10 DEBUG TaskMemoryManager: Task 459 acquired 5.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4ead4aa1
18/03/19 07:55:11 DEBUG TaskMemoryManager: Task 459 acquired 10.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4ead4aa1
18/03/19 07:55:11 DEBUG TaskMemoryManager: Task 460 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5abb9032
18/03/19 07:55:11 DEBUG TaskMemoryManager: Task 459 acquired 20.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4ead4aa1
18/03/19 07:55:11 DEBUG TaskMemoryManager: Task 459 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@69ca6d3d
18/03/19 07:55:11 DEBUG TaskMemoryManager: Task 459 release 36.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@4ead4aa1
18/03/19 07:55:11 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=46
18/03/19 07:55:11 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000046_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000046
18/03/19 07:55:11 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000046_0: Committed
18/03/19 07:55:11 INFO Executor: Finished task 46.0 in stage 16.0 (TID 459). 1502 bytes result sent to driver
18/03/19 07:55:11 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:11 INFO TaskSetManager: Starting task 48.0 in stage 16.0 (TID 461, localhost, executor driver, partition 48, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:11 INFO TaskSetManager: Finished task 46.0 in stage 16.0 (TID 459) in 2400 ms on localhost (executor driver) (47/96)
18/03/19 07:55:11 INFO Executor: Running task 48.0 in stage 16.0 (TID 461)
18/03/19 07:55:11 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 48-49
18/03/19 07:55:11 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:11 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:11 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:11 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 48-49
18/03/19 07:55:11 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:11 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:11 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:11 DEBUG TaskMemoryManager: Task 461 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5d687e19
18/03/19 07:55:11 DEBUG TaskMemoryManager: Task 460 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5abb9032
18/03/19 07:55:12 DEBUG TaskMemoryManager: Task 461 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5d687e19
18/03/19 07:55:13 DEBUG TaskMemoryManager: Task 460 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@54b362d5
18/03/19 07:55:13 DEBUG TaskMemoryManager: Task 461 acquired 5.8 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@68966eaa
18/03/19 07:55:13 DEBUG TaskMemoryManager: Task 460 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@54b362d5
18/03/19 07:55:13 DEBUG TaskMemoryManager: Task 460 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@54b362d5
18/03/19 07:55:13 DEBUG TaskMemoryManager: Task 461 acquired 11.8 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@68966eaa
18/03/19 07:55:14 DEBUG TaskMemoryManager: Task 461 acquired 22.7 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@68966eaa
18/03/19 07:55:14 DEBUG TaskMemoryManager: Task 460 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5abb9032
18/03/19 07:55:14 DEBUG TaskMemoryManager: Task 460 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@54b362d5
18/03/19 07:55:14 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=47
18/03/19 07:55:14 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000047_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000047
18/03/19 07:55:14 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000047_0: Committed
18/03/19 07:55:14 INFO Executor: Finished task 47.0 in stage 16.0 (TID 460). 1502 bytes result sent to driver
18/03/19 07:55:14 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:14 INFO TaskSetManager: Starting task 49.0 in stage 16.0 (TID 462, localhost, executor driver, partition 49, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:14 INFO Executor: Running task 49.0 in stage 16.0 (TID 462)
18/03/19 07:55:14 INFO TaskSetManager: Finished task 47.0 in stage 16.0 (TID 460) in 3412 ms on localhost (executor driver) (48/96)
18/03/19 07:55:14 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 49-50
18/03/19 07:55:14 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:14 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:14 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:14 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 49-50
18/03/19 07:55:14 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:14 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:14 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:14 DEBUG TaskMemoryManager: Task 462 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6637dd10
18/03/19 07:55:14 DEBUG TaskMemoryManager: Task 461 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5d687e19
18/03/19 07:55:14 DEBUG TaskMemoryManager: Task 461 release 40.3 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@68966eaa
18/03/19 07:55:14 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=48
18/03/19 07:55:14 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000048_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000048
18/03/19 07:55:14 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000048_0: Committed
18/03/19 07:55:14 INFO Executor: Finished task 48.0 in stage 16.0 (TID 461). 1502 bytes result sent to driver
18/03/19 07:55:14 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:14 INFO TaskSetManager: Starting task 50.0 in stage 16.0 (TID 463, localhost, executor driver, partition 50, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:14 INFO Executor: Running task 50.0 in stage 16.0 (TID 463)
18/03/19 07:55:14 INFO TaskSetManager: Finished task 48.0 in stage 16.0 (TID 461) in 2886 ms on localhost (executor driver) (49/96)
18/03/19 07:55:14 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 50-51
18/03/19 07:55:14 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:14 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:14 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:55:14 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 50-51
18/03/19 07:55:14 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:14 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:14 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:14 DEBUG TaskMemoryManager: Task 462 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6637dd10
18/03/19 07:55:14 DEBUG TaskMemoryManager: Task 463 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@36d7cbf6
18/03/19 07:55:15 DEBUG TaskMemoryManager: Task 463 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@36d7cbf6
18/03/19 07:55:15 DEBUG TaskMemoryManager: Task 462 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6637dd10
18/03/19 07:55:16 DEBUG TaskMemoryManager: Task 462 acquired 5.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@704cd4e0
18/03/19 07:55:16 DEBUG TaskMemoryManager: Task 462 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@704cd4e0
18/03/19 07:55:16 DEBUG TaskMemoryManager: Task 462 acquired 20.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@704cd4e0
18/03/19 07:55:16 DEBUG TaskMemoryManager: Task 462 acquired 41.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@704cd4e0
18/03/19 07:55:17 DEBUG TaskMemoryManager: Task 462 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@6637dd10
18/03/19 07:55:17 DEBUG TaskMemoryManager: Task 462 release 76.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@704cd4e0
18/03/19 07:55:17 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=49
18/03/19 07:55:17 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000049_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000049
18/03/19 07:55:17 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000049_0: Committed
18/03/19 07:55:17 INFO Executor: Finished task 49.0 in stage 16.0 (TID 462). 1502 bytes result sent to driver
18/03/19 07:55:17 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:17 INFO TaskSetManager: Starting task 51.0 in stage 16.0 (TID 464, localhost, executor driver, partition 51, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:17 INFO Executor: Running task 51.0 in stage 16.0 (TID 464)
18/03/19 07:55:17 INFO TaskSetManager: Finished task 49.0 in stage 16.0 (TID 462) in 2899 ms on localhost (executor driver) (50/96)
18/03/19 07:55:17 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 51-52
18/03/19 07:55:17 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:17 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:55:17 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:55:17 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 51-52
18/03/19 07:55:17 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:17 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:17 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:17 DEBUG TaskMemoryManager: Task 463 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@23ff4d86
18/03/19 07:55:17 DEBUG TaskMemoryManager: Task 464 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6a7abb97
18/03/19 07:55:17 DEBUG TaskMemoryManager: Task 463 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@23ff4d86
18/03/19 07:55:17 DEBUG TaskMemoryManager: Task 463 acquired 20.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@23ff4d86
18/03/19 07:55:17 DEBUG TaskMemoryManager: Task 464 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6a7abb97
18/03/19 07:55:17 DEBUG TaskMemoryManager: Task 463 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@36d7cbf6
18/03/19 07:55:17 DEBUG TaskMemoryManager: Task 463 release 35.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@23ff4d86
18/03/19 07:55:17 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=50
18/03/19 07:55:17 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000050_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000050
18/03/19 07:55:17 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000050_0: Committed
18/03/19 07:55:17 INFO Executor: Finished task 50.0 in stage 16.0 (TID 463). 1502 bytes result sent to driver
18/03/19 07:55:17 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:17 INFO TaskSetManager: Starting task 52.0 in stage 16.0 (TID 465, localhost, executor driver, partition 52, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:17 INFO Executor: Running task 52.0 in stage 16.0 (TID 465)
18/03/19 07:55:17 INFO TaskSetManager: Finished task 50.0 in stage 16.0 (TID 463) in 3543 ms on localhost (executor driver) (51/96)
18/03/19 07:55:17 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 52-53
18/03/19 07:55:17 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:17 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:17 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:17 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 52-53
18/03/19 07:55:17 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:17 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:17 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:18 DEBUG TaskMemoryManager: Task 465 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4128116b
18/03/19 07:55:18 DEBUG TaskMemoryManager: Task 464 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6a7abb97
18/03/19 07:55:18 TRACE HeartbeatReceiver: Checking for hosts with no recent heartbeats in HeartbeatReceiver.
18/03/19 07:55:18 DEBUG TaskMemoryManager: Task 465 acquired 10.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4128116b
18/03/19 07:55:19 DEBUG TaskMemoryManager: Task 464 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@24230f81
18/03/19 07:55:19 DEBUG TaskMemoryManager: Task 464 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@24230f81
18/03/19 07:55:19 DEBUG TaskMemoryManager: Task 465 acquired 20.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4128116b
18/03/19 07:55:19 DEBUG TaskMemoryManager: Task 464 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@24230f81
18/03/19 07:55:20 DEBUG TaskMemoryManager: Task 464 acquired 43.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@24230f81
18/03/19 07:55:20 DEBUG TaskMemoryManager: Task 464 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@6a7abb97
18/03/19 07:55:20 DEBUG TaskMemoryManager: Task 464 release 78.4 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@24230f81
18/03/19 07:55:20 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=51
18/03/19 07:55:20 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000051_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000051
18/03/19 07:55:20 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000051_0: Committed
18/03/19 07:55:20 INFO Executor: Finished task 51.0 in stage 16.0 (TID 464). 1502 bytes result sent to driver
18/03/19 07:55:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:20 INFO TaskSetManager: Starting task 53.0 in stage 16.0 (TID 466, localhost, executor driver, partition 53, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:20 INFO Executor: Running task 53.0 in stage 16.0 (TID 466)
18/03/19 07:55:20 INFO TaskSetManager: Finished task 51.0 in stage 16.0 (TID 464) in 3247 ms on localhost (executor driver) (52/96)
18/03/19 07:55:20 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 53-54
18/03/19 07:55:20 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:20 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:20 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:20 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 53-54
18/03/19 07:55:20 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:20 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:20 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:20 DEBUG TaskMemoryManager: Task 465 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5d95d1ed
18/03/19 07:55:20 DEBUG TaskMemoryManager: Task 466 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1321471b
18/03/19 07:55:20 DEBUG TaskMemoryManager: Task 465 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5d95d1ed
18/03/19 07:55:20 DEBUG TaskMemoryManager: Task 465 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5d95d1ed
18/03/19 07:55:21 DEBUG TaskMemoryManager: Task 466 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1321471b
18/03/19 07:55:21 DEBUG TaskMemoryManager: Task 465 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5d95d1ed
18/03/19 07:55:21 DEBUG TaskMemoryManager: Task 465 release 35.7 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@4128116b
18/03/19 07:55:21 DEBUG TaskMemoryManager: Task 465 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5d95d1ed
18/03/19 07:55:21 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=52
18/03/19 07:55:21 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000052_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000052
18/03/19 07:55:21 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000052_0: Committed
18/03/19 07:55:21 INFO Executor: Finished task 52.0 in stage 16.0 (TID 465). 1545 bytes result sent to driver
18/03/19 07:55:21 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:21 INFO TaskSetManager: Starting task 54.0 in stage 16.0 (TID 467, localhost, executor driver, partition 54, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:21 INFO TaskSetManager: Finished task 52.0 in stage 16.0 (TID 465) in 3439 ms on localhost (executor driver) (53/96)
18/03/19 07:55:21 INFO Executor: Running task 54.0 in stage 16.0 (TID 467)
18/03/19 07:55:21 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 54-55
18/03/19 07:55:21 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:21 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:21 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:21 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 54-55
18/03/19 07:55:21 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:21 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:21 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:21 DEBUG TaskMemoryManager: Task 467 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@740e700c
18/03/19 07:55:22 DEBUG TaskMemoryManager: Task 466 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1321471b
18/03/19 07:55:22 DEBUG TaskMemoryManager: Task 467 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@740e700c
18/03/19 07:55:22 DEBUG TaskMemoryManager: Task 467 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@740e700c
18/03/19 07:55:23 DEBUG TaskMemoryManager: Task 466 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7659035f
18/03/19 07:55:23 DEBUG TaskMemoryManager: Task 466 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7659035f
18/03/19 07:55:23 DEBUG TaskMemoryManager: Task 466 acquired 20.9 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7659035f
18/03/19 07:55:23 DEBUG TaskMemoryManager: Task 466 acquired 40.9 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7659035f
18/03/19 07:55:23 DEBUG TaskMemoryManager: Task 466 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@1321471b
18/03/19 07:55:23 DEBUG TaskMemoryManager: Task 467 acquired 5.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5879432
18/03/19 07:55:24 DEBUG TaskMemoryManager: Task 466 release 76.9 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@7659035f
18/03/19 07:55:24 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=53
18/03/19 07:55:24 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000053_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000053
18/03/19 07:55:24 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000053_0: Committed
18/03/19 07:55:24 INFO Executor: Finished task 53.0 in stage 16.0 (TID 466). 1502 bytes result sent to driver
18/03/19 07:55:24 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:24 INFO TaskSetManager: Starting task 55.0 in stage 16.0 (TID 468, localhost, executor driver, partition 55, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:24 INFO TaskSetManager: Finished task 53.0 in stage 16.0 (TID 466) in 3708 ms on localhost (executor driver) (54/96)
18/03/19 07:55:24 INFO Executor: Running task 55.0 in stage 16.0 (TID 468)
18/03/19 07:55:24 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 55-56
18/03/19 07:55:24 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:24 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:55:24 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:24 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 55-56
18/03/19 07:55:24 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:24 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:55:24 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:24 DEBUG TaskMemoryManager: Task 467 acquired 10.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5879432
18/03/19 07:55:24 DEBUG TaskMemoryManager: Task 468 acquired 5.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5a7ae37b
18/03/19 07:55:24 DEBUG TaskMemoryManager: Task 467 acquired 20.7 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5879432
18/03/19 07:55:24 DEBUG TaskMemoryManager: Task 467 acquired 41.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5879432
18/03/19 07:55:24 DEBUG TaskMemoryManager: Task 468 acquired 10.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5a7ae37b
18/03/19 07:55:24 DEBUG TaskMemoryManager: Task 467 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@740e700c
18/03/19 07:55:24 DEBUG TaskMemoryManager: Task 467 release 77.8 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5879432
18/03/19 07:55:24 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=54
18/03/19 07:55:24 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000054_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000054
18/03/19 07:55:24 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000054_0: Committed
18/03/19 07:55:24 INFO Executor: Finished task 54.0 in stage 16.0 (TID 467). 1502 bytes result sent to driver
18/03/19 07:55:24 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:24 INFO TaskSetManager: Starting task 56.0 in stage 16.0 (TID 469, localhost, executor driver, partition 56, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:24 INFO TaskSetManager: Finished task 54.0 in stage 16.0 (TID 467) in 3505 ms on localhost (executor driver) (55/96)
18/03/19 07:55:24 INFO Executor: Running task 56.0 in stage 16.0 (TID 469)
18/03/19 07:55:24 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 56-57
18/03/19 07:55:24 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:24 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:24 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:24 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 56-57
18/03/19 07:55:24 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:24 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:24 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:25 DEBUG TaskMemoryManager: Task 469 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@36101a72
18/03/19 07:55:25 DEBUG TaskMemoryManager: Task 468 acquired 20.7 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5a7ae37b
18/03/19 07:55:25 DEBUG TaskMemoryManager: Task 469 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@36101a72
18/03/19 07:55:26 DEBUG TaskMemoryManager: Task 469 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@36101a72
18/03/19 07:55:27 DEBUG TaskMemoryManager: Task 468 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7830c08b
18/03/19 07:55:27 DEBUG TaskMemoryManager: Task 468 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7830c08b
18/03/19 07:55:27 DEBUG TaskMemoryManager: Task 468 acquired 20.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7830c08b
18/03/19 07:55:27 DEBUG TaskMemoryManager: Task 469 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@24ab921
18/03/19 07:55:27 DEBUG TaskMemoryManager: Task 468 acquired 40.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7830c08b
18/03/19 07:55:27 DEBUG TaskMemoryManager: Task 469 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@24ab921
18/03/19 07:55:29 DEBUG TaskMemoryManager: Task 468 release 36.5 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5a7ae37b
18/03/19 07:55:29 DEBUG TaskMemoryManager: Task 468 release 75.5 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@7830c08b
18/03/19 07:55:29 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=55
18/03/19 07:55:29 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000055_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000055
18/03/19 07:55:29 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000055_0: Committed
18/03/19 07:55:29 INFO Executor: Finished task 55.0 in stage 16.0 (TID 468). 1502 bytes result sent to driver
18/03/19 07:55:29 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:29 INFO TaskSetManager: Starting task 57.0 in stage 16.0 (TID 470, localhost, executor driver, partition 57, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:29 INFO Executor: Running task 57.0 in stage 16.0 (TID 470)
18/03/19 07:55:29 INFO TaskSetManager: Finished task 55.0 in stage 16.0 (TID 468) in 5051 ms on localhost (executor driver) (56/96)
18/03/19 07:55:29 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 57-58
18/03/19 07:55:29 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:29 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:29 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:29 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 57-58
18/03/19 07:55:29 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:29 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:29 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:29 DEBUG TaskMemoryManager: Task 469 acquired 20.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@24ab921
18/03/19 07:55:29 DEBUG TaskMemoryManager: Task 469 acquired 40.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@24ab921
18/03/19 07:55:29 DEBUG TaskMemoryManager: Task 469 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@36101a72
18/03/19 07:55:29 DEBUG TaskMemoryManager: Task 470 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@61642358
18/03/19 07:55:29 DEBUG TaskMemoryManager: Task 469 release 75.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@24ab921
18/03/19 07:55:29 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=56
18/03/19 07:55:29 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000056_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000056
18/03/19 07:55:29 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000056_0: Committed
18/03/19 07:55:29 INFO Executor: Finished task 56.0 in stage 16.0 (TID 469). 1502 bytes result sent to driver
18/03/19 07:55:29 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:29 INFO TaskSetManager: Starting task 58.0 in stage 16.0 (TID 471, localhost, executor driver, partition 58, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:29 INFO Executor: Running task 58.0 in stage 16.0 (TID 471)
18/03/19 07:55:29 INFO TaskSetManager: Finished task 56.0 in stage 16.0 (TID 469) in 4740 ms on localhost (executor driver) (57/96)
18/03/19 07:55:29 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 58-59
18/03/19 07:55:29 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:29 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:29 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:29 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 58-59
18/03/19 07:55:29 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:29 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:29 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:29 DEBUG TaskMemoryManager: Task 471 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@664aa964
18/03/19 07:55:30 DEBUG TaskMemoryManager: Task 470 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@61642358
18/03/19 07:55:30 DEBUG TaskMemoryManager: Task 471 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@664aa964
18/03/19 07:55:31 DEBUG TaskMemoryManager: Task 470 acquired 20.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@61642358
18/03/19 07:55:31 DEBUG TaskMemoryManager: Task 471 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@664aa964
18/03/19 07:55:32 DEBUG TaskMemoryManager: Task 470 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@e186ae9
18/03/19 07:55:33 DEBUG TaskMemoryManager: Task 470 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@e186ae9
18/03/19 07:55:33 DEBUG TaskMemoryManager: Task 471 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@455412
18/03/19 07:55:33 DEBUG TaskMemoryManager: Task 471 acquired 10.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@455412
18/03/19 07:55:33 DEBUG TaskMemoryManager: Task 470 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@e186ae9
18/03/19 07:55:33 DEBUG TaskMemoryManager: Task 471 acquired 20.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@455412
18/03/19 07:55:33 DEBUG TaskMemoryManager: Task 470 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@e186ae9
18/03/19 07:55:33 DEBUG TaskMemoryManager: Task 470 release 35.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@61642358
18/03/19 07:55:33 DEBUG TaskMemoryManager: Task 471 acquired 41.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@455412
18/03/19 07:55:33 DEBUG TaskMemoryManager: Task 470 release 75.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@e186ae9
18/03/19 07:55:33 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=57
18/03/19 07:55:33 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000057_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000057
18/03/19 07:55:33 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000057_0: Committed
18/03/19 07:55:33 INFO Executor: Finished task 57.0 in stage 16.0 (TID 470). 1502 bytes result sent to driver
18/03/19 07:55:33 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:33 INFO TaskSetManager: Starting task 59.0 in stage 16.0 (TID 472, localhost, executor driver, partition 59, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:33 INFO TaskSetManager: Finished task 57.0 in stage 16.0 (TID 470) in 4771 ms on localhost (executor driver) (58/96)
18/03/19 07:55:33 INFO Executor: Running task 59.0 in stage 16.0 (TID 472)
18/03/19 07:55:33 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 59-60
18/03/19 07:55:33 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:33 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:33 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:33 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 59-60
18/03/19 07:55:33 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:33 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:33 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:33 DEBUG TaskMemoryManager: Task 471 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@664aa964
18/03/19 07:55:34 DEBUG TaskMemoryManager: Task 472 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2159089f
18/03/19 07:55:34 DEBUG TaskMemoryManager: Task 471 release 77.3 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@455412
18/03/19 07:55:34 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=58
18/03/19 07:55:34 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000058_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000058
18/03/19 07:55:34 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000058_0: Committed
18/03/19 07:55:34 INFO Executor: Finished task 58.0 in stage 16.0 (TID 471). 1502 bytes result sent to driver
18/03/19 07:55:34 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:34 INFO TaskSetManager: Starting task 60.0 in stage 16.0 (TID 473, localhost, executor driver, partition 60, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:34 INFO TaskSetManager: Finished task 58.0 in stage 16.0 (TID 471) in 4441 ms on localhost (executor driver) (59/96)
18/03/19 07:55:34 INFO Executor: Running task 60.0 in stage 16.0 (TID 473)
18/03/19 07:55:34 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 60-61
18/03/19 07:55:34 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:34 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:34 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:34 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 60-61
18/03/19 07:55:34 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:34 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:34 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:34 DEBUG TaskMemoryManager: Task 473 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@53d63354
18/03/19 07:55:34 DEBUG TaskMemoryManager: Task 472 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2159089f
18/03/19 07:55:34 DEBUG TaskMemoryManager: Task 473 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@53d63354
18/03/19 07:55:35 DEBUG TaskMemoryManager: Task 472 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2159089f
18/03/19 07:55:36 DEBUG TaskMemoryManager: Task 473 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@53d63354
18/03/19 07:55:37 DEBUG TaskMemoryManager: Task 472 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@10c0eebe
18/03/19 07:55:37 DEBUG TaskMemoryManager: Task 472 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@10c0eebe
18/03/19 07:55:37 DEBUG TaskMemoryManager: Task 473 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@17033ea8
18/03/19 07:55:37 DEBUG TaskMemoryManager: Task 472 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@10c0eebe
18/03/19 07:55:37 DEBUG TaskMemoryManager: Task 473 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@17033ea8
18/03/19 07:55:37 DEBUG TaskMemoryManager: Task 472 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@10c0eebe
18/03/19 07:55:37 DEBUG TaskMemoryManager: Task 473 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@17033ea8
18/03/19 07:55:38 DEBUG TaskMemoryManager: Task 472 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2159089f
18/03/19 07:55:38 DEBUG TaskMemoryManager: Task 472 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@10c0eebe
18/03/19 07:55:38 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=59
18/03/19 07:55:38 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000059_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000059
18/03/19 07:55:38 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000059_0: Committed
18/03/19 07:55:38 INFO Executor: Finished task 59.0 in stage 16.0 (TID 472). 1502 bytes result sent to driver
18/03/19 07:55:38 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:38 INFO TaskSetManager: Starting task 61.0 in stage 16.0 (TID 474, localhost, executor driver, partition 61, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:38 INFO Executor: Running task 61.0 in stage 16.0 (TID 474)
18/03/19 07:55:38 INFO TaskSetManager: Finished task 59.0 in stage 16.0 (TID 472) in 4398 ms on localhost (executor driver) (60/96)
18/03/19 07:55:38 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 61-62
18/03/19 07:55:38 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:38 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:55:38 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:38 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 61-62
18/03/19 07:55:38 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:38 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:38 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:38 DEBUG TaskMemoryManager: Task 473 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@17033ea8
18/03/19 07:55:38 DEBUG TaskMemoryManager: Task 474 acquired 5.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@17d7a73b
18/03/19 07:55:38 DEBUG TaskMemoryManager: Task 473 release 35.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@53d63354
18/03/19 07:55:38 DEBUG TaskMemoryManager: Task 473 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@17033ea8
18/03/19 07:55:38 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=60
18/03/19 07:55:38 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000060_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000060
18/03/19 07:55:38 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000060_0: Committed
18/03/19 07:55:38 INFO Executor: Finished task 60.0 in stage 16.0 (TID 473). 1502 bytes result sent to driver
18/03/19 07:55:38 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:38 INFO TaskSetManager: Starting task 62.0 in stage 16.0 (TID 475, localhost, executor driver, partition 62, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:38 INFO Executor: Running task 62.0 in stage 16.0 (TID 475)
18/03/19 07:55:38 INFO TaskSetManager: Finished task 60.0 in stage 16.0 (TID 473) in 4565 ms on localhost (executor driver) (61/96)
18/03/19 07:55:38 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 62-63
18/03/19 07:55:38 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:38 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:38 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:55:38 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 62-63
18/03/19 07:55:38 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:38 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:38 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:38 DEBUG TaskMemoryManager: Task 475 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@21cd90bf
18/03/19 07:55:39 DEBUG TaskMemoryManager: Task 474 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@17d7a73b
18/03/19 07:55:39 DEBUG TaskMemoryManager: Task 475 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@21cd90bf
18/03/19 07:55:40 DEBUG TaskMemoryManager: Task 474 acquired 20.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@17d7a73b
18/03/19 07:55:40 DEBUG TaskMemoryManager: Task 475 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@21cd90bf
18/03/19 07:55:41 DEBUG TaskMemoryManager: Task 474 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@54eec656
18/03/19 07:55:41 DEBUG TaskMemoryManager: Task 475 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7096c4c
18/03/19 07:55:41 DEBUG TaskMemoryManager: Task 474 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@54eec656
18/03/19 07:55:42 DEBUG TaskMemoryManager: Task 475 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7096c4c
18/03/19 07:55:42 DEBUG TaskMemoryManager: Task 474 acquired 20.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@54eec656
18/03/19 07:55:42 DEBUG TaskMemoryManager: Task 475 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7096c4c
18/03/19 07:55:42 DEBUG TaskMemoryManager: Task 474 acquired 40.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@54eec656
18/03/19 07:55:42 DEBUG TaskMemoryManager: Task 475 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7096c4c
18/03/19 07:55:42 DEBUG TaskMemoryManager: Task 474 release 35.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@17d7a73b
18/03/19 07:55:42 DEBUG TaskMemoryManager: Task 475 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@21cd90bf
18/03/19 07:55:42 DEBUG TaskMemoryManager: Task 474 release 75.3 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@54eec656
18/03/19 07:55:42 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=61
18/03/19 07:55:42 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000061_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000061
18/03/19 07:55:42 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000061_0: Committed
18/03/19 07:55:42 INFO Executor: Finished task 61.0 in stage 16.0 (TID 474). 1502 bytes result sent to driver
18/03/19 07:55:42 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:42 INFO TaskSetManager: Starting task 63.0 in stage 16.0 (TID 476, localhost, executor driver, partition 63, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:42 INFO Executor: Running task 63.0 in stage 16.0 (TID 476)
18/03/19 07:55:42 INFO TaskSetManager: Finished task 61.0 in stage 16.0 (TID 474) in 4584 ms on localhost (executor driver) (62/96)
18/03/19 07:55:42 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 63-64
18/03/19 07:55:42 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:42 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:42 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:55:42 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 63-64
18/03/19 07:55:42 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:42 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:42 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:42 DEBUG TaskMemoryManager: Task 475 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@7096c4c
18/03/19 07:55:42 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=62
18/03/19 07:55:42 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000062_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000062
18/03/19 07:55:42 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000062_0: Committed
18/03/19 07:55:42 INFO Executor: Finished task 62.0 in stage 16.0 (TID 475). 1502 bytes result sent to driver
18/03/19 07:55:42 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:42 INFO TaskSetManager: Starting task 64.0 in stage 16.0 (TID 477, localhost, executor driver, partition 64, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:42 INFO TaskSetManager: Finished task 62.0 in stage 16.0 (TID 475) in 4230 ms on localhost (executor driver) (63/96)
18/03/19 07:55:42 INFO Executor: Running task 64.0 in stage 16.0 (TID 477)
18/03/19 07:55:42 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 64-65
18/03/19 07:55:42 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:42 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:42 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:42 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 64-65
18/03/19 07:55:42 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:42 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:42 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:42 DEBUG TaskMemoryManager: Task 476 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@8ba80e6
18/03/19 07:55:43 DEBUG TaskMemoryManager: Task 477 acquired 5.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@58013df3
18/03/19 07:55:43 DEBUG TaskMemoryManager: Task 476 acquired 10.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@8ba80e6
18/03/19 07:55:43 DEBUG TaskMemoryManager: Task 477 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@58013df3
18/03/19 07:55:44 DEBUG TaskMemoryManager: Task 476 acquired 20.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@8ba80e6
18/03/19 07:55:44 DEBUG TaskMemoryManager: Task 477 acquired 20.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@58013df3
18/03/19 07:55:45 DEBUG TaskMemoryManager: Task 476 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@25bfea25
18/03/19 07:55:45 DEBUG TaskMemoryManager: Task 477 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@79178c9f
18/03/19 07:55:46 DEBUG TaskMemoryManager: Task 476 acquired 10.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@25bfea25
18/03/19 07:55:46 DEBUG TaskMemoryManager: Task 477 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@79178c9f
18/03/19 07:55:46 DEBUG TaskMemoryManager: Task 476 acquired 20.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@25bfea25
18/03/19 07:55:46 DEBUG TaskMemoryManager: Task 477 acquired 21.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@79178c9f
18/03/19 07:55:46 DEBUG TaskMemoryManager: Task 476 acquired 40.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@25bfea25
18/03/19 07:55:46 DEBUG TaskMemoryManager: Task 477 acquired 41.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@79178c9f
18/03/19 07:55:46 DEBUG TaskMemoryManager: Task 476 release 35.7 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@8ba80e6
18/03/19 07:55:46 DEBUG TaskMemoryManager: Task 477 release 35.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@58013df3
18/03/19 07:55:48 DEBUG TaskMemoryManager: Task 476 release 75.7 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@25bfea25
18/03/19 07:55:48 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=63
18/03/19 07:55:48 DEBUG TaskMemoryManager: Task 477 release 78.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@79178c9f
18/03/19 07:55:48 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000063_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000063
18/03/19 07:55:48 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=64
18/03/19 07:55:48 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000063_0: Committed
18/03/19 07:55:48 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000064_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000064
18/03/19 07:55:48 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000064_0: Committed
18/03/19 07:55:48 INFO Executor: Finished task 63.0 in stage 16.0 (TID 476). 1502 bytes result sent to driver
18/03/19 07:55:48 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:48 INFO TaskSetManager: Starting task 65.0 in stage 16.0 (TID 478, localhost, executor driver, partition 65, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:48 INFO Executor: Running task 65.0 in stage 16.0 (TID 478)
18/03/19 07:55:48 INFO TaskSetManager: Finished task 63.0 in stage 16.0 (TID 476) in 5495 ms on localhost (executor driver) (64/96)
18/03/19 07:55:48 INFO Executor: Finished task 64.0 in stage 16.0 (TID 477). 1545 bytes result sent to driver
18/03/19 07:55:48 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:48 INFO TaskSetManager: Starting task 66.0 in stage 16.0 (TID 479, localhost, executor driver, partition 66, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:48 INFO Executor: Running task 66.0 in stage 16.0 (TID 479)
18/03/19 07:55:48 INFO TaskSetManager: Finished task 64.0 in stage 16.0 (TID 477) in 5447 ms on localhost (executor driver) (65/96)
18/03/19 07:55:48 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 66-67
18/03/19 07:55:48 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:48 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:48 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:48 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 66-67
18/03/19 07:55:48 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:48 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:48 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:48 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 65-66
18/03/19 07:55:48 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:48 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:48 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:55:48 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 65-66
18/03/19 07:55:48 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:48 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:48 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:48 DEBUG TaskMemoryManager: Task 478 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@361ca240
18/03/19 07:55:48 DEBUG TaskMemoryManager: Task 479 acquired 5.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@47b6fb1e
18/03/19 07:55:49 DEBUG TaskMemoryManager: Task 479 acquired 10.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@47b6fb1e
18/03/19 07:55:49 DEBUG TaskMemoryManager: Task 478 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@361ca240
18/03/19 07:55:50 DEBUG TaskMemoryManager: Task 479 acquired 20.9 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@47b6fb1e
18/03/19 07:55:50 DEBUG TaskMemoryManager: Task 478 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@361ca240
18/03/19 07:55:51 DEBUG TaskMemoryManager: Task 478 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2a63c84d
18/03/19 07:55:51 DEBUG TaskMemoryManager: Task 479 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5bf33529
18/03/19 07:55:51 DEBUG TaskMemoryManager: Task 478 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2a63c84d
18/03/19 07:55:51 DEBUG TaskMemoryManager: Task 479 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5bf33529
18/03/19 07:55:51 DEBUG TaskMemoryManager: Task 478 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2a63c84d
18/03/19 07:55:51 DEBUG TaskMemoryManager: Task 479 acquired 20.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5bf33529
18/03/19 07:55:51 DEBUG TaskMemoryManager: Task 478 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2a63c84d
18/03/19 07:55:51 DEBUG TaskMemoryManager: Task 478 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@361ca240
18/03/19 07:55:52 DEBUG TaskMemoryManager: Task 478 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2a63c84d
18/03/19 07:55:52 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=65
18/03/19 07:55:52 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000065_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000065
18/03/19 07:55:52 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000065_0: Committed
18/03/19 07:55:52 INFO Executor: Finished task 65.0 in stage 16.0 (TID 478). 1502 bytes result sent to driver
18/03/19 07:55:52 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:52 INFO TaskSetManager: Starting task 67.0 in stage 16.0 (TID 480, localhost, executor driver, partition 67, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:52 INFO TaskSetManager: Finished task 65.0 in stage 16.0 (TID 478) in 3735 ms on localhost (executor driver) (66/96)
18/03/19 07:55:52 INFO Executor: Running task 67.0 in stage 16.0 (TID 480)
18/03/19 07:55:52 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 67-68
18/03/19 07:55:52 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:52 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:52 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:52 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 67-68
18/03/19 07:55:52 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:52 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:52 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:52 DEBUG TaskMemoryManager: Task 479 acquired 40.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5bf33529
18/03/19 07:55:52 DEBUG TaskMemoryManager: Task 480 acquired 5.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4e5a6fc6
18/03/19 07:55:52 DEBUG TaskMemoryManager: Task 479 release 36.3 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@47b6fb1e
18/03/19 07:55:52 DEBUG TaskMemoryManager: Task 479 release 76.3 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5bf33529
18/03/19 07:55:52 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=66
18/03/19 07:55:52 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000066_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000066
18/03/19 07:55:52 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000066_0: Committed
18/03/19 07:55:52 INFO Executor: Finished task 66.0 in stage 16.0 (TID 479). 1502 bytes result sent to driver
18/03/19 07:55:52 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:52 INFO TaskSetManager: Starting task 68.0 in stage 16.0 (TID 481, localhost, executor driver, partition 68, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:52 INFO Executor: Running task 68.0 in stage 16.0 (TID 481)
18/03/19 07:55:52 INFO TaskSetManager: Finished task 66.0 in stage 16.0 (TID 479) in 4005 ms on localhost (executor driver) (67/96)
18/03/19 07:55:52 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 68-69
18/03/19 07:55:52 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:52 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:52 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:52 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 68-69
18/03/19 07:55:52 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:52 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:55:52 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:52 DEBUG TaskMemoryManager: Task 481 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@62f0b2f7
18/03/19 07:55:52 DEBUG TaskMemoryManager: Task 480 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4e5a6fc6
18/03/19 07:55:53 DEBUG TaskMemoryManager: Task 481 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@62f0b2f7
18/03/19 07:55:53 DEBUG TaskMemoryManager: Task 480 acquired 20.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4e5a6fc6
18/03/19 07:55:53 DEBUG TaskMemoryManager: Task 481 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@62f0b2f7
18/03/19 07:55:54 DEBUG TaskMemoryManager: Task 480 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3594c7e3
18/03/19 07:55:54 DEBUG TaskMemoryManager: Task 480 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3594c7e3
18/03/19 07:55:54 DEBUG TaskMemoryManager: Task 481 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2f4ab552
18/03/19 07:55:54 DEBUG TaskMemoryManager: Task 481 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2f4ab552
18/03/19 07:55:54 DEBUG TaskMemoryManager: Task 480 acquired 20.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3594c7e3
18/03/19 07:55:55 DEBUG TaskMemoryManager: Task 481 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2f4ab552
18/03/19 07:55:55 DEBUG TaskMemoryManager: Task 480 acquired 42.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3594c7e3
18/03/19 07:55:55 DEBUG TaskMemoryManager: Task 481 acquired 42.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2f4ab552
18/03/19 07:55:55 DEBUG TaskMemoryManager: Task 480 release 35.7 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@4e5a6fc6
18/03/19 07:55:55 DEBUG TaskMemoryManager: Task 480 release 77.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3594c7e3
18/03/19 07:55:55 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=67
18/03/19 07:55:55 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000067_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000067
18/03/19 07:55:55 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000067_0: Committed
18/03/19 07:55:55 INFO Executor: Finished task 67.0 in stage 16.0 (TID 480). 1502 bytes result sent to driver
18/03/19 07:55:55 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:55 INFO TaskSetManager: Starting task 69.0 in stage 16.0 (TID 482, localhost, executor driver, partition 69, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:55 INFO Executor: Running task 69.0 in stage 16.0 (TID 482)
18/03/19 07:55:55 INFO TaskSetManager: Finished task 67.0 in stage 16.0 (TID 480) in 3479 ms on localhost (executor driver) (68/96)
18/03/19 07:55:55 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 69-70
18/03/19 07:55:55 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:55 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:55 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:55 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 69-70
18/03/19 07:55:55 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:55 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:55 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:55 DEBUG TaskMemoryManager: Task 481 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@62f0b2f7
18/03/19 07:55:55 DEBUG TaskMemoryManager: Task 481 release 77.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2f4ab552
18/03/19 07:55:55 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=68
18/03/19 07:55:55 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000068_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000068
18/03/19 07:55:55 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000068_0: Committed
18/03/19 07:55:55 INFO Executor: Finished task 68.0 in stage 16.0 (TID 481). 1502 bytes result sent to driver
18/03/19 07:55:55 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:55 INFO TaskSetManager: Starting task 70.0 in stage 16.0 (TID 483, localhost, executor driver, partition 70, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:55 INFO Executor: Running task 70.0 in stage 16.0 (TID 483)
18/03/19 07:55:55 INFO TaskSetManager: Finished task 68.0 in stage 16.0 (TID 481) in 3388 ms on localhost (executor driver) (69/96)
18/03/19 07:55:55 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 70-71
18/03/19 07:55:55 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:55 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:55:55 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:55:55 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 70-71
18/03/19 07:55:55 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:55 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:55 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:55 DEBUG TaskMemoryManager: Task 482 acquired 5.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@736682ac
18/03/19 07:55:55 DEBUG TaskMemoryManager: Task 483 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3eb5d828
18/03/19 07:55:56 DEBUG TaskMemoryManager: Task 483 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3eb5d828
18/03/19 07:55:56 DEBUG TaskMemoryManager: Task 482 acquired 10.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@736682ac
18/03/19 07:55:56 DEBUG TaskMemoryManager: Task 483 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3eb5d828
18/03/19 07:55:57 DEBUG TaskMemoryManager: Task 482 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5edddb8
18/03/19 07:55:58 DEBUG TaskMemoryManager: Task 483 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@68f900da
18/03/19 07:55:58 DEBUG TaskMemoryManager: Task 482 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5edddb8
18/03/19 07:55:58 DEBUG TaskMemoryManager: Task 483 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@68f900da
18/03/19 07:55:58 DEBUG TaskMemoryManager: Task 482 acquired 20.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5edddb8
18/03/19 07:55:58 DEBUG TaskMemoryManager: Task 483 acquired 20.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@68f900da
18/03/19 07:55:58 DEBUG TaskMemoryManager: Task 483 acquired 48.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@68f900da
18/03/19 07:55:58 DEBUG TaskMemoryManager: Task 482 release 15.5 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@736682ac
18/03/19 07:55:58 DEBUG TaskMemoryManager: Task 482 release 35.7 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5edddb8
18/03/19 07:55:58 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=69
18/03/19 07:55:58 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000069_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000069
18/03/19 07:55:58 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000069_0: Committed
18/03/19 07:55:58 INFO Executor: Finished task 69.0 in stage 16.0 (TID 482). 1502 bytes result sent to driver
18/03/19 07:55:58 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:58 INFO TaskSetManager: Starting task 71.0 in stage 16.0 (TID 484, localhost, executor driver, partition 71, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:58 INFO Executor: Running task 71.0 in stage 16.0 (TID 484)
18/03/19 07:55:58 INFO TaskSetManager: Finished task 69.0 in stage 16.0 (TID 482) in 3106 ms on localhost (executor driver) (70/96)
18/03/19 07:55:58 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 71-72
18/03/19 07:55:58 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:58 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:58 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:58 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 71-72
18/03/19 07:55:58 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:58 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:58 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:58 DEBUG TaskMemoryManager: Task 483 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3eb5d828
18/03/19 07:55:58 DEBUG TaskMemoryManager: Task 483 release 84.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@68f900da
18/03/19 07:55:58 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=70
18/03/19 07:55:58 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000070_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000070
18/03/19 07:55:58 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000070_0: Committed
18/03/19 07:55:58 INFO Executor: Finished task 70.0 in stage 16.0 (TID 483). 1502 bytes result sent to driver
18/03/19 07:55:58 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:55:58 INFO TaskSetManager: Starting task 72.0 in stage 16.0 (TID 485, localhost, executor driver, partition 72, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:55:58 INFO Executor: Running task 72.0 in stage 16.0 (TID 485)
18/03/19 07:55:58 INFO TaskSetManager: Finished task 70.0 in stage 16.0 (TID 483) in 3103 ms on localhost (executor driver) (71/96)
18/03/19 07:55:58 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 72-73
18/03/19 07:55:58 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:58 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:55:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:58 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:55:58 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 72-73
18/03/19 07:55:58 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:55:58 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:55:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:55:58 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:55:59 DEBUG TaskMemoryManager: Task 484 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1a60e56a
18/03/19 07:55:59 DEBUG TaskMemoryManager: Task 485 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@21188274
18/03/19 07:55:59 DEBUG TaskMemoryManager: Task 485 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@21188274
18/03/19 07:55:59 DEBUG TaskMemoryManager: Task 484 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@1a60e56a
18/03/19 07:56:00 DEBUG TaskMemoryManager: Task 484 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3f922acf
18/03/19 07:56:01 DEBUG TaskMemoryManager: Task 484 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3f922acf
18/03/19 07:56:01 DEBUG TaskMemoryManager: Task 485 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7bd6b0e5
18/03/19 07:56:01 DEBUG TaskMemoryManager: Task 485 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7bd6b0e5
18/03/19 07:56:01 DEBUG TaskMemoryManager: Task 484 acquired 23.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3f922acf
18/03/19 07:56:01 DEBUG TaskMemoryManager: Task 485 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7bd6b0e5
18/03/19 07:56:01 DEBUG TaskMemoryManager: Task 484 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@1a60e56a
18/03/19 07:56:01 DEBUG TaskMemoryManager: Task 485 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@21188274
18/03/19 07:56:01 DEBUG TaskMemoryManager: Task 485 release 35.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@7bd6b0e5
18/03/19 07:56:01 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=72
18/03/19 07:56:01 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000072_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000072
18/03/19 07:56:01 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000072_0: Committed
18/03/19 07:56:01 INFO Executor: Finished task 72.0 in stage 16.0 (TID 485). 1502 bytes result sent to driver
18/03/19 07:56:01 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:56:01 INFO TaskSetManager: Starting task 73.0 in stage 16.0 (TID 486, localhost, executor driver, partition 73, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:56:01 INFO TaskSetManager: Finished task 72.0 in stage 16.0 (TID 485) in 3034 ms on localhost (executor driver) (72/96)
18/03/19 07:56:01 INFO Executor: Running task 73.0 in stage 16.0 (TID 486)
18/03/19 07:56:01 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 73-74
18/03/19 07:56:01 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:01 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:56:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:01 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:56:01 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 73-74
18/03/19 07:56:01 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:01 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:56:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:01 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:56:01 DEBUG TaskMemoryManager: Task 484 release 38.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3f922acf
18/03/19 07:56:01 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=71
18/03/19 07:56:01 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000071_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000071
18/03/19 07:56:01 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000071_0: Committed
18/03/19 07:56:01 INFO Executor: Finished task 71.0 in stage 16.0 (TID 484). 1502 bytes result sent to driver
18/03/19 07:56:01 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:56:01 INFO TaskSetManager: Starting task 74.0 in stage 16.0 (TID 487, localhost, executor driver, partition 74, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:56:01 INFO TaskSetManager: Finished task 71.0 in stage 16.0 (TID 484) in 3300 ms on localhost (executor driver) (73/96)
18/03/19 07:56:01 INFO Executor: Running task 74.0 in stage 16.0 (TID 487)
18/03/19 07:56:01 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 74-75
18/03/19 07:56:01 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:01 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:56:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:01 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:56:01 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 74-75
18/03/19 07:56:01 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:01 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:56:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:01 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:56:02 DEBUG TaskMemoryManager: Task 486 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@261ce894
18/03/19 07:56:02 DEBUG TaskMemoryManager: Task 487 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2dc4896d
18/03/19 07:56:02 DEBUG TaskMemoryManager: Task 486 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@261ce894
18/03/19 07:56:02 DEBUG TaskMemoryManager: Task 487 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2dc4896d
18/03/19 07:56:03 DEBUG TaskMemoryManager: Task 486 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@15c4da11
18/03/19 07:56:03 DEBUG TaskMemoryManager: Task 487 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3ced1635
18/03/19 07:56:03 DEBUG TaskMemoryManager: Task 486 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@15c4da11
18/03/19 07:56:03 DEBUG TaskMemoryManager: Task 487 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3ced1635
18/03/19 07:56:04 DEBUG TaskMemoryManager: Task 486 acquired 20.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@15c4da11
18/03/19 07:56:04 DEBUG TaskMemoryManager: Task 487 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3ced1635
18/03/19 07:56:04 DEBUG TaskMemoryManager: Task 486 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@261ce894
18/03/19 07:56:04 DEBUG TaskMemoryManager: Task 487 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2dc4896d
18/03/19 07:56:04 DEBUG TaskMemoryManager: Task 486 release 35.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@15c4da11
18/03/19 07:56:04 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=73
18/03/19 07:56:04 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000073_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000073
18/03/19 07:56:04 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000073_0: Committed
18/03/19 07:56:04 INFO Executor: Finished task 73.0 in stage 16.0 (TID 486). 1502 bytes result sent to driver
18/03/19 07:56:04 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:56:04 INFO TaskSetManager: Starting task 75.0 in stage 16.0 (TID 488, localhost, executor driver, partition 75, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:56:04 INFO Executor: Running task 75.0 in stage 16.0 (TID 488)
18/03/19 07:56:04 INFO TaskSetManager: Finished task 73.0 in stage 16.0 (TID 486) in 2478 ms on localhost (executor driver) (74/96)
18/03/19 07:56:04 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 75-76
18/03/19 07:56:04 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:04 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:56:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:04 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:56:04 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 75-76
18/03/19 07:56:04 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:04 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:56:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:04 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:56:04 DEBUG TaskMemoryManager: Task 487 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3ced1635
18/03/19 07:56:04 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=74
18/03/19 07:56:04 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000074_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000074
18/03/19 07:56:04 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000074_0: Committed
18/03/19 07:56:04 INFO Executor: Finished task 74.0 in stage 16.0 (TID 487). 1502 bytes result sent to driver
18/03/19 07:56:04 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:56:04 INFO TaskSetManager: Starting task 76.0 in stage 16.0 (TID 489, localhost, executor driver, partition 76, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:56:04 INFO Executor: Running task 76.0 in stage 16.0 (TID 489)
18/03/19 07:56:04 INFO TaskSetManager: Finished task 74.0 in stage 16.0 (TID 487) in 2415 ms on localhost (executor driver) (75/96)
18/03/19 07:56:04 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 76-77
18/03/19 07:56:04 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:04 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:56:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:04 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:56:04 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 76-77
18/03/19 07:56:04 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:04 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:56:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:56:04 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:56:04 DEBUG TaskMemoryManager: Task 489 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@24f8100c
18/03/19 07:56:04 DEBUG TaskMemoryManager: Task 488 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@54e27693
18/03/19 07:56:04 DEBUG TaskMemoryManager: Task 489 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@24f8100c
18/03/19 07:56:05 DEBUG TaskMemoryManager: Task 488 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@54e27693
18/03/19 07:56:06 DEBUG TaskMemoryManager: Task 488 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7516039c
18/03/19 07:56:06 DEBUG TaskMemoryManager: Task 489 acquired 5.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@13a5c164
18/03/19 07:56:06 DEBUG TaskMemoryManager: Task 488 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7516039c
18/03/19 07:56:06 DEBUG TaskMemoryManager: Task 489 acquired 10.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@13a5c164
18/03/19 07:56:06 DEBUG TaskMemoryManager: Task 489 acquired 22.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@13a5c164
18/03/19 07:56:06 DEBUG TaskMemoryManager: Task 488 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@7516039c
18/03/19 07:56:06 DEBUG TaskMemoryManager: Task 488 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@54e27693
18/03/19 07:56:06 DEBUG TaskMemoryManager: Task 488 release 35.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@7516039c
18/03/19 07:56:06 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=75
18/03/19 07:56:06 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000075_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000075
18/03/19 07:56:06 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000075_0: Committed
18/03/19 07:56:06 INFO Executor: Finished task 75.0 in stage 16.0 (TID 488). 1502 bytes result sent to driver
18/03/19 07:56:06 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:56:06 INFO TaskSetManager: Starting task 77.0 in stage 16.0 (TID 490, localhost, executor driver, partition 77, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:56:06 INFO TaskSetManager: Finished task 75.0 in stage 16.0 (TID 488) in 2525 ms on localhost (executor driver) (76/96)
18/03/19 07:56:06 INFO Executor: Running task 77.0 in stage 16.0 (TID 490)
18/03/19 07:56:06 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 77-78
18/03/19 07:56:06 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:06 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:56:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:06 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:56:06 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 77-78
18/03/19 07:56:06 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:06 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:56:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:56:06 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:56:06 DEBUG TaskMemoryManager: Task 489 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@24f8100c
18/03/19 07:56:06 DEBUG TaskMemoryManager: Task 489 release 37.4 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@13a5c164
18/03/19 07:56:06 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=76
18/03/19 07:56:06 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000076_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000076
18/03/19 07:56:06 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000076_0: Committed
18/03/19 07:56:06 INFO Executor: Finished task 76.0 in stage 16.0 (TID 489). 1502 bytes result sent to driver
18/03/19 07:56:06 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:56:06 INFO TaskSetManager: Starting task 78.0 in stage 16.0 (TID 491, localhost, executor driver, partition 78, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:56:06 INFO Executor: Running task 78.0 in stage 16.0 (TID 491)
18/03/19 07:56:06 INFO TaskSetManager: Finished task 76.0 in stage 16.0 (TID 489) in 2577 ms on localhost (executor driver) (77/96)
18/03/19 07:56:06 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 78-79
18/03/19 07:56:06 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:06 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:56:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:06 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:56:06 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 78-79
18/03/19 07:56:06 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:06 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:56:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:06 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:56:07 DEBUG TaskMemoryManager: Task 490 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2b346bb4
18/03/19 07:56:07 DEBUG TaskMemoryManager: Task 491 acquired 5.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@28965c2f
18/03/19 07:56:07 DEBUG TaskMemoryManager: Task 490 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2b346bb4
18/03/19 07:56:07 DEBUG TaskMemoryManager: Task 491 acquired 10.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@28965c2f
18/03/19 07:56:08 DEBUG TaskMemoryManager: Task 490 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@13e7ee7e
18/03/19 07:56:08 DEBUG TaskMemoryManager: Task 490 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@13e7ee7e
18/03/19 07:56:08 DEBUG TaskMemoryManager: Task 490 acquired 20.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@13e7ee7e
18/03/19 07:56:09 DEBUG TaskMemoryManager: Task 491 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@cb2de65
18/03/19 07:56:09 DEBUG TaskMemoryManager: Task 490 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2b346bb4
18/03/19 07:56:09 DEBUG TaskMemoryManager: Task 490 release 35.5 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@13e7ee7e
18/03/19 07:56:09 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=77
18/03/19 07:56:09 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000077_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000077
18/03/19 07:56:09 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000077_0: Committed
18/03/19 07:56:09 INFO Executor: Finished task 77.0 in stage 16.0 (TID 490). 1502 bytes result sent to driver
18/03/19 07:56:09 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:56:09 INFO TaskSetManager: Starting task 79.0 in stage 16.0 (TID 492, localhost, executor driver, partition 79, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:56:09 INFO Executor: Running task 79.0 in stage 16.0 (TID 492)
18/03/19 07:56:09 INFO TaskSetManager: Finished task 77.0 in stage 16.0 (TID 490) in 2544 ms on localhost (executor driver) (78/96)
18/03/19 07:56:09 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 79-80
18/03/19 07:56:09 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:09 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:56:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:09 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:56:09 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 79-80
18/03/19 07:56:09 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:09 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:56:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:09 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:56:09 DEBUG TaskMemoryManager: Task 491 acquired 10.5 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@cb2de65
18/03/19 07:56:09 DEBUG TaskMemoryManager: Task 491 acquired 21.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@cb2de65
18/03/19 07:56:09 DEBUG TaskMemoryManager: Task 492 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5bbd9b38
18/03/19 07:56:09 DEBUG TaskMemoryManager: Task 491 release 15.5 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@28965c2f
18/03/19 07:56:09 DEBUG TaskMemoryManager: Task 491 release 36.8 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@cb2de65
18/03/19 07:56:09 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=78
18/03/19 07:56:09 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000078_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000078
18/03/19 07:56:09 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000078_0: Committed
18/03/19 07:56:09 INFO Executor: Finished task 78.0 in stage 16.0 (TID 491). 1502 bytes result sent to driver
18/03/19 07:56:09 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:56:09 INFO TaskSetManager: Starting task 80.0 in stage 16.0 (TID 493, localhost, executor driver, partition 80, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:56:09 INFO TaskSetManager: Finished task 78.0 in stage 16.0 (TID 491) in 2863 ms on localhost (executor driver) (79/96)
18/03/19 07:56:09 INFO Executor: Running task 80.0 in stage 16.0 (TID 493)
18/03/19 07:56:09 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 80-81
18/03/19 07:56:09 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:09 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:56:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:09 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:56:09 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 80-81
18/03/19 07:56:09 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:09 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:56:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:09 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:56:10 DEBUG TaskMemoryManager: Task 493 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5e88611
18/03/19 07:56:10 DEBUG TaskMemoryManager: Task 492 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5bbd9b38
18/03/19 07:56:10 DEBUG TaskMemoryManager: Task 493 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5e88611
18/03/19 07:56:11 DEBUG TaskMemoryManager: Task 492 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@659e6f30
18/03/19 07:56:12 DEBUG TaskMemoryManager: Task 492 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@659e6f30
18/03/19 07:56:12 DEBUG TaskMemoryManager: Task 493 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@12ffe227
18/03/19 07:56:12 DEBUG TaskMemoryManager: Task 492 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@659e6f30
18/03/19 07:56:12 DEBUG TaskMemoryManager: Task 493 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@12ffe227
18/03/19 07:56:13 DEBUG TaskMemoryManager: Task 492 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5bbd9b38
18/03/19 07:56:13 DEBUG TaskMemoryManager: Task 492 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@659e6f30
18/03/19 07:56:13 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=79
18/03/19 07:56:13 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000079_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000079
18/03/19 07:56:13 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000079_0: Committed
18/03/19 07:56:13 INFO Executor: Finished task 79.0 in stage 16.0 (TID 492). 1502 bytes result sent to driver
18/03/19 07:56:13 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:56:13 INFO TaskSetManager: Starting task 81.0 in stage 16.0 (TID 494, localhost, executor driver, partition 81, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:56:13 INFO Executor: Running task 81.0 in stage 16.0 (TID 494)
18/03/19 07:56:13 INFO TaskSetManager: Finished task 79.0 in stage 16.0 (TID 492) in 3697 ms on localhost (executor driver) (80/96)
18/03/19 07:56:13 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 81-82
18/03/19 07:56:13 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:13 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:56:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:13 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:56:13 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 81-82
18/03/19 07:56:13 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:13 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:56:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:13 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:56:13 DEBUG TaskMemoryManager: Task 493 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@12ffe227
18/03/19 07:56:13 DEBUG TaskMemoryManager: Task 493 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5e88611
18/03/19 07:56:13 DEBUG TaskMemoryManager: Task 494 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@46f3b416
18/03/19 07:56:13 DEBUG TaskMemoryManager: Task 493 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@12ffe227
18/03/19 07:56:13 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=80
18/03/19 07:56:13 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000080_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000080
18/03/19 07:56:13 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000080_0: Committed
18/03/19 07:56:13 INFO Executor: Finished task 80.0 in stage 16.0 (TID 493). 1502 bytes result sent to driver
18/03/19 07:56:13 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:56:13 INFO TaskSetManager: Starting task 82.0 in stage 16.0 (TID 495, localhost, executor driver, partition 82, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:56:13 INFO TaskSetManager: Finished task 80.0 in stage 16.0 (TID 493) in 3643 ms on localhost (executor driver) (81/96)
18/03/19 07:56:13 INFO Executor: Running task 82.0 in stage 16.0 (TID 495)
18/03/19 07:56:13 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 82-83
18/03/19 07:56:13 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:13 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:56:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:56:13 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:56:13 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 82-83
18/03/19 07:56:13 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:13 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:56:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:13 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:56:13 DEBUG TaskMemoryManager: Task 495 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@192685ea
18/03/19 07:56:14 DEBUG TaskMemoryManager: Task 494 acquired 10.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@46f3b416
18/03/19 07:56:14 DEBUG TaskMemoryManager: Task 495 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@192685ea
18/03/19 07:56:15 DEBUG TaskMemoryManager: Task 494 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@61ec7ffb
18/03/19 07:56:16 DEBUG TaskMemoryManager: Task 495 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6d1d445e
18/03/19 07:56:16 DEBUG TaskMemoryManager: Task 494 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@61ec7ffb
18/03/19 07:56:16 DEBUG TaskMemoryManager: Task 495 acquired 10.7 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6d1d445e
18/03/19 07:56:16 DEBUG TaskMemoryManager: Task 494 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@61ec7ffb
18/03/19 07:56:16 DEBUG TaskMemoryManager: Task 495 acquired 20.7 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6d1d445e
18/03/19 07:56:16 DEBUG TaskMemoryManager: Task 494 acquired 40.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@61ec7ffb
18/03/19 07:56:16 DEBUG TaskMemoryManager: Task 494 release 15.4 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@46f3b416
18/03/19 07:56:16 DEBUG TaskMemoryManager: Task 494 release 75.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@61ec7ffb
18/03/19 07:56:16 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=81
18/03/19 07:56:16 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000081_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000081
18/03/19 07:56:16 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000081_0: Committed
18/03/19 07:56:16 INFO Executor: Finished task 81.0 in stage 16.0 (TID 494). 1502 bytes result sent to driver
18/03/19 07:56:16 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:56:16 INFO TaskSetManager: Starting task 83.0 in stage 16.0 (TID 496, localhost, executor driver, partition 83, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:56:16 INFO TaskSetManager: Finished task 81.0 in stage 16.0 (TID 494) in 3528 ms on localhost (executor driver) (82/96)
18/03/19 07:56:16 INFO Executor: Running task 83.0 in stage 16.0 (TID 496)
18/03/19 07:56:16 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 83-84
18/03/19 07:56:16 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:16 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:56:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:16 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:56:16 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 83-84
18/03/19 07:56:16 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:16 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:56:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/19 07:56:16 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:56:16 DEBUG TaskMemoryManager: Task 495 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@192685ea
18/03/19 07:56:16 DEBUG TaskMemoryManager: Task 495 release 36.4 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@6d1d445e
18/03/19 07:56:16 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=82
18/03/19 07:56:16 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000082_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000082
18/03/19 07:56:16 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000082_0: Committed
18/03/19 07:56:16 INFO Executor: Finished task 82.0 in stage 16.0 (TID 495). 1502 bytes result sent to driver
18/03/19 07:56:16 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:56:16 INFO TaskSetManager: Starting task 84.0 in stage 16.0 (TID 497, localhost, executor driver, partition 84, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:56:16 INFO TaskSetManager: Finished task 82.0 in stage 16.0 (TID 495) in 3292 ms on localhost (executor driver) (83/96)
18/03/19 07:56:16 INFO Executor: Running task 84.0 in stage 16.0 (TID 497)
18/03/19 07:56:16 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 84-85
18/03/19 07:56:16 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:16 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:56:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:16 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:56:16 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 84-85
18/03/19 07:56:16 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:16 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:56:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:16 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:56:16 DEBUG TaskMemoryManager: Task 496 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2d8a69ef
18/03/19 07:56:17 DEBUG TaskMemoryManager: Task 497 acquired 5.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@17e1f1c4
18/03/19 07:56:17 DEBUG TaskMemoryManager: Task 496 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2d8a69ef
18/03/19 07:56:17 DEBUG TaskMemoryManager: Task 497 acquired 10.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@17e1f1c4
18/03/19 07:56:18 DEBUG TaskMemoryManager: Task 496 acquired 20.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2d8a69ef
18/03/19 07:56:18 TRACE HeartbeatReceiver: Checking for hosts with no recent heartbeats in HeartbeatReceiver.
18/03/19 07:56:18 DEBUG TaskMemoryManager: Task 497 acquired 20.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@17e1f1c4
18/03/19 07:56:19 DEBUG TaskMemoryManager: Task 496 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2a833c7e
18/03/19 07:56:19 DEBUG TaskMemoryManager: Task 497 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@156ff69b
18/03/19 07:56:19 DEBUG TaskMemoryManager: Task 496 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2a833c7e
18/03/19 07:56:19 DEBUG TaskMemoryManager: Task 497 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@156ff69b
18/03/19 07:56:19 DEBUG TaskMemoryManager: Task 497 acquired 20.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@156ff69b
18/03/19 07:56:19 DEBUG TaskMemoryManager: Task 496 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2a833c7e
18/03/19 07:56:20 DEBUG TaskMemoryManager: Task 496 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@2a833c7e
18/03/19 07:56:20 DEBUG TaskMemoryManager: Task 496 release 35.3 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2d8a69ef
18/03/19 07:56:20 DEBUG TaskMemoryManager: Task 497 acquired 42.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@156ff69b
18/03/19 07:56:20 DEBUG TaskMemoryManager: Task 496 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@2a833c7e
18/03/19 07:56:20 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=83
18/03/19 07:56:20 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000083_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000083
18/03/19 07:56:20 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000083_0: Committed
18/03/19 07:56:20 INFO Executor: Finished task 83.0 in stage 16.0 (TID 496). 1502 bytes result sent to driver
18/03/19 07:56:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:56:20 INFO TaskSetManager: Starting task 85.0 in stage 16.0 (TID 498, localhost, executor driver, partition 85, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:56:20 INFO Executor: Running task 85.0 in stage 16.0 (TID 498)
18/03/19 07:56:20 INFO TaskSetManager: Finished task 83.0 in stage 16.0 (TID 496) in 3645 ms on localhost (executor driver) (84/96)
18/03/19 07:56:20 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 85-86
18/03/19 07:56:20 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:20 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:56:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:20 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:56:20 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 85-86
18/03/19 07:56:20 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:20 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:56:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:20 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:56:20 DEBUG TaskMemoryManager: Task 497 release 35.5 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@17e1f1c4
18/03/19 07:56:20 DEBUG TaskMemoryManager: Task 497 release 77.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@156ff69b
18/03/19 07:56:20 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=84
18/03/19 07:56:20 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000084_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000084
18/03/19 07:56:20 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000084_0: Committed
18/03/19 07:56:20 INFO Executor: Finished task 84.0 in stage 16.0 (TID 497). 1502 bytes result sent to driver
18/03/19 07:56:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:56:20 INFO TaskSetManager: Starting task 86.0 in stage 16.0 (TID 499, localhost, executor driver, partition 86, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:56:20 INFO TaskSetManager: Finished task 84.0 in stage 16.0 (TID 497) in 3605 ms on localhost (executor driver) (85/96)
18/03/19 07:56:20 INFO Executor: Running task 86.0 in stage 16.0 (TID 499)
18/03/19 07:56:20 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 86-87
18/03/19 07:56:20 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:20 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:56:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:20 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:56:20 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 86-87
18/03/19 07:56:20 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:20 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:56:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:20 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:56:20 DEBUG TaskMemoryManager: Task 499 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@301022ab
18/03/19 07:56:20 DEBUG TaskMemoryManager: Task 498 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3725e761
18/03/19 07:56:21 DEBUG TaskMemoryManager: Task 499 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@301022ab
18/03/19 07:56:21 DEBUG TaskMemoryManager: Task 498 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3725e761
18/03/19 07:56:22 DEBUG TaskMemoryManager: Task 499 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@301022ab
18/03/19 07:56:22 DEBUG TaskMemoryManager: Task 498 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@597c164c
18/03/19 07:56:23 DEBUG TaskMemoryManager: Task 498 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@597c164c
18/03/19 07:56:23 DEBUG TaskMemoryManager: Task 499 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@48df492c
18/03/19 07:56:23 DEBUG TaskMemoryManager: Task 498 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@597c164c
18/03/19 07:56:23 DEBUG TaskMemoryManager: Task 499 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@48df492c
18/03/19 07:56:23 DEBUG TaskMemoryManager: Task 499 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@48df492c
18/03/19 07:56:23 DEBUG TaskMemoryManager: Task 498 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@597c164c
18/03/19 07:56:23 DEBUG TaskMemoryManager: Task 498 release 15.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3725e761
18/03/19 07:56:23 DEBUG TaskMemoryManager: Task 498 release 75.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@597c164c
18/03/19 07:56:23 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=85
18/03/19 07:56:23 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000085_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000085
18/03/19 07:56:23 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000085_0: Committed
18/03/19 07:56:23 INFO Executor: Finished task 85.0 in stage 16.0 (TID 498). 1502 bytes result sent to driver
18/03/19 07:56:23 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:56:23 INFO TaskSetManager: Starting task 87.0 in stage 16.0 (TID 500, localhost, executor driver, partition 87, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:56:23 INFO TaskSetManager: Finished task 85.0 in stage 16.0 (TID 498) in 3549 ms on localhost (executor driver) (86/96)
18/03/19 07:56:23 INFO Executor: Running task 87.0 in stage 16.0 (TID 500)
18/03/19 07:56:23 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 87-88
18/03/19 07:56:23 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:23 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:56:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:23 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:56:23 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 87-88
18/03/19 07:56:23 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:23 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:56:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:23 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:56:23 DEBUG TaskMemoryManager: Task 499 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@48df492c
18/03/19 07:56:24 DEBUG TaskMemoryManager: Task 499 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@301022ab
18/03/19 07:56:24 DEBUG TaskMemoryManager: Task 499 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@48df492c
18/03/19 07:56:24 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=86
18/03/19 07:56:24 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000086_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000086
18/03/19 07:56:24 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000086_0: Committed
18/03/19 07:56:24 INFO Executor: Finished task 86.0 in stage 16.0 (TID 499). 1502 bytes result sent to driver
18/03/19 07:56:24 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:56:24 INFO TaskSetManager: Starting task 88.0 in stage 16.0 (TID 501, localhost, executor driver, partition 88, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:56:24 INFO Executor: Running task 88.0 in stage 16.0 (TID 501)
18/03/19 07:56:24 INFO TaskSetManager: Finished task 86.0 in stage 16.0 (TID 499) in 3822 ms on localhost (executor driver) (87/96)
18/03/19 07:56:24 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 88-89
18/03/19 07:56:24 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:24 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:56:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:24 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:56:24 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 88-89
18/03/19 07:56:24 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:24 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:56:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:24 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:56:24 DEBUG TaskMemoryManager: Task 500 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4364736b
18/03/19 07:56:24 DEBUG TaskMemoryManager: Task 501 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3b7bd8a7
18/03/19 07:56:24 DEBUG TaskMemoryManager: Task 500 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4364736b
18/03/19 07:56:24 DEBUG TaskMemoryManager: Task 501 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3b7bd8a7
18/03/19 07:56:25 DEBUG TaskMemoryManager: Task 501 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3b7bd8a7
18/03/19 07:56:25 DEBUG TaskMemoryManager: Task 500 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@4364736b
18/03/19 07:56:26 DEBUG TaskMemoryManager: Task 500 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5fbd2023
18/03/19 07:56:26 DEBUG TaskMemoryManager: Task 500 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5fbd2023
18/03/19 07:56:27 DEBUG TaskMemoryManager: Task 500 acquired 20.7 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5fbd2023
18/03/19 07:56:27 DEBUG TaskMemoryManager: Task 501 acquired 5.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@217be05e
18/03/19 07:56:27 DEBUG TaskMemoryManager: Task 500 acquired 40.7 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5fbd2023
18/03/19 07:56:27 DEBUG TaskMemoryManager: Task 500 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@4364736b
18/03/19 07:56:27 DEBUG TaskMemoryManager: Task 501 acquired 10.4 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@217be05e
18/03/19 07:56:27 DEBUG TaskMemoryManager: Task 500 release 76.5 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5fbd2023
18/03/19 07:56:27 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=87
18/03/19 07:56:27 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000087_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000087
18/03/19 07:56:27 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000087_0: Committed
18/03/19 07:56:27 INFO Executor: Finished task 87.0 in stage 16.0 (TID 500). 1502 bytes result sent to driver
18/03/19 07:56:27 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:56:27 INFO TaskSetManager: Starting task 89.0 in stage 16.0 (TID 502, localhost, executor driver, partition 89, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:56:27 INFO Executor: Running task 89.0 in stage 16.0 (TID 502)
18/03/19 07:56:27 INFO TaskSetManager: Finished task 87.0 in stage 16.0 (TID 500) in 3940 ms on localhost (executor driver) (88/96)
18/03/19 07:56:27 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 89-90
18/03/19 07:56:27 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:27 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:56:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:27 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  2 ms
18/03/19 07:56:27 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 89-90
18/03/19 07:56:27 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:27 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:56:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:27 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:56:27 DEBUG TaskMemoryManager: Task 502 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@482546f7
18/03/19 07:56:27 DEBUG TaskMemoryManager: Task 501 acquired 20.9 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@217be05e
18/03/19 07:56:28 DEBUG TaskMemoryManager: Task 501 acquired 45.7 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@217be05e
18/03/19 07:56:28 DEBUG TaskMemoryManager: Task 502 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@482546f7
18/03/19 07:56:28 DEBUG TaskMemoryManager: Task 501 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3b7bd8a7
18/03/19 07:56:28 DEBUG TaskMemoryManager: Task 501 release 82.5 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@217be05e
18/03/19 07:56:28 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=88
18/03/19 07:56:28 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000088_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000088
18/03/19 07:56:28 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000088_0: Committed
18/03/19 07:56:28 INFO Executor: Finished task 88.0 in stage 16.0 (TID 501). 1502 bytes result sent to driver
18/03/19 07:56:28 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:56:28 INFO TaskSetManager: Starting task 90.0 in stage 16.0 (TID 503, localhost, executor driver, partition 90, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:56:28 INFO Executor: Running task 90.0 in stage 16.0 (TID 503)
18/03/19 07:56:28 INFO TaskSetManager: Finished task 88.0 in stage 16.0 (TID 501) in 4486 ms on localhost (executor driver) (89/96)
18/03/19 07:56:28 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 90-91
18/03/19 07:56:28 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:28 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:56:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:28 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:56:28 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 90-91
18/03/19 07:56:28 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:28 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:56:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:28 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:56:28 DEBUG TaskMemoryManager: Task 503 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@daf3b67
18/03/19 07:56:29 DEBUG TaskMemoryManager: Task 502 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@482546f7
18/03/19 07:56:29 DEBUG TaskMemoryManager: Task 503 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@daf3b67
18/03/19 07:56:30 DEBUG TaskMemoryManager: Task 502 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5e5c9f93
18/03/19 07:56:31 DEBUG TaskMemoryManager: Task 503 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@daf3b67
18/03/19 07:56:31 DEBUG TaskMemoryManager: Task 502 acquired 10.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5e5c9f93
18/03/19 07:56:31 DEBUG TaskMemoryManager: Task 502 acquired 20.2 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5e5c9f93
18/03/19 07:56:31 DEBUG TaskMemoryManager: Task 502 acquired 40.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@5e5c9f93
18/03/19 07:56:31 DEBUG TaskMemoryManager: Task 502 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@482546f7
18/03/19 07:56:31 DEBUG TaskMemoryManager: Task 502 release 75.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@5e5c9f93
18/03/19 07:56:31 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=89
18/03/19 07:56:31 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000089_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000089
18/03/19 07:56:31 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000089_0: Committed
18/03/19 07:56:31 INFO Executor: Finished task 89.0 in stage 16.0 (TID 502). 1502 bytes result sent to driver
18/03/19 07:56:31 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:56:31 INFO TaskSetManager: Starting task 91.0 in stage 16.0 (TID 504, localhost, executor driver, partition 91, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:56:31 INFO Executor: Running task 91.0 in stage 16.0 (TID 504)
18/03/19 07:56:31 INFO TaskSetManager: Finished task 89.0 in stage 16.0 (TID 502) in 4213 ms on localhost (executor driver) (90/96)
18/03/19 07:56:31 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 91-92
18/03/19 07:56:31 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:31 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:56:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:31 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:56:31 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 91-92
18/03/19 07:56:31 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:31 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:56:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:31 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:56:32 DEBUG TaskMemoryManager: Task 504 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@31ed27a3
18/03/19 07:56:32 DEBUG TaskMemoryManager: Task 503 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@62599517
18/03/19 07:56:32 DEBUG TaskMemoryManager: Task 504 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@31ed27a3
18/03/19 07:56:32 DEBUG TaskMemoryManager: Task 503 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@62599517
18/03/19 07:56:33 DEBUG TaskMemoryManager: Task 503 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@62599517
18/03/19 07:56:33 DEBUG TaskMemoryManager: Task 503 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@62599517
18/03/19 07:56:33 DEBUG TaskMemoryManager: Task 503 release 35.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@daf3b67
18/03/19 07:56:33 DEBUG TaskMemoryManager: Task 503 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@62599517
18/03/19 07:56:33 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=90
18/03/19 07:56:33 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000090_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000090
18/03/19 07:56:33 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000090_0: Committed
18/03/19 07:56:33 INFO Executor: Finished task 90.0 in stage 16.0 (TID 503). 1502 bytes result sent to driver
18/03/19 07:56:33 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:56:33 INFO TaskSetManager: Starting task 92.0 in stage 16.0 (TID 505, localhost, executor driver, partition 92, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:56:33 INFO TaskSetManager: Finished task 90.0 in stage 16.0 (TID 503) in 4964 ms on localhost (executor driver) (91/96)
18/03/19 07:56:33 INFO Executor: Running task 92.0 in stage 16.0 (TID 505)
18/03/19 07:56:33 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 92-93
18/03/19 07:56:33 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:33 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:56:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:33 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:56:33 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 92-93
18/03/19 07:56:33 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:33 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:56:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:33 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:56:33 DEBUG TaskMemoryManager: Task 504 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@31ed27a3
18/03/19 07:56:33 DEBUG TaskMemoryManager: Task 505 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3c7bb8fb
18/03/19 07:56:34 DEBUG TaskMemoryManager: Task 505 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3c7bb8fb
18/03/19 07:56:35 DEBUG TaskMemoryManager: Task 504 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@563c627b
18/03/19 07:56:35 DEBUG TaskMemoryManager: Task 504 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@563c627b
18/03/19 07:56:35 DEBUG TaskMemoryManager: Task 505 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3c7bb8fb
18/03/19 07:56:35 DEBUG TaskMemoryManager: Task 504 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@563c627b
18/03/19 07:56:35 DEBUG TaskMemoryManager: Task 504 acquired 40.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@563c627b
18/03/19 07:56:36 DEBUG TaskMemoryManager: Task 504 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@31ed27a3
18/03/19 07:56:36 DEBUG TaskMemoryManager: Task 504 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@563c627b
18/03/19 07:56:36 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=91
18/03/19 07:56:36 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000091_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000091
18/03/19 07:56:36 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000091_0: Committed
18/03/19 07:56:36 INFO Executor: Finished task 91.0 in stage 16.0 (TID 504). 1502 bytes result sent to driver
18/03/19 07:56:36 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:56:36 INFO TaskSetManager: Starting task 93.0 in stage 16.0 (TID 506, localhost, executor driver, partition 93, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:56:36 INFO Executor: Running task 93.0 in stage 16.0 (TID 506)
18/03/19 07:56:36 INFO TaskSetManager: Finished task 91.0 in stage 16.0 (TID 504) in 4265 ms on localhost (executor driver) (92/96)
18/03/19 07:56:36 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 93-94
18/03/19 07:56:36 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:36 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:56:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:36 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:56:36 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 93-94
18/03/19 07:56:36 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:36 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:56:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:36 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:56:36 DEBUG TaskMemoryManager: Task 506 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@57b5ecbf
18/03/19 07:56:36 DEBUG TaskMemoryManager: Task 506 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@57b5ecbf
18/03/19 07:56:37 DEBUG TaskMemoryManager: Task 505 acquired 5.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@58cdc048
18/03/19 07:56:37 DEBUG TaskMemoryManager: Task 505 acquired 10.6 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@58cdc048
18/03/19 07:56:37 DEBUG TaskMemoryManager: Task 505 acquired 21.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@58cdc048
18/03/19 07:56:37 DEBUG TaskMemoryManager: Task 506 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@57b5ecbf
18/03/19 07:56:38 DEBUG TaskMemoryManager: Task 505 acquired 47.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@58cdc048
18/03/19 07:56:38 DEBUG TaskMemoryManager: Task 505 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3c7bb8fb
18/03/19 07:56:38 DEBUG TaskMemoryManager: Task 505 release 84.6 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@58cdc048
18/03/19 07:56:38 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=92
18/03/19 07:56:38 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000092_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000092
18/03/19 07:56:38 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000092_0: Committed
18/03/19 07:56:38 INFO Executor: Finished task 92.0 in stage 16.0 (TID 505). 1502 bytes result sent to driver
18/03/19 07:56:38 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:56:38 INFO TaskSetManager: Starting task 94.0 in stage 16.0 (TID 507, localhost, executor driver, partition 94, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:56:38 INFO TaskSetManager: Finished task 92.0 in stage 16.0 (TID 505) in 4738 ms on localhost (executor driver) (93/96)
18/03/19 07:56:38 INFO Executor: Running task 94.0 in stage 16.0 (TID 507)
18/03/19 07:56:38 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 94-95
18/03/19 07:56:38 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:38 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:56:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:38 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:56:38 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 94-95
18/03/19 07:56:38 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:38 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:56:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:38 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:56:38 DEBUG TaskMemoryManager: Task 507 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3b0a356c
18/03/19 07:56:39 DEBUG TaskMemoryManager: Task 507 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3b0a356c
18/03/19 07:56:39 DEBUG TaskMemoryManager: Task 506 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3d39959a
18/03/19 07:56:40 DEBUG TaskMemoryManager: Task 507 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3b0a356c
18/03/19 07:56:40 DEBUG TaskMemoryManager: Task 506 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3d39959a
18/03/19 07:56:40 DEBUG TaskMemoryManager: Task 506 acquired 25.3 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3d39959a
18/03/19 07:56:40 DEBUG TaskMemoryManager: Task 506 acquired 48.9 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@3d39959a
18/03/19 07:56:40 DEBUG TaskMemoryManager: Task 506 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@57b5ecbf
18/03/19 07:56:40 DEBUG TaskMemoryManager: Task 506 release 89.2 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3d39959a
18/03/19 07:56:40 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=93
18/03/19 07:56:40 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000093_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000093
18/03/19 07:56:40 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000093_0: Committed
18/03/19 07:56:40 INFO Executor: Finished task 93.0 in stage 16.0 (TID 506). 1502 bytes result sent to driver
18/03/19 07:56:40 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:56:40 INFO TaskSetManager: Starting task 95.0 in stage 16.0 (TID 508, localhost, executor driver, partition 95, PROCESS_LOCAL, 7712 bytes)
18/03/19 07:56:40 INFO Executor: Running task 95.0 in stage 16.0 (TID 508)
18/03/19 07:56:40 INFO TaskSetManager: Finished task 93.0 in stage 16.0 (TID 506) in 4619 ms on localhost (executor driver) (94/96)
18/03/19 07:56:40 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 0, partitions 95-96
18/03/19 07:56:40 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:40 INFO ShuffleBlockFetcherIterator: Getting 96 non-empty blocks out of 96 blocks
18/03/19 07:56:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:40 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  1 ms
18/03/19 07:56:40 DEBUG MapOutputTrackerMaster: Fetching outputs for shuffle 1, partitions 95-96
18/03/19 07:56:40 DEBUG ShuffleBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
18/03/19 07:56:40 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
18/03/19 07:56:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/19 07:56:40 DEBUG ShuffleBlockFetcherIterator: Got local blocks in  0 ms
18/03/19 07:56:41 DEBUG TaskMemoryManager: Task 508 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@26932221
18/03/19 07:56:41 DEBUG TaskMemoryManager: Task 508 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@26932221
18/03/19 07:56:41 DEBUG TaskMemoryManager: Task 507 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6939abba
18/03/19 07:56:41 DEBUG TaskMemoryManager: Task 507 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6939abba
18/03/19 07:56:42 DEBUG TaskMemoryManager: Task 507 acquired 21.8 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6939abba
18/03/19 07:56:42 DEBUG TaskMemoryManager: Task 508 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@26932221
18/03/19 07:56:42 DEBUG TaskMemoryManager: Task 507 acquired 41.9 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@6939abba
18/03/19 07:56:42 DEBUG TaskMemoryManager: Task 507 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@3b0a356c
18/03/19 07:56:42 DEBUG TaskMemoryManager: Task 507 release 78.7 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@6939abba
18/03/19 07:56:42 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=94
18/03/19 07:56:42 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000094_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000094
18/03/19 07:56:42 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000094_0: Committed
18/03/19 07:56:42 INFO Executor: Finished task 94.0 in stage 16.0 (TID 507). 1502 bytes result sent to driver
18/03/19 07:56:42 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 1
18/03/19 07:56:42 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
18/03/19 07:56:42 INFO TaskSetManager: Finished task 94.0 in stage 16.0 (TID 507) in 4446 ms on localhost (executor driver) (95/96)
18/03/19 07:56:43 DEBUG TaskMemoryManager: Task 508 acquired 5.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@77c87098
18/03/19 07:56:43 DEBUG TaskMemoryManager: Task 508 acquired 10.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@77c87098
18/03/19 07:56:43 DEBUG TaskMemoryManager: Task 508 acquired 20.0 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@77c87098
18/03/19 07:56:44 DEBUG TaskMemoryManager: Task 508 acquired 40.1 MB for org.apache.spark.util.collection.ExternalAppendOnlyMap@77c87098
18/03/19 07:56:44 DEBUG TaskMemoryManager: Task 508 release 35.0 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@26932221
18/03/19 07:56:44 DEBUG TaskMemoryManager: Task 508 release 75.1 MB from org.apache.spark.util.collection.ExternalAppendOnlyMap@77c87098
18/03/19 07:56:44 DEBUG OutputCommitCoordinator: Authorizing attemptNumber=0 to commit for stage=16, partition=95
18/03/19 07:56:44 INFO FileOutputCommitter: Saved output of task 'attempt_20180319075351_0017_m_000095_0' to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000095
18/03/19 07:56:44 INFO SparkHadoopMapRedUtil: attempt_20180319075351_0017_m_000095_0: Committed
18/03/19 07:56:44 INFO Executor: Finished task 95.0 in stage 16.0 (TID 508). 1502 bytes result sent to driver
18/03/19 07:56:44 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16.0, runningTasks: 0
18/03/19 07:56:44 INFO TaskSetManager: Finished task 95.0 in stage 16.0 (TID 508) in 3678 ms on localhost (executor driver) (96/96)
18/03/19 07:56:44 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
18/03/19 07:56:44 INFO DAGScheduler: ResultStage 16 (runJob at SparkHadoopWriter.scala:78) finished in 172.652 s
18/03/19 07:56:44 DEBUG DAGScheduler: After removal of stage 14, remaining stages = 2
18/03/19 07:56:44 DEBUG DAGScheduler: After removal of stage 16, remaining stages = 1
18/03/19 07:56:44 DEBUG DAGScheduler: After removal of stage 15, remaining stages = 0
18/03/19 07:56:44 INFO DAGScheduler: Job 10 finished: runJob at SparkHadoopWriter.scala:78, took 172.658936 s
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000000; isDirectory=true; modification_time=1521438835000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000000/part-00000; isDirectory=false; length=632950; replication=1; blocksize=33554432; modification_time=1521438835000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00000
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000001; isDirectory=true; modification_time=1521438836000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000001/part-00001; isDirectory=false; length=603409; replication=1; blocksize=33554432; modification_time=1521438837000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00001
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000002; isDirectory=true; modification_time=1521438839000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000002/part-00002; isDirectory=false; length=571680; replication=1; blocksize=33554432; modification_time=1521438839000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00002
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000003; isDirectory=true; modification_time=1521438840000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000003/part-00003; isDirectory=false; length=536610; replication=1; blocksize=33554432; modification_time=1521438840000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00003
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000004; isDirectory=true; modification_time=1521438842000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000004/part-00004; isDirectory=false; length=497479; replication=1; blocksize=33554432; modification_time=1521438842000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00004
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000005; isDirectory=true; modification_time=1521438844000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000005/part-00005; isDirectory=false; length=460916; replication=1; blocksize=33554432; modification_time=1521438844000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00005
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000006; isDirectory=true; modification_time=1521438846000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000006/part-00006; isDirectory=false; length=425111; replication=1; blocksize=33554432; modification_time=1521438847000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00006
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000007; isDirectory=true; modification_time=1521438848000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000007/part-00007; isDirectory=false; length=390959; replication=1; blocksize=33554432; modification_time=1521438848000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00007
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000008; isDirectory=true; modification_time=1521438849000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000008/part-00008; isDirectory=false; length=365224; replication=1; blocksize=33554432; modification_time=1521438849000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00008
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000009; isDirectory=true; modification_time=1521438850000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000009/part-00009; isDirectory=false; length=345099; replication=1; blocksize=33554432; modification_time=1521438851000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00009
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000010; isDirectory=true; modification_time=1521438851000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000010/part-00010; isDirectory=false; length=331798; replication=1; blocksize=33554432; modification_time=1521438851000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00010
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000011; isDirectory=true; modification_time=1521438854000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000011/part-00011; isDirectory=false; length=328076; replication=1; blocksize=33554432; modification_time=1521438854000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00011
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000012; isDirectory=true; modification_time=1521438854000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000012/part-00012; isDirectory=false; length=331304; replication=1; blocksize=33554432; modification_time=1521438854000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00012
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000013; isDirectory=true; modification_time=1521438856000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000013/part-00013; isDirectory=false; length=343781; replication=1; blocksize=33554432; modification_time=1521438856000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00013
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000014; isDirectory=true; modification_time=1521438856000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000014/part-00014; isDirectory=false; length=362747; replication=1; blocksize=33554432; modification_time=1521438856000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00014
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000015; isDirectory=true; modification_time=1521438859000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000015/part-00015; isDirectory=false; length=385647; replication=1; blocksize=33554432; modification_time=1521438859000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00015
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000016; isDirectory=true; modification_time=1521438860000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000016/part-00016; isDirectory=false; length=415817; replication=1; blocksize=33554432; modification_time=1521438860000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00016
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000017; isDirectory=true; modification_time=1521438861000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000017/part-00017; isDirectory=false; length=447066; replication=1; blocksize=33554432; modification_time=1521438861000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00017
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000018; isDirectory=true; modification_time=1521438863000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000018/part-00018; isDirectory=false; length=478480; replication=1; blocksize=33554432; modification_time=1521438863000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00018
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000019; isDirectory=true; modification_time=1521438864000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000019/part-00019; isDirectory=false; length=512279; replication=1; blocksize=33554432; modification_time=1521438864000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00019
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000020; isDirectory=true; modification_time=1521438866000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000020/part-00020; isDirectory=false; length=543541; replication=1; blocksize=33554432; modification_time=1521438866000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00020
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000021; isDirectory=true; modification_time=1521438868000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000021/part-00021; isDirectory=false; length=572654; replication=1; blocksize=33554432; modification_time=1521438869000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00021
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000022; isDirectory=true; modification_time=1521438870000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000022/part-00022; isDirectory=false; length=601443; replication=1; blocksize=33554432; modification_time=1521438870000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00022
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000023; isDirectory=true; modification_time=1521438873000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000023/part-00023; isDirectory=false; length=624580; replication=1; blocksize=33554432; modification_time=1521438873000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00023
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000024; isDirectory=true; modification_time=1521438874000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000024/part-00024; isDirectory=false; length=643755; replication=1; blocksize=33554432; modification_time=1521438874000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00024
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000025; isDirectory=true; modification_time=1521438877000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000025/part-00025; isDirectory=false; length=662498; replication=1; blocksize=33554432; modification_time=1521438877000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00025
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000026; isDirectory=true; modification_time=1521438878000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000026/part-00026; isDirectory=false; length=673149; replication=1; blocksize=33554432; modification_time=1521438878000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00026
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000027; isDirectory=true; modification_time=1521438881000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000027/part-00027; isDirectory=false; length=679523; replication=1; blocksize=33554432; modification_time=1521438881000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00027
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000028; isDirectory=true; modification_time=1521438882000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000028/part-00028; isDirectory=false; length=683439; replication=1; blocksize=33554432; modification_time=1521438883000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00028
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000029; isDirectory=true; modification_time=1521438886000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000029/part-00029; isDirectory=false; length=678365; replication=1; blocksize=33554432; modification_time=1521438886000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00029
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000030; isDirectory=true; modification_time=1521438887000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000030/part-00030; isDirectory=false; length=668330; replication=1; blocksize=33554432; modification_time=1521438887000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00030
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000031; isDirectory=true; modification_time=1521438890000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000031/part-00031; isDirectory=false; length=654266; replication=1; blocksize=33554432; modification_time=1521438890000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00031
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000032; isDirectory=true; modification_time=1521438891000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000032/part-00032; isDirectory=false; length=630722; replication=1; blocksize=33554432; modification_time=1521438891000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00032
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000033; isDirectory=true; modification_time=1521438893000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000033/part-00033; isDirectory=false; length=604302; replication=1; blocksize=33554432; modification_time=1521438894000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00033
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000034; isDirectory=true; modification_time=1521438894000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000034/part-00034; isDirectory=false; length=573452; replication=1; blocksize=33554432; modification_time=1521438895000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00034
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000035; isDirectory=true; modification_time=1521438897000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000035/part-00035; isDirectory=false; length=535181; replication=1; blocksize=33554432; modification_time=1521438897000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00035
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000036; isDirectory=true; modification_time=1521438898000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000036/part-00036; isDirectory=false; length=498785; replication=1; blocksize=33554432; modification_time=1521438898000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00036
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000037; isDirectory=true; modification_time=1521438900000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000037/part-00037; isDirectory=false; length=461966; replication=1; blocksize=33554432; modification_time=1521438900000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00037
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000038; isDirectory=true; modification_time=1521438901000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000038/part-00038; isDirectory=false; length=424493; replication=1; blocksize=33554432; modification_time=1521438901000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00038
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000039; isDirectory=true; modification_time=1521438903000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000039/part-00039; isDirectory=false; length=392572; replication=1; blocksize=33554432; modification_time=1521438903000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00039
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000040; isDirectory=true; modification_time=1521438904000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000040/part-00040; isDirectory=false; length=365571; replication=1; blocksize=33554432; modification_time=1521438904000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00040
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000041; isDirectory=true; modification_time=1521438906000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000041/part-00041; isDirectory=false; length=344942; replication=1; blocksize=33554432; modification_time=1521438906000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00041
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000042; isDirectory=true; modification_time=1521438906000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000042/part-00042; isDirectory=false; length=332670; replication=1; blocksize=33554432; modification_time=1521438906000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00042
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000043; isDirectory=true; modification_time=1521438908000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000043/part-00043; isDirectory=false; length=328093; replication=1; blocksize=33554432; modification_time=1521438908000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00043
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000044; isDirectory=true; modification_time=1521438909000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000044/part-00044; isDirectory=false; length=332059; replication=1; blocksize=33554432; modification_time=1521438909000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00044
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000045; isDirectory=true; modification_time=1521438910000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000045/part-00045; isDirectory=false; length=344243; replication=1; blocksize=33554432; modification_time=1521438910000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00045
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000046; isDirectory=true; modification_time=1521438911000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000046/part-00046; isDirectory=false; length=362513; replication=1; blocksize=33554432; modification_time=1521438911000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00046
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000047; isDirectory=true; modification_time=1521438914000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000047/part-00047; isDirectory=false; length=387034; replication=1; blocksize=33554432; modification_time=1521438914000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00047
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000048; isDirectory=true; modification_time=1521438914000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000048/part-00048; isDirectory=false; length=416058; replication=1; blocksize=33554432; modification_time=1521438914000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00048
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000049; isDirectory=true; modification_time=1521438917000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000049/part-00049; isDirectory=false; length=446449; replication=1; blocksize=33554432; modification_time=1521438917000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00049
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000050; isDirectory=true; modification_time=1521438917000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000050/part-00050; isDirectory=false; length=480393; replication=1; blocksize=33554432; modification_time=1521438917000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00050
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000051; isDirectory=true; modification_time=1521438920000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000051/part-00051; isDirectory=false; length=512440; replication=1; blocksize=33554432; modification_time=1521438920000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00051
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000052; isDirectory=true; modification_time=1521438921000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000052/part-00052; isDirectory=false; length=543623; replication=1; blocksize=33554432; modification_time=1521438921000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00052
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000053; isDirectory=true; modification_time=1521438923000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000053/part-00053; isDirectory=false; length=574560; replication=1; blocksize=33554432; modification_time=1521438924000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00053
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000054; isDirectory=true; modification_time=1521438924000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000054/part-00054; isDirectory=false; length=601132; replication=1; blocksize=33554432; modification_time=1521438924000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00054
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000055; isDirectory=true; modification_time=1521438929000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000055/part-00055; isDirectory=false; length=624737; replication=1; blocksize=33554432; modification_time=1521438929000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00055
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000056; isDirectory=true; modification_time=1521438929000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000056/part-00056; isDirectory=false; length=646939; replication=1; blocksize=33554432; modification_time=1521438929000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00056
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000057; isDirectory=true; modification_time=1521438933000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000057/part-00057; isDirectory=false; length=661820; replication=1; blocksize=33554432; modification_time=1521438933000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00057
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000058; isDirectory=true; modification_time=1521438933000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000058/part-00058; isDirectory=false; length=672691; replication=1; blocksize=33554432; modification_time=1521438934000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00058
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000059; isDirectory=true; modification_time=1521438938000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000059/part-00059; isDirectory=false; length=682011; replication=1; blocksize=33554432; modification_time=1521438938000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00059
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000060; isDirectory=true; modification_time=1521438938000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000060/part-00060; isDirectory=false; length=682245; replication=1; blocksize=33554432; modification_time=1521438938000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00060
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000061; isDirectory=true; modification_time=1521438942000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000061/part-00061; isDirectory=false; length=678235; replication=1; blocksize=33554432; modification_time=1521438942000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00061
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000062; isDirectory=true; modification_time=1521438942000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000062/part-00062; isDirectory=false; length=670238; replication=1; blocksize=33554432; modification_time=1521438942000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00062
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000063; isDirectory=true; modification_time=1521438946000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000063/part-00063; isDirectory=false; length=652049; replication=1; blocksize=33554432; modification_time=1521438948000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00063
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000064; isDirectory=true; modification_time=1521438946000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000064/part-00064; isDirectory=false; length=631253; replication=1; blocksize=33554432; modification_time=1521438948000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00064
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000065; isDirectory=true; modification_time=1521438951000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000065/part-00065; isDirectory=false; length=605228; replication=1; blocksize=33554432; modification_time=1521438952000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00065
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000066; isDirectory=true; modification_time=1521438952000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000066/part-00066; isDirectory=false; length=570727; replication=1; blocksize=33554432; modification_time=1521438952000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00066
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000067; isDirectory=true; modification_time=1521438955000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000067/part-00067; isDirectory=false; length=536417; replication=1; blocksize=33554432; modification_time=1521438955000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00067
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000068; isDirectory=true; modification_time=1521438955000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000068/part-00068; isDirectory=false; length=499395; replication=1; blocksize=33554432; modification_time=1521438955000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00068
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000069; isDirectory=true; modification_time=1521438958000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000069/part-00069; isDirectory=false; length=459386; replication=1; blocksize=33554432; modification_time=1521438958000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00069
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000070; isDirectory=true; modification_time=1521438958000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000070/part-00070; isDirectory=false; length=425112; replication=1; blocksize=33554432; modification_time=1521438958000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00070
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000072; isDirectory=true; modification_time=1521438961000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000072/part-00072; isDirectory=false; length=364989; replication=1; blocksize=33554432; modification_time=1521438961000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00072
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000071; isDirectory=true; modification_time=1521438961000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000071/part-00071; isDirectory=false; length=392632; replication=1; blocksize=33554432; modification_time=1521438961000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00071
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000073; isDirectory=true; modification_time=1521438964000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000073/part-00073; isDirectory=false; length=345077; replication=1; blocksize=33554432; modification_time=1521438964000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00073
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000074; isDirectory=true; modification_time=1521438964000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000074/part-00074; isDirectory=false; length=332435; replication=1; blocksize=33554432; modification_time=1521438964000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00074
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000075; isDirectory=true; modification_time=1521438966000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000075/part-00075; isDirectory=false; length=327580; replication=1; blocksize=33554432; modification_time=1521438966000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00075
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000076; isDirectory=true; modification_time=1521438966000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000076/part-00076; isDirectory=false; length=332683; replication=1; blocksize=33554432; modification_time=1521438966000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00076
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000077; isDirectory=true; modification_time=1521438969000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000077/part-00077; isDirectory=false; length=343134; replication=1; blocksize=33554432; modification_time=1521438969000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00077
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000078; isDirectory=true; modification_time=1521438969000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000078/part-00078; isDirectory=false; length=362467; replication=1; blocksize=33554432; modification_time=1521438969000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00078
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000079; isDirectory=true; modification_time=1521438973000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000079/part-00079; isDirectory=false; length=387073; replication=1; blocksize=33554432; modification_time=1521438973000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00079
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000080; isDirectory=true; modification_time=1521438973000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000080/part-00080; isDirectory=false; length=414964; replication=1; blocksize=33554432; modification_time=1521438973000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00080
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000081; isDirectory=true; modification_time=1521438976000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000081/part-00081; isDirectory=false; length=447193; replication=1; blocksize=33554432; modification_time=1521438976000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00081
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000082; isDirectory=true; modification_time=1521438976000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000082/part-00082; isDirectory=false; length=480166; replication=1; blocksize=33554432; modification_time=1521438976000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00082
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000083; isDirectory=true; modification_time=1521438980000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000083/part-00083; isDirectory=false; length=511596; replication=1; blocksize=33554432; modification_time=1521438980000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00083
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000084; isDirectory=true; modification_time=1521438980000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000084/part-00084; isDirectory=false; length=545158; replication=1; blocksize=33554432; modification_time=1521438980000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00084
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000085; isDirectory=true; modification_time=1521438983000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000085/part-00085; isDirectory=false; length=574282; replication=1; blocksize=33554432; modification_time=1521438983000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00085
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000086; isDirectory=true; modification_time=1521438984000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000086/part-00086; isDirectory=false; length=600561; replication=1; blocksize=33554432; modification_time=1521438984000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00086
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000087; isDirectory=true; modification_time=1521438987000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000087/part-00087; isDirectory=false; length=626145; replication=1; blocksize=33554432; modification_time=1521438987000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00087
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000088; isDirectory=true; modification_time=1521438988000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000088/part-00088; isDirectory=false; length=645459; replication=1; blocksize=33554432; modification_time=1521438988000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00088
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000089; isDirectory=true; modification_time=1521438991000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000089/part-00089; isDirectory=false; length=661533; replication=1; blocksize=33554432; modification_time=1521438991000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00089
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000090; isDirectory=true; modification_time=1521438993000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000090/part-00090; isDirectory=false; length=675788; replication=1; blocksize=33554432; modification_time=1521438993000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00090
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000091; isDirectory=true; modification_time=1521438996000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000091/part-00091; isDirectory=false; length=680836; replication=1; blocksize=33554432; modification_time=1521438996000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00091
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000092; isDirectory=true; modification_time=1521438998000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000092/part-00092; isDirectory=false; length=682804; replication=1; blocksize=33554432; modification_time=1521438998000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00092
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000093; isDirectory=true; modification_time=1521439000000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000093/part-00093; isDirectory=false; length=680975; replication=1; blocksize=33554432; modification_time=1521439000000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00093
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000094; isDirectory=true; modification_time=1521439002000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000094/part-00094; isDirectory=false; length=669292; replication=1; blocksize=33554432; modification_time=1521439002000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00094
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000095; isDirectory=true; modification_time=1521439004000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4
18/03/19 07:56:44 DEBUG FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/_temporary/0/task_20180319075351_0017_m_000095/part-00095; isDirectory=false; length=653472; replication=1; blocksize=33554432; modification_time=1521439004000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/rudaini/IdeaProjects/SparkJoinAlgorithms/output4/part-00095
18/03/19 07:56:44 DEBUG HadoopMapRedCommitProtocol: Committing files staged for absolute locations Map()
18/03/19 07:56:44 INFO SparkHadoopWriter: Job job_20180319075351_0017 committed.
18/03/19 07:56:44 INFO SparkContext: Invoking stop() from shutdown hook
18/03/19 07:56:44 INFO SparkUI: Stopped Spark web UI at http://192.168.8.100:4040
18/03/19 07:56:45 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0e/shuffle_0_15_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0e/shuffle_0_22_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0e/shuffle_0_26_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0e/shuffle_0_37_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0e/shuffle_0_44_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0e/shuffle_0_59_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0e/shuffle_0_66_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0e/shuffle_0_88_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0e has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/11/shuffle_0_16_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/11/shuffle_0_23_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/11/shuffle_0_29_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/11/shuffle_0_38_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/11/shuffle_0_45_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/11/shuffle_0_58_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/11/shuffle_0_89_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/11/shuffle_0_67_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/11 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0d/shuffle_0_3_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0d/shuffle_0_69_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0d/shuffle_1_2_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0d has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0c/shuffle_0_0_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0c/shuffle_0_4_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0c/shuffle_0_86_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0c/shuffle_0_17_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0c/shuffle_0_20_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0c/shuffle_0_24_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0c/shuffle_0_39_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0c/shuffle_0_42_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0c/shuffle_0_46_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0c/shuffle_0_64_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0c/shuffle_0_68_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0c/shuffle_1_3_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0c has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/13/shuffle_0_16_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/13/shuffle_0_21_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/13/shuffle_0_38_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/13/shuffle_0_43_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/13/shuffle_0_65_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/13/shuffle_0_87_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/13 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0b/shuffle_0_30_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0b/shuffle_0_52_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0b/shuffle_0_74_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0b has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0a/shuffle_0_6_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0a/shuffle_0_19_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0a/shuffle_0_22_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0a/shuffle_0_44_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0a/shuffle_0_66_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0a/shuffle_0_88_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0a/shuffle_1_1_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0a/shuffle_1_5_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0a has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/15/shuffle_0_1_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/15/shuffle_0_18_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/15 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/09/shuffle_0_50_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/09/shuffle_0_72_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/09/shuffle_0_94_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/09 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/36/shuffle_0_2_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/36/shuffle_0_40_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/36/shuffle_0_62_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/36/shuffle_0_84_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/36 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/08/shuffle_0_8_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/08/shuffle_0_42_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/08/shuffle_0_64_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/08/shuffle_0_86_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/08/shuffle_1_3_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/08/shuffle_1_7_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/08 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/29/shuffle_0_3_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/29/shuffle_0_10_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/29/shuffle_0_32_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/29/shuffle_0_54_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/29/shuffle_0_61_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/29/shuffle_0_76_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/29/shuffle_0_83_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/29 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/07/shuffle_0_41_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/07/shuffle_0_70_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/07/shuffle_0_92_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/07 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/38/shuffle_0_4_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/38/shuffle_0_20_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/38/shuffle_0_60_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/38/shuffle_0_82_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/38 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/06/shuffle_0_84_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/06/shuffle_1_5_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/06 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/27/shuffle_0_5_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/27/shuffle_0_52_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/27/shuffle_0_74_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/27/shuffle_0_81_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/27 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/05/shuffle_0_61_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/05/shuffle_0_83_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/05 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/3a/shuffle_0_6_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/3a/shuffle_0_40_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/3a/shuffle_0_62_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/3a/shuffle_0_80_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/3a has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/1d/shuffle_0_9_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/1d/shuffle_0_70_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/1d/shuffle_0_92_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/1d has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/24/shuffle_0_71_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/24/shuffle_0_93_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/24 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/1e has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/3d has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/1a/shuffle_0_73_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/1a/shuffle_0_91_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/1a/shuffle_0_95_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/1a has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/03/shuffle_0_81_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/03 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/1c has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/00 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/19/shuffle_0_30_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/19/shuffle_1_4_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/19 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/35/shuffle_0_5_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/35/shuffle_0_23_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/35/shuffle_0_29_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/35/shuffle_0_45_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/35/shuffle_0_67_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/35/shuffle_0_89_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/35/shuffle_1_4_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/35 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/3e/shuffle_0_80_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/3e has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/16/shuffle_0_11_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/16/shuffle_0_33_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/16/shuffle_0_51_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/16/shuffle_0_55_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/16/shuffle_0_73_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/16/shuffle_0_77_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/16/shuffle_0_95_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/16 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2a has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/04/shuffle_0_8_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/04 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/3b/shuffle_0_90_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/3b has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/25 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/1b/shuffle_0_7_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/1b/shuffle_0_50_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/1b/shuffle_0_72_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/1b/shuffle_0_94_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/1b/shuffle_1_6_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/1b has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2c/shuffle_0_28_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2c/shuffle_0_31_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2c/shuffle_0_53_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2c/shuffle_0_75_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2c has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/20 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/17/shuffle_1_2_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/17 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/33/shuffle_0_10_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/33/shuffle_0_25_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/33/shuffle_0_27_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/33/shuffle_0_32_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/33/shuffle_0_47_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/33/shuffle_0_49_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/33/shuffle_0_54_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/33/shuffle_0_76_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/33 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/10/shuffle_0_24_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/10/shuffle_0_46_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/10/shuffle_0_68_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/10 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/37/shuffle_0_7_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/37/shuffle_0_21_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/37/shuffle_0_43_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/37/shuffle_0_65_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/37/shuffle_0_87_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/37/shuffle_1_6_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/37 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/3f has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/23 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/3c/shuffle_0_60_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/3c/shuffle_0_82_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/3c/shuffle_1_7_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/3c has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/21 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/26/shuffle_0_51_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/26 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/02 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2b/shuffle_0_78_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2b/shuffle_0_85_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2b/shuffle_0_12_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2b/shuffle_0_34_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2b/shuffle_0_41_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2b/shuffle_0_56_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2b/shuffle_0_63_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2b/shuffle_1_0_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2b has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2d/shuffle_0_14_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2d/shuffle_0_36_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2d/shuffle_0_58_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2d has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/39/shuffle_0_9_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/39/shuffle_0_63_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/39/shuffle_0_85_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/39 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/30/shuffle_0_0_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/30/shuffle_0_13_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/30/shuffle_0_17_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/30/shuffle_0_28_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/30/shuffle_0_35_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/30/shuffle_0_39_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/30/shuffle_0_57_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/30/shuffle_0_79_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/30 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2f/shuffle_0_14_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2f/shuffle_0_36_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2f has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/12/shuffle_0_15_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/12 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/32/shuffle_0_2_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/32/shuffle_0_19_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/32/shuffle_0_48_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/32/shuffle_1_1_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/32 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/34 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/14/shuffle_0_13_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/14/shuffle_0_35_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/14/shuffle_0_57_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/14/shuffle_0_79_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/14 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/1f/shuffle_0_90_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/1f has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/31/shuffle_0_12_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/31/shuffle_0_34_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/31/shuffle_0_47_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/31/shuffle_0_56_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/31/shuffle_0_69_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/31/shuffle_0_78_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/31 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/01 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/28 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/22/shuffle_0_91_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/22 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0f/shuffle_0_1_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0f/shuffle_0_18_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0f/shuffle_0_25_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0f/shuffle_0_27_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0f/shuffle_0_49_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0f/shuffle_1_0_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/0f has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/18/shuffle_0_31_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/18/shuffle_0_53_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/18/shuffle_0_71_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/18/shuffle_0_75_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/18/shuffle_0_93_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/18 has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2e/shuffle_0_11_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2e/shuffle_0_26_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2e/shuffle_0_48_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2e/shuffle_0_59_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2e/shuffle_0_77_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2e/shuffle_0_33_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2e/shuffle_0_37_0.index has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2e/shuffle_0_55_0.data has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d/2e has been deleted
18/03/19 07:56:45 TRACE Utils: /tmp/blockmgr-1a1464b3-9144-4d6c-b10d-195b7910694d has been deleted
18/03/19 07:56:45 INFO MemoryStore: MemoryStore cleared
18/03/19 07:56:45 INFO BlockManager: BlockManager stopped
18/03/19 07:56:45 INFO BlockManagerMaster: BlockManagerMaster stopped
18/03/19 07:56:45 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/03/19 07:56:45 TRACE Utils: /tmp/spark-e95b86df-4f55-4689-8171-b1bfb6f1b196/userFiles-e39b1977-7124-4ca5-b3e7-83fd15c2fd5b has been deleted
18/03/19 07:56:45 INFO SparkContext: Successfully stopped SparkContext
18/03/19 07:56:45 INFO ShutdownHookManager: Shutdown hook called
18/03/19 07:56:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-e95b86df-4f55-4689-8171-b1bfb6f1b196
18/03/19 07:56:45 TRACE Utils: /tmp/spark-e95b86df-4f55-4689-8171-b1bfb6f1b196 has been deleted
